<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#42b983"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/blog/public/index.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/public/index.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/public/index.ico">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#42b983">

<link rel="stylesheet" href="/blog/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"ayou129.github.io","root":"/blog/","images":"/blog/images","scheme":"Muse","darkmode":false,"version":"8.14.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":"flat","style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/blog/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/blog/js/config.js"></script>

    <meta name="description" content="暂无描述">
<meta property="og:type" content="article">
<meta property="og:title" content="AI大模型">
<meta property="og:url" content="https://ayou129.github.io/blog/p/614a8113/index.html">
<meta property="og:site_name" content="阿尤">
<meta property="og:description" content="暂无描述">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E6%A8%A1%E5%9E%8B%E5%AE%B9%E9%87%8F%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E5%85%B3%E7%B3%BB.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/tsne_df.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E8%BF%9B%E8%A1%8Ct%E5%88%86%E5%B8%83%E9%9A%8F%E6%9C%BA%E9%82%BB%E5%9F%9F%E5%B5%8C%E5%85%A5%EF%BC%88t-SNE%EF%BC%89%E5%88%86%E8%A7%A3%EF%BC%8C%E5%B0%86%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E5%88%B02%E4%B8%AA%E7%BB%B4%E5%BA%A6%EF%BC%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%B8%80%E5%AE%9A%E7%A8%8B%E5%BA%A6%E4%B8%8A%E5%88%86%E7%A6%BB%E5%9B%BE%E5%83%8F.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E6%84%9F%E7%9F%A5%E6%9C%BA(%E4%BA%8C%E5%88%86%E7%B1%BB">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/Transformer.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E6%96%AF%E5%9D%A6%E7%A6%8F21%E7%A7%8B%E5%AD%A3%EF%BC%9A%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BE%8B%E5%A6%82%EF%BC%9A%E9%A2%84%E6%B5%8B%E6%88%BF%E5%B1%8B%E9%94%80%E5%94%AE%E4%BB%B7%E6%A0%BC.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E5%A6%82%E4%BD%95%E5%AF%BB%E6%89%BE%E6%9C%80%E5%90%88%E9%80%82%E7%9A%84a%E3%80%81b.png">
<meta property="og:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E5%A6%82%E4%BD%95%E5%AF%BB%E6%89%BE%E6%9C%80%E5%90%88%E9%80%82%E7%9A%84a%E3%80%81b_%E8%BD%AC%E5%8C%96.png">
<meta property="article:published_time" content="2024-03-14T14:34:00.000Z">
<meta property="article:modified_time" content="2024-03-14T14:34:00.000Z">
<meta property="article:author" content="阿尤">
<meta property="article:tag" content="learning, coding, writing, 学习, 编程, 阿尤">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ayou129.github.io/blog/p/614a8113/p/614a8113/%E6%A8%A1%E5%9E%8B%E5%AE%B9%E9%87%8F%E5%92%8C%E6%95%B0%E6%8D%AE%E7%9A%84%E5%85%B3%E7%B3%BB.png">


<link rel="canonical" href="https://ayou129.github.io/blog/p/614a8113/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://ayou129.github.io/blog/p/614a8113/","path":"p/614a8113/","title":"AI大模型"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AI大模型 | 阿尤</title>
  






  <script async defer data-website-id="" src=""></script>

  <script defer data-domain="" src=""></script>

  <noscript>
    <link rel="stylesheet" href="/blog/css/noscript.css">
  </noscript>
<link rel="alternate" href="/blog/atom.xml" title="阿尤" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">
      <img class="custom-logo-image" src="/blog/uploads/%E9%98%BF%E5%B0%A4%E5%8A%A8%E6%BC%AB%E5%A4%B4.jpeg" alt="阿尤">

    <a href="/blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">阿尤</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">博客</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">37</span></a></li><li class="menu-item menu-item-categories"><a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">2</span></a></li><li class="menu-item menu-item-archives"><a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">66</span></a></li><li class="menu-item menu-item-sitemap"><a href="/blog/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">下载模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Hugging-Face-%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BA%93"><span class="nav-number">1.1.</span> <span class="nav-text">使用 Hugging Face 客户端库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Git"><span class="nav-number">1.2.</span> <span class="nav-text">使用 Git</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">模型推理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Transformers-%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.</span> <span class="nav-text">Transformers 模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-number">3.</span> <span class="nav-text">处理器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Transformers-%E5%A4%84%E7%90%86%E5%99%A8%E6%9C%89%E4%B8%A4%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84%E5%90%AB%E4%B9%89"><span class="nav-number">3.1.</span> <span class="nav-text">Transformers 处理器有两种不同的含义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0"><span class="nav-number">4.</span> <span class="nav-text">学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E6%88%98"><span class="nav-number">5.</span> <span class="nav-text">实战</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9-%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="nav-number">5.0.1.</span> <span class="nav-text">11 模型选择+过拟合和欠拟合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#28-%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-number">5.0.2.</span> <span class="nav-text">28 批量归一化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%80%9D%E8%B7%AF"><span class="nav-number">5.1.</span> <span class="nav-text">训练思路</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8F%90%E9%97%AE"><span class="nav-number">5.1.1.</span> <span class="nav-text">提问</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%9E%E7%AD%94"><span class="nav-number">5.1.2.</span> <span class="nav-text">回答</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%B3%E7%90%86%E4%B8%80%E4%B8%8B%E7%AC%AC%E4%B8%80%E6%AD%A5-%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%92%8C%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E6%AF%8F%E4%B8%AA%E7%BB%86%E8%8A%82"><span class="nav-number">5.2.</span> <span class="nav-text">梳理一下第一步 数据收集和预处理的每个细节</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8F%90%E9%97%AE-1"><span class="nav-number">5.2.1.</span> <span class="nav-text">提问</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%9E%E7%AD%94-1"><span class="nav-number">5.2.2.</span> <span class="nav-text">回答</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9php%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86"><span class="nav-number">5.2.3.</span> <span class="nav-text">对php文件进行处理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8F%90%E9%97%AE-2"><span class="nav-number">5.2.3.1.</span> <span class="nav-text">提问</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9B%9E%E7%AD%94-2"><span class="nav-number">5.2.3.2.</span> <span class="nav-text">回答</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%94%B6%E9%9B%86%E5%92%8C%E5%A4%84%E7%90%86%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="nav-number">5.3.</span> <span class="nav-text">数据集收集和处理训练数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Download%E6%A8%A1%E5%9E%8B"><span class="nav-number">6.</span> <span class="nav-text">Download模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9D%82%E9%A1%B9"><span class="nav-number">7.</span> <span class="nav-text">杂项</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BE%E7%A8%8B"><span class="nav-number">8.</span> <span class="nav-text">课程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Approaching-Almost-Any-NLP-Problem"><span class="nav-number">8.1.</span> <span class="nav-text">Approaching (Almost) Any NLP Problem</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%89%E7%9B%91%E7%9D%A3%E5%92%8C%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-number">8.1.1.</span> <span class="nav-text">有监督和无监督学习</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E6%A3%80%E9%AA%8C"><span class="nav-number">8.1.2.</span> <span class="nav-text">交叉检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E5%8F%98%E9%87%8F"><span class="nav-number">8.1.3.</span> <span class="nav-text">分类变量</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%87%E7%AD%BE%E7%BC%96%E7%A0%81"><span class="nav-number">8.1.3.1.</span> <span class="nav-text">标签编码</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5"><span class="nav-number">8.1.3.2.</span> <span class="nav-text">稀疏矩阵</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81"><span class="nav-number">8.1.3.3.</span> <span class="nav-text">独热编码</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83"><span class="nav-number">8.1.4.</span> <span class="nav-text">设置环境</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0v2"><span class="nav-number">8.2.</span> <span class="nav-text">动手学深度学习v2</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">8.2.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%8B%E8%BC%89%E5%AE%89%E8%A3%9D%E6%9C%8D%E5%8B%99%E5%99%A8"><span class="nav-number">8.2.2.</span> <span class="nav-text">下載安裝服務器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#04-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">8.2.3.</span> <span class="nav-text">04 数据操作 + 数据预处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#05-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0"><span class="nav-number">8.2.4.</span> <span class="nav-text">05 线性代数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-%E6%84%9F%E7%9F%A5%E6%9C%BASNP-%E5%92%8C-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA-MLP"><span class="nav-number">8.2.5.</span> <span class="nav-text">10 感知机SNP 和 多层感知机 MLP</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%84%9F%E7%9F%A5%E6%9C%BA%EF%BC%88%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="nav-number">8.2.5.1.</span> <span class="nav-text">感知机（模型）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">8.2.5.2.</span> <span class="nav-text">多层感知机</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-%E5%AE%9E%E6%88%98-Kaggle-%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B"><span class="nav-number">8.2.6.</span> <span class="nav-text">15 实战 Kaggle 房价预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#19-%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">8.2.7.</span> <span class="nav-text">19 卷积层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#22-%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="nav-number">8.2.8.</span> <span class="nav-text">22 池化层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#33-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E5%B9%B6%E8%A1%8C"><span class="nav-number">8.2.9.</span> <span class="nav-text">33 单机多卡并行</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#35-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83"><span class="nav-number">8.2.10.</span> <span class="nav-text">35 分布式训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#37-%E5%BE%AE%E8%B0%83"><span class="nav-number">8.2.11.</span> <span class="nav-text">37 微调</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#64-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">8.2.12.</span> <span class="nav-text">64 注意力机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#68-Transformer"><span class="nav-number">8.2.13.</span> <span class="nav-text">68 Transformer</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%AF%E5%9D%A6%E7%A6%8F21%E7%A7%8B%E5%AD%A3%EF%BC%9A%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="nav-number">8.3.</span> <span class="nav-text">斯坦福21秋季：实用机器学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-%E4%BB%8B%E7%BB%8D"><span class="nav-number">8.3.1.</span> <span class="nav-text">1.1 介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-%E6%95%B0%E6%8D%AE%E8%8E%B7%E5%8F%96"><span class="nav-number">8.3.2.</span> <span class="nav-text">1.2 数据获取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3-%E7%BD%91%E9%A1%B5%E7%9A%84%E6%95%B0%E6%8D%AE%E6%8A%93%E5%8F%96"><span class="nav-number">8.3.3.</span> <span class="nav-text">1.3 网页的数据抓取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-4-%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8"><span class="nav-number">8.3.4.</span> <span class="nav-text">1.4 数据标注</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-8%E5%88%86%E9%92%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D"><span class="nav-number">8.3.5.</span> <span class="nav-text">3.1 8分钟机器学习介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-%E6%9C%80%E7%AE%80%E5%8D%95%E4%B9%9F%E6%9C%80%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%B3%E7%AD%96%E6%A0%91-Decision-Tree"><span class="nav-number">8.3.6.</span> <span class="nav-text">3.2 最简单也最常用的决策树 Decision Tree</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E0%E5%85%A5%E9%97%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="nav-number">8.4.</span> <span class="nav-text">从0入门人工智能</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="nav-number">8.4.1.</span> <span class="nav-text">介绍以及环境配置</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7%E5%8C%85"><span class="nav-number">8.4.1.1.</span> <span class="nav-text">基础工具包</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D"><span class="nav-number">8.4.1.2.</span> <span class="nav-text">机器学习介绍</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">8.4.1.3.</span> <span class="nav-text">机器学习-线性回归</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5-%E5%A4%9A%E5%9B%A0%E5%AD%90%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E6%88%98"><span class="nav-number">8.4.2.</span> <span class="nav-text">2-5 多因子线性回归实战</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-number">8.4.3.</span> <span class="nav-text">3-1 机器学习-逻辑回归</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3"><span class="nav-number">8.4.4.</span> <span class="nav-text">3-3</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4"><span class="nav-number">8.4.5.</span> <span class="nav-text">3-4</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-5-%E5%AE%9E%E6%88%981-%E8%80%83%E8%AF%95%E9%80%9A%E8%BF%87%E9%A2%84%E6%B5%8B"><span class="nav-number">8.4.6.</span> <span class="nav-text">3-5 实战1 考试通过预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%81%9A%E7%B1%BB"><span class="nav-number">8.4.7.</span> <span class="nav-text">4 机器学习-聚类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%85%B6%E4%BB%96"><span class="nav-number">8.4.8.</span> <span class="nav-text">5 机器学习-其他</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E5%92%8C%E4%BC%98%E5%8C%96"><span class="nav-number">8.4.9.</span> <span class="nav-text">6 模型评价和优化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-number">8.4.10.</span> <span class="nav-text">7 深度学习-多层感知机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-1-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA-MLP"><span class="nav-number">8.4.11.</span> <span class="nav-text">7-1 多层感知机 MLP</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-2-MLP-%E5%AE%9E%E7%8E%B0%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB"><span class="nav-number">8.4.12.</span> <span class="nav-text">7-2 MLP 实现非线性分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-3-Keras"><span class="nav-number">8.4.13.</span> <span class="nav-text">7-3 Keras</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-%E5%AE%9E%E6%88%98-1-%E5%BB%BA%E7%AB%8BMLP%E5%AE%9E%E7%8E%B0%E9%9D%9E%E7%BA%BF%E6%80%A7%E4%BA%8C%E5%88%86%E7%B1%BB"><span class="nav-number">8.4.14.</span> <span class="nav-text">7-4 实战 1 建立MLP实现非线性二分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">8.4.15.</span> <span class="nav-text">8 深度学习-卷积神经网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">8.4.16.</span> <span class="nav-text">9 深度学习-循环神经网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E3%80%81%E6%B7%B7%E5%90%88%E7%AE%97%E6%B3%95"><span class="nav-number">8.4.17.</span> <span class="nav-text">10 迁移学习、混合算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-2-%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B"><span class="nav-number">8.4.18.</span> <span class="nav-text">10-2 混合模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-6-%E5%AE%9E%E6%88%98%E5%87%86%E5%A4%87"><span class="nav-number">8.4.19.</span> <span class="nav-text">10-6 实战准备</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E6%88%981-%E5%87%86%E5%A4%87"><span class="nav-number">8.4.19.1.</span> <span class="nav-text">实战1 准备</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E6%88%981-%E5%9F%BA%E4%BA%8E%E6%96%B0%E6%95%B0%E6%8D%AE%E7%9A%84%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="nav-number">8.4.19.2.</span> <span class="nav-text">实战1 基于新数据的迁移学习</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E6%88%982-%E5%AF%BB%E6%89%BE%E6%99%AE%E9%80%9A%E8%8B%B9%E6%9E%9C%E5%92%8C%E5%85%B6%E4%BB%96%E8%8B%B9%E6%9E%9C"><span class="nav-number">8.4.19.3.</span> <span class="nav-text">实战2 寻找普通苹果和其他苹果</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AE%E8%BD%AF%E7%94%9F%E6%88%90%E5%BC%8FAI-generative-ai-for-beginners"><span class="nav-number">8.5.</span> <span class="nav-text">微软生成式AI generative-ai-for-beginners</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">阿尤</p>
  <div class="site-description" itemprop="description">成长就是不断发现自己是SB的过程！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/blog/archives/">
          <span class="site-state-item-count">66</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/blog/categories/">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/blog/tags/">
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ayou129.github.io/blog/p/614a8113/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="阿尤">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="阿尤">
      <meta itemprop="description" content="成长就是不断发现自己是SB的过程！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="AI大模型 | 阿尤">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AI大模型
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-14 22:34:00" itemprop="dateCreated datePublished" datetime="2024-03-14T22:34:00+08:00">2024-03-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" itemprop="url" rel="index"><span itemprop="name">编程语言</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>暂无描述</p>
<span id="more"></span>



<p><a href="https://huggingface.co/welcome" target="_blank" rel="noopener">https://huggingface.co/welcome</a></p>
<p>ML 模型</p>
<p>模型存储库</p>
<ul>
<li>模型卡 Model Cards 模型随附的文件，可提供方便的信息<ul>
<li>带有附加元数据的简单 Markdown 文件 README.md</li>
<li>模型卡 模板 <a href="https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md" target="_blank" rel="noopener">https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md</a></li>
</ul>
</li>
</ul>
<p>模型<br>数据集</p>
<ul>
<li>不同领域和模式的各种数据<br>Spaces</li>
<li>用于直接在浏览器中演示 ML 模型的交互式应用程序。</li>
</ul>
<p>使用 Huggingface hub 客户端 下载 预先训练的模型，数据集和 Spaces，使用 Transformers 进行微调和推理。而后可以利用 Inference API 在生产设置中使用模型。</p>
<h2 id="下载模型"><a href="#下载模型" class="headerlink" title="下载模型"></a>下载模型</h2><h3 id="使用-Hugging-Face-客户端库"><a href="#使用-Hugging-Face-客户端库" class="headerlink" title="使用 Hugging Face 客户端库"></a>使用 Hugging Face 客户端库</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> hf_hub_download</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"></span><br><span class="line">REPO_ID = <span class="string">&quot;YOUR_REPO_ID&quot;</span></span><br><span class="line">FILENAME = <span class="string">&quot;sklearn_model.joblib&quot;</span></span><br><span class="line"></span><br><span class="line">model = joblib.load(</span><br><span class="line">    hf_hub_download(repo_id=REPO_ID, filename=FILENAME)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="使用-Git"><a href="#使用-Git" class="headerlink" title="使用 Git"></a>使用 Git</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git lfs install </span><br><span class="line">git clone git@hf.co:&lt;MODEL ID&gt; <span class="comment"># 示例: git clone git@hf.co:bigscience/bloom</span></span><br></pre></td></tr></table></figure>

<h2 id="模型推理"><a href="#模型推理" class="headerlink" title="模型推理"></a>模型推理</h2><h3 id="Transformers-模型"><a href="#Transformers-模型" class="headerlink" title="Transformers 模型"></a>Transformers 模型</h3><p>Pipelines （管道）为 API 提供支持</p>
<ul>
<li>命名实体识别</li>
<li>掩码语言建模</li>
<li>情感分析特征提取</li>
<li>问答</li>
</ul>
<h2 id="处理器"><a href="#处理器" class="headerlink" title="处理器"></a>处理器</h2><h3 id="Transformers-处理器有两种不同的含义"><a href="#Transformers-处理器有两种不同的含义" class="headerlink" title="Transformers 处理器有两种不同的含义"></a>Transformers 处理器有两种不同的含义</h3><ul>
<li>预处理多模态模型输入的对象，例如Wav2Vec2（语音和文本）或CLIP（文本和视觉）</li>
<li>旧版本库中用于预处理 GLUE 或 SQUAD 数据的已弃用对象。</li>
</ul>
<h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><p>Introduction<br>We’ll start with an overview of how machine learning models work and how they are used. This may feel basic if you’ve done statistical modeling or machine learning before. Don’t worry, we will progress to building powerful models soon.</p>
<p>This course will have you build models as you go through following scenario:</p>
<p>Your cousin has made millions of dollars speculating on real estate. He’s offered to become business partners with you because of your interest in data science. He’ll supply the money, and you’ll supply models that predict how much various houses are worth.</p>
<p>You ask your cousin how he’s predicted real estate values in the past, and he says it is just intuition. But more questioning reveals that he’s identified price patterns from houses he has seen in the past, and he uses those patterns to make predictions for new houses he is considering.</p>
<p>Machine learning works the same way. We’ll start with a model called the Decision Tree. There are fancier models that give more accurate predictions. But decision trees are easy to understand, and they are the basic building block for some of the best models in data science.</p>
<p>For simplicity, we’ll start with the simplest possible decision tree.</p>
<p>决策树的模型</p>
<p>Pandas 简称ps，是数据科学家用来探索和操纵数据的主要工具。<br>import pandas as pd</p>
<p>将把同样的过程应用于一个新的数据集</p>
<p>示例（墨尔本）数据位于文件路径&#x2F;input&#x2F;melbourne housing snapshot&#x2F;melb_data.csv</p>
<p>使用以下命令加载和浏览数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save filepath to variable for easier access</span></span><br><span class="line">melbourne_file_path = <span class="string">&#x27;../input/melbourne-housing-snapshot/melb_data.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># read the data and store data in DataFrame titled melbourne_data</span></span><br><span class="line">melbourne_data = pd.read_csv(melbourne_file_path) </span><br><span class="line"></span><br><span class="line"><span class="comment"># print a summary of the data in Melbourne data</span></span><br><span class="line">melbourne_data.describe()</span><br></pre></td></tr></table></figure>






<h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>我现在计划训练一个能帮助我写代码的机器人</p>
<p>需求和目标如下：</p>
<ul>
<li>模型是专注于特定编程语言（Html5、css3、php8、Mysql8）<ul>
<li>其中 php 采用的是 Hyperf3.1 版本基于Swoole的协程框架</li>
<li>项目整体采用的Docker-compose 架构</li>
</ul>
</li>
<li>模型的应用场景，用于自动生成函数、类、模块、甚至是整个项目的代码。</li>
<li>设计模型目标输出：<ul>
<li>基于自然语言描述自动生成符合需求的<ul>
<li>函数和类</li>
<li>API说明文档</li>
<li>数据表</li>
</ul>
</li>
</ul>
</li>
<li>除了能根据代码片段生成建议代码，我还要能够正常和ai沟通，让他了解我的需求，从而进一步帮我生成更完善的需求代码</li>
</ul>
<p>我现在的项目预训练数据大概是这种结构(每个结构中都是一个文件夹，内部都是相关的许多文件)：</p>
<ul>
<li>服务端<ul>
<li>使用的hyperf3.1基于swoole（PHP的异步、并行、高性能网络通信引擎,支持TCP长连接,Websocket,Mqtt等协议）的php语言框架</li>
</ul>
</li>
<li>数据库<ul>
<li>mysql目前只有一个sql文件。</li>
</ul>
</li>
<li>前端代码<ul>
<li>基于Vue3的JavaScript 框架，包含了sass等</li>
</ul>
</li>
</ul>
<p>训练项目的文件结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">project/</span><br><span class="line">  ├── data/</span><br><span class="line">      <span class="comment"># 存放项目所需的数据集</span></span><br><span class="line">      ├── raw_text/</span><br><span class="line">          <span class="comment"># 存放原始自然语言描述和对应代码示例的文本数据</span></span><br><span class="line">          <span class="comment"># 可以根据数据格式进一步细分，例如 .txt 文件、.json 文件等</span></span><br><span class="line">          <span class="comment"># 建议使用版本控制工具管理原始数据的版本</span></span><br><span class="line">          ├── python/</span><br><span class="line">          └── php/</span><br><span class="line">              ├── hyperf/</span><br><span class="line">              └── hyperf-skeleton/</span><br><span class="line">      ├── preprocessed/</span><br><span class="line">          <span class="comment"># 存放预处理后的数据集，便于模型直接读取</span></span><br><span class="line">          <span class="comment"># 可以根据编程语言或框架分类存储，方便后续训练和使用</span></span><br><span class="line">          <span class="comment"># 预处理脚本应该记录预处理过程和参数，以便复现结果</span></span><br><span class="line">          ├── python/</span><br><span class="line">              ├── train.json</span><br><span class="line">              ├── dev.json</span><br><span class="line">              ├── test.json</span><br><span class="line">          └── java/</span><br><span class="line">              ├── train.json</span><br><span class="line">              ├── dev.json</span><br><span class="line">              ├── test.json</span><br><span class="line">  ├── models/</span><br><span class="line">      ├── models.py</span><br><span class="line">      <span class="comment"># 存放模型文件</span></span><br><span class="line">      ├── base_model/</span><br><span class="line">          <span class="comment"># 存储预训练模型文件，例如来自 Hugging Face 或其他模型库</span></span><br><span class="line">          <span class="comment"># 可以根据模型类型或来源进行分类存储</span></span><br><span class="line">          <span class="comment"># 建议记录模型的版本、训练参数等信息</span></span><br><span class="line">          ├── bert-base-uncased.<span class="built_in">zip</span></span><br><span class="line">          └── gpt2.<span class="built_in">zip</span></span><br><span class="line">      ├── fine_tuned_model/</span><br><span class="line">          <span class="comment"># 存储微调后保存的特定编程语言和框架的模型</span></span><br><span class="line">          <span class="comment"># 可以根据编程语言、框架或任务进行分类存储</span></span><br><span class="line">          <span class="comment"># 建议记录模型的训练参数、性能指标等信息</span></span><br><span class="line">          ├── python/</span><br><span class="line">              ├── model_name.ckpt</span><br><span class="line">          └── java/</span><br><span class="line">              ├── model_name.ckpt</span><br><span class="line">  ├── scripts/</span><br><span class="line">      <span class="comment"># 存放项目相关的脚本</span></span><br><span class="line">      ├── preprocessing.py</span><br><span class="line">          <span class="comment"># 数据预处理脚本，用于将原始数据转换为模型可用的格式</span></span><br><span class="line">          <span class="comment"># 应该包含详细的注释和文档，解释预处理过程和参数</span></span><br><span class="line">          <span class="comment"># 可以使用函数或类将代码组织成模块，提高可读性</span></span><br><span class="line">      ├── training.py</span><br><span class="line">          <span class="comment"># 模型训练脚本，用于训练代码生成模型</span></span><br><span class="line">          <span class="comment"># 应该包含详细的注释和文档，解释训练参数和过程</span></span><br><span class="line">          <span class="comment"># 可以使用函数或类将代码组织成模块，提高可读性</span></span><br><span class="line">      ├── inference.py</span><br><span class="line">          <span class="comment"># 模型推理脚本，用于使用训练好的模型生成代码</span></span><br><span class="line">          <span class="comment"># 应该包含详细的注释和文档，解释推理过程和参数</span></span><br><span class="line">          <span class="comment"># 可以提供命令行接口或 API 方便调用</span></span><br><span class="line">  ├── config.py</span><br><span class="line">      <span class="comment"># 训练配置文件，存储训练所需的参数，例如数据集路径、模型参数、训练超参数等</span></span><br><span class="line">      <span class="comment"># 建议将配置文件细分为不同的模块，例如 data、model、training 等，以便更清晰地管理配置参数</span></span><br><span class="line">  └── README.md</span><br><span class="line">      <span class="comment"># 项目说明文档，介绍项目概况、文件结构、使用说明等</span></span><br><span class="line">      <span class="comment"># 应该包含项目简介、安装说明、使用教程、常见问题解答等内容</span></span><br><span class="line">      <span class="comment"># 可以使用 Markdown 格式编写，方便阅读和维护</span></span><br></pre></td></tr></table></figure>

<p>我现在计划训练一个能帮助我写代码的机器人</p>
<p>需求和目标如下：</p>
<ul>
<li>模型是专注于特定编程语言（Html5、css3、php8、Mysql8）<ul>
<li>其中 php 采用的是 Hyperf3.1 版本基于Swoole的协程框架</li>
<li>项目整体采用的Docker-compose 架构</li>
</ul>
</li>
<li>模型的应用场景，用于自动生成函数、类、模块、甚至是整个项目的代码。</li>
<li>设计模型目标输出：<ul>
<li>基于自然语言描述自动生成符合需求的<ul>
<li>函数和类</li>
<li>API说明文档</li>
<li>数据表</li>
</ul>
</li>
</ul>
</li>
<li>除了能根据代码片段生成建议代码，我还要能够正常和ai沟通，让他了解我的需求，从而进一步帮我生成更完善的需求代码</li>
</ul>
<p>我现在的项目预训练数据大概是这种结构(每个结构中都是一个文件夹，内部都是相关的许多文件)：</p>
<ul>
<li>服务端<ul>
<li>使用的hyperf3.1基于swoole（PHP的异步、并行、高性能网络通信引擎,支持TCP长连接,Websocket,Mqtt等协议）的php语言框架</li>
</ul>
</li>
<li>数据库<ul>
<li>mysql目前只有一个sql文件。</li>
</ul>
</li>
<li>前端代码<ul>
<li>基于Vue3的JavaScript 框架，包含了sass等</li>
</ul>
</li>
</ul>
<p>我计划使用本地设备包括一个显卡NVIDIA GeForce RTX 4070 Ti SUPER 以及采用 Transformer 架构来训练场景</p>
<p>我现在添加了学习前的数据，在php目录下的文件夹</p>
<ul>
<li>hyperf-skeleton 文件夹是独立的专门用于开发后端应用服务的框架</li>
</ul>
<p>现在开始执行第一步的代码：整理php的数据集<br>要求如下：</p>
<ul>
<li>要考虑除了.php文件的情况，每一种文件的数据集整理方式不同</li>
<li>数据集需要清除不必要的符号，但是需要留下注释作为描述</li>
</ul>
<ol>
<li>先训练一个php的模型<ol>
<li>训练</li>
<li>预测</li>
<li>评估</li>
<li>优化</li>
</ol>
</li>
<li>训练Composer的模型<ol>
<li>训练</li>
<li>预测</li>
<li>评估</li>
<li>优化</li>
</ol>
</li>
<li>训练Mysql的模型<br>TODO</li>
</ol>
<p>现在我准备着手开始训练我的模型，我应该给什么样子的数据给 模型 进行第一步的训练呢</p>
<p>我应该如何将数据集加入到训练项目中，你的回答要带实际的代码</p>
<p>首先我确定我使用的是基于Transformer的模型，但是我学习到 有很多其他的功能 比如双向循环神经网络 深层循环神经网络 长短期记忆网络 门控循环单元 循环神经网络 序列模型 卷积神经网络 批量归一化  等 我应该如何根据自己的需求选择呢 或者如何搭配？在python代码层面来说 我拿到php所有内容之后 是直接执行 tf的 fit 进行训练吗？</p>
<p>针对于与我的.php内容想要进行训练，训练前，我需要进行分词或Tokenization吗 分词或Tokenization是什么？<br>针对于与我的.php内容想要进行训练，如何进行分词或Tokenization？用python表示一下</p>
<p>如果放在一起 路径和注释需不需要转化以及如何转化为稠密向量   代码已经做了分词处理 然后三者应该如何结合在一起呢</p>
<p>针对于与我的.php内容想要进行训练，训练前，我需要进行词嵌入（例如使用Word2Vec、BERT等预训练模型）将tokens转化为稠密向量吗？</p>
<p>针对于与我的.php内容想要进行训练，训练前，我需要将所有数组文本构造成适合模型训练的形式，通常是张量（Tensor）吗？</p>
<p>针对于与我的.php内容想要进行训练，我这个是属于监督学习还是其他的？</p>
<h4 id="11-模型选择-过拟合和欠拟合"><a href="#11-模型选择-过拟合和欠拟合" class="headerlink" title="11 模型选择+过拟合和欠拟合"></a>11 模型选择+过拟合和欠拟合</h4><p>训练误差和泛化误差</p>
<ul>
<li>训练误差(训练场景)：景-训练集上的误差</li>
<li>泛化误差(真实场景)：-模型在任意一个新样本上的误差的期望，并且泛化误差是我们关心的，因为我们希望模型对新样本也能有很好的预测能力</li>
</ul>
<p>验证数据集合测试数据集</p>
<ul>
<li>验证数据集：用来评估模型好坏<ul>
<li>拿出50%的训练数据</li>
<li>不和训练数据混在一起（常犯错误）</li>
</ul>
</li>
<li>测试数据集：只用一次的数据集<ul>
<li>未来的考试</li>
</ul>
</li>
</ul>
<p>K-则交叉验证</p>
<ul>
<li>在没有足够多数据时使用（常态）</li>
<li>算法<ul>
<li>将训练数据分割成K块</li>
<li>For i &#x3D; 1,2,…,K<ul>
<li>循环的使用第i块作为验证数据集，其他的座位训练数据集</li>
</ul>
</li>
<li>报告K个验证集误差的平均</li>
</ul>
</li>
<li>常用K&#x3D;5或10</li>
</ul>
<p>总结：</p>
<ol>
<li>训练数据集：训练模型参数</li>
<li>验证数据集：选择模型超参数</li>
<li>非大数据集上通常使用k-则交叉验证</li>
</ol>
<p>过拟合Underfitting和欠拟合Overfitting 中间是 Desired</p>
<ul>
<li>过拟合：模型在训练数据集上表现很好，但是在测试数据集上表现很差<ul>
<li>原因：模型太复杂，参数太多</li>
<li>解决：减少模型复杂度(多层神经网络)，增加数据量</li>
</ul>
</li>
<li>欠拟合：模型在训练数据集上表现很差<ul>
<li>原因：模型太简单，参数太少</li>
<li>解决：增加模型复杂度(多层神经网络)，增加数据量</li>
</ul>
</li>
</ul>
<div>
                <img src="p/614a8113/模型容量和数据的关系.png" alt="模型容量和数据的关系"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[模型容量和数据的关系]</p>
            </div>
模型容量（max-0,0就是完美拟合）：
- 拟合各种函数的能力
- 低容量的模型难以拟合训练数据
- 高容量的模型可以记住所有的训练数据


<p>估计模型容量</p>
<ul>
<li>难以在不同的种类算法之间比较<ul>
<li>例如 树模型 和 神经网络</li>
</ul>
</li>
<li>给定一个模型种类，将有两个主要因素<ul>
<li>参数的个数</li>
<li>参数值的选择范围</li>
</ul>
</li>
</ul>
<p>统计学理论核心思想：VC理论</p>
<ul>
<li>给定一个分类模型，VC等于一个最大的数据集的大小，不管如何给定标号，都存在一个模型来对她进行完美分类</li>
</ul>
<p>线性分类器的VC维</p>
<ul>
<li>2维输入的感知机，VC维&#x3D;3<ul>
<li>能分类任何三个点，但不是4个（xor）</li>
</ul>
</li>
<li>支持N维输入的感知机的VC维是N+1</li>
<li>一些多层感知机的VC维是O(N * log2N)</li>
</ul>
<p>VC维的用处</p>
<ul>
<li>提供为什么一个模型好的理论依据<ul>
<li>可以衡量训练误差和泛化误差之间的间隔</li>
</ul>
</li>
<li>深度学习中很少使用<ul>
<li>衡量不准确</li>
<li>计算深度学习模型的VC维很困难</li>
</ul>
</li>
</ul>
<p>数据复杂度</p>
<ul>
<li>多个重要因素<ul>
<li>样本个数</li>
<li>每个样本的元素个数</li>
<li>时间、空间结构</li>
<li>多样性</li>
</ul>
</li>
</ul>
<h4 id="28-批量归一化"><a href="#28-批量归一化" class="headerlink" title="28 批量归一化"></a>28 批量归一化</h4><ul>
<li>层数很多，损失梯度大，数据在最后</li>
<li>上层训练的快，但是更新了底层后上层需要重新训练，导致收敛会很慢</li>
</ul>
<p>解决方案：</p>
<ul>
<li>固定小批量里面的均值和方差，使得每一层的输入分布都是固定的</li>
<li>可学习的参数为 γ 和 β，使得模型可以学习到恒等映射</li>
<li>作用在<ul>
<li>全连接层和卷积层输出上，激活函数前</li>
<li>全连接层和卷积层输入上</li>
</ul>
</li>
<li>对全连接层，作用在特征维度</li>
<li>对于卷积层，作用在通道维度</li>
</ul>
<p>通过在每个小批量里增加噪音（随机偏移和随机缩放）控制模型复杂度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"><span class="comment"># 定义批量归一化层</span></span><br><span class="line"><span class="comment"># X: 输入</span></span><br><span class="line"><span class="comment"># gamma: 可以学习的缩放参数</span></span><br><span class="line"><span class="comment"># beta: 可以学习的偏移参数</span></span><br><span class="line"><span class="comment"># moving_mean: 整个数据集上的平均的均值</span></span><br><span class="line"><span class="comment"># moving_var: 整个数据集上的平均的方差</span></span><br><span class="line"><span class="comment"># eps: 防止除以0的值</span></span><br><span class="line"><span class="comment"># momentum: 移动平均的动量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_norm</span>(<span class="params">X, gamma, beta, moving_mean, moving_var, eps, momentum</span>)</span><br><span class="line">    <span class="comment"># 通过 is_grad_enabled 函数来判断当前模式是训练还是预测</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> torch.is_grad_enabled():</span><br><span class="line">        <span class="comment"># 如果是在预测模式下，直接使用整个数据集上的的均值和方差</span></span><br><span class="line">        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 如果是在训练模式下，计算当前小批量的均值和方差</span></span><br><span class="line">        <span class="comment"># X.shape = 2 时，计算全连接层的均值和方差</span></span><br><span class="line">        <span class="comment"># X.shape = 4 时，计算卷积层的均值和方差</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(X.shape) <span class="keyword">in</span> (<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X.shape) == <span class="number">2</span>: <span class="comment"># = 2的情况 0就是批量大小 1就是特征数 （全连接）</span></span><br><span class="line">            <span class="comment"># 按行求均值</span></span><br><span class="line">            mean = X.mean(dim=<span class="number">0</span>)</span><br><span class="line">            <span class="comment"># 方差也是1xn的行向量 2d</span></span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(dim=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># = 4的情况 0就是批量大小 1就是通道数 2就是高 3就是宽 （卷积）</span></span><br><span class="line">            <span class="comment"># 按行求均值</span></span><br><span class="line">            mean = X.mean(dim=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">            <span class="comment"># 方差 也是 1xnx1x1 4d</span></span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(dim=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 训练模式下，使用当前小批量的均值和方差做标准化</span></span><br><span class="line">        X_hat = (X - mean) / torch.sqrt(var + eps)</span><br><span class="line">        moving_mean = momentum * moving_mean + (<span class="number">1.0</span> - momentum) * mean</span><br><span class="line">        moving_var = momentum * moving_var + (<span class="number">1.0</span> - momentum) * var</span><br><span class="line">    Y = gamma * X_hat + beta</span><br><span class="line">    <span class="keyword">return</span> Y, moving_mean, moving_var</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 BatchNorm 图层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BatchNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, num_dims</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> num_dims == <span class="number">2</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 可学习的缩放和偏移参数，要不断被迭代的</span></span><br><span class="line">        self.gamma = nn.Parameter(torch.ones(shape))</span><br><span class="line">        self.beta = nn.Parameter(torch.zeros(shape))</span><br><span class="line">        <span class="comment"># 不参与训练的变量</span></span><br><span class="line">        self.moving_mean = torch.zeros(shape)</span><br><span class="line">        self.moving_var = torch.zeros(shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">if</span> self.moving_mean.device != X.device:</span><br><span class="line">            self.moving_mean = self.moving_mean.to(X.device)</span><br><span class="line">            self.moving_var = self.moving_var.to(X.device)</span><br><span class="line">        <span class="comment"># 保存更新过的 moving_mean 和 moving_var</span></span><br><span class="line">        Y, self.moving_mean, self.moving_var = batch_norm(</span><br><span class="line">            X, self.gamma, self.beta, self.moving_mean,</span><br><span class="line">            self.moving_var, eps=<span class="number">1e-5</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">        <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用 BatchNorm 于 卷积神经网络(LeNet) 模型</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>), </span><br><span class="line">    BatchNorm(<span class="number">6</span>, num_dims=<span class="number">4</span>), <span class="comment"># 第一个卷积后增加 BatchNorm 在Sigmoid之前，给定输入的通道数6</span></span><br><span class="line">    nn.Sigmoid(), </span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), </span><br><span class="line">    BatchNorm(<span class="number">16</span>, num_dims=<span class="number">4</span>), <span class="comment"># 第二个卷积后增加 BatchNorm 在Sigmoid之前</span></span><br><span class="line">    nn.Sigmoid(), </span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), </span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">120</span>), </span><br><span class="line">    BatchNorm(<span class="number">120</span>, num_dims=<span class="number">2</span>), <span class="comment"># 在线性层后增加 BatchNorm 在Sigmoid之前，给定输出的通道数120</span></span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), </span><br><span class="line">    BatchNorm(<span class="number">84</span>, num_dims=<span class="number">2</span>), <span class="comment"># 在线性层后增加 BatchNorm 在Sigmoid之前</span></span><br><span class="line">    nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)) <span class="comment"># 输出层不增加</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Fashion-MNIST 数据集上训练带有批量归一化的 卷积神经网络(LeNet)</span></span><br><span class="line">lr, num_epochs, batch_size = <span class="number">1.0</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line">d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拉伸参数 gamma 和偏移参数 beta</span></span><br><span class="line">net[<span class="number">1</span>].gamma.reshape((-<span class="number">1</span>,)), net[<span class="number">1</span>].beta.reshape((-<span class="number">1</span>,))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简明实现</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>), </span><br><span class="line">    nn.BatchNorm2d(<span class="number">6</span>), <span class="comment"># 不需要增加维度，内部自动处理</span></span><br><span class="line">    nn.Sigmoid(), </span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), </span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), </span><br><span class="line">    nn.BatchNorm2d(<span class="number">16</span>), </span><br><span class="line">    nn.Sigmoid(), </span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), </span><br><span class="line">    nn.Flatten(), </span><br><span class="line">    nn.Linear(<span class="number">256</span>, <span class="number">120</span>), </span><br><span class="line">    nn.BatchNorm1d(<span class="number">120</span>), </span><br><span class="line">    nn.Sigmoid(), </span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), </span><br><span class="line">    nn.BatchNorm1d(<span class="number">84</span>), </span><br><span class="line">    nn.Sigmoid(), </span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用相同超参数来训练模型</span></span><br><span class="line">d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</span><br></pre></td></tr></table></figure>

<p>那现在应该使用什么预训练模型能满足需求呢？</p>
<p>训练场景项目的 文件结构是什么样</p>
<h3 id="训练思路"><a href="#训练思路" class="headerlink" title="训练思路"></a>训练思路</h3><h4 id="提问"><a href="#提问" class="headerlink" title="提问"></a>提问</h4><p>我现在对机器学习有一些不理解，我知道大致的学习流程 比如 准备预处理数据集  然后不知道怎么处理数据 后面是开始学习 然后微调 最后得到想要的结果  中间的细节我不太懂</p>
<h4 id="回答"><a href="#回答" class="headerlink" title="回答"></a>回答</h4><ul>
<li>数据收集和预处理：<ul>
<li>收集数据集，包括训练数据、验证数据和测试数据。</li>
<li>数据清洗：处理缺失值、异常值等。</li>
<li>特征工程：选择合适的特征、进行特征变换和提取。</li>
<li>数据标准化或归一化：确保数据在相同的尺度范围内，以提高模型训练的稳定性和收敛速度。</li>
</ul>
</li>
<li>选择合适的模型：<ul>
<li>根据问题类型（分类、回归、聚类等）和数据特点选择合适的模型。</li>
<li>选择模型的结构和参数，可以通过调参、网格搜索等方法来寻找最优的模型配置。</li>
</ul>
</li>
<li>模型训练：<ul>
<li>使用训练数据对模型进行训练。</li>
<li>选择合适的损失函数和优化算法。</li>
<li>监控训练过程中的指标，如损失函数值、准确率等。</li>
</ul>
</li>
<li>模型评估：<ul>
<li>使用验证数据集评估模型的性能，检查模型是否过拟合或欠拟合。</li>
<li>考虑不同的评估指标，如准确率、精确率、召回率、F1 分数等。</li>
</ul>
</li>
<li>模型微调和优化：<ul>
<li>根据验证结果调整模型结构、超参数和优化算法，以进一步提高模型性能。</li>
<li>可以使用交叉验证等技术来确定最优的参数组合。</li>
</ul>
</li>
<li>模型部署和应用：<ul>
<li>使用测试数据对模型进行最终评估。</li>
<li>将模型部署到生产环境中，应用于实际问题解决中。</li>
</ul>
</li>
<li>持续监控和更新：<ul>
<li>监控模型在实际应用中的性能，定期更新模型以适应数据的变化和新的需求。</li>
</ul>
</li>
</ul>
<h3 id="梳理一下第一步-数据收集和预处理的每个细节"><a href="#梳理一下第一步-数据收集和预处理的每个细节" class="headerlink" title="梳理一下第一步 数据收集和预处理的每个细节"></a>梳理一下第一步 数据收集和预处理的每个细节</h3><h4 id="提问-1"><a href="#提问-1" class="headerlink" title="提问"></a>提问</h4><p>我现在计划训练一个能帮助我写代码的机器人</p>
<p>需求和目标如下：</p>
<p>模型是专注于特定编程语言（Html5、css3、php8、Mysql8）<br>其中 php 采用的是 Hyperf3.1 版本基于Swoole的协程框架<br>项目整体采用的Docker-compose 架构<br>模型的应用场景，用于自动生成函数、类、模块、甚至是整个项目的代码。<br>设计模型目标输出：<br>基于自然语言描述自动生成符合需求的<br>函数和类<br>API说明文档<br>数据表<br>除了能根据代码片段生成建议代码，我还要能够正常和ai沟通，让他了解我的需求，从而进一步帮我生成更完善的需求代码<br>我现在的项目预训练数据大概是这种结构(每个结构中都是一个文件夹，内部都是相关的许多文件)：</p>
<p>服务端<br>使用的hyperf3.1基于swoole（PHP的异步、并行、高性能网络通信引擎,支持TCP长连接,Websocket,Mqtt等协议）的php语言框架<br>数据库<br>mysql目前只有一个sql文件。<br>前端代码<br>基于Vue3的JavaScript 框架，包含了sass等   现在可以从php的项目初始化的所有文件开始，你结合一下上面的解答，帮我梳理一下第一步 数据收集和预处理的每个细节</p>
<h4 id="回答-1"><a href="#回答-1" class="headerlink" title="回答"></a>回答</h4><p>第一步是数据收集和预处理，针对您的项目需求，这个步骤可以细分如下：</p>
<ul>
<li>收集预训练数据：<ul>
<li>从您的项目中收集关于 PHP、HTML5、CSS3、MySQL8 的代码片段和相关文档，包括函数、类、模块、API 文档等。</li>
<li>收集关于 Hyperf3.1 和 Docker-compose 架构的相关文档和示例代码。</li>
</ul>
</li>
<li>数据清洗：<ul>
<li>清洗收集到的代码片段和文档，去除无效的、重复的或者不相关的部分。</li>
<li>处理可能存在的缺失值、异常值等问题。</li>
</ul>
</li>
<li>数据标准化或归一化：<ul>
<li>对收集到的数据进行统一的格式处理，确保数据的一致性和可比性。</li>
<li>对代码片段进行标准化，去除不必要的格式差异，使其适合模型训练。</li>
</ul>
</li>
<li>特征工程：<ul>
<li>对收集到的代码片段进行特征提取，包括词频统计、词向量化等方法，以便模型理解和处理。</li>
<li>对文档和注释进行文本处理，提取关键信息和特征，以便模型生成相应的代码片段或文档。</li>
</ul>
</li>
<li>构建预处理数据集：<ul>
<li>将清洗和标准化后的数据组织成适合模型训练的数据集，包括训练数据集、验证数据集和测试数据集。</li>
<li>将数据集保存为适合模型读取的格式，如 JSON、CSV 等。</li>
</ul>
</li>
<li>记录数据预处理过程：<ul>
<li>记录数据预处理的步骤和方法，以便后续复现和调整。</li>
<li>记录数据集的统计信息，如数据量、特征数量等。</li>
</ul>
</li>
<li>数据集管理和版本控制：<ul>
<li>使用版本控制工具管理数据集的版本，确保数据集的一致性和可追溯性。</li>
<li>定期更新数据集，保持数据集的新鲜和有效性。</li>
</ul>
</li>
<li>通过以上步骤，您可以完成数据收集和预处理阶段，为后续模型训练提供高质量的数据基础。</li>
</ul>
<h4 id="对php文件进行处理"><a href="#对php文件进行处理" class="headerlink" title="对php文件进行处理"></a>对php文件进行处理</h4><h5 id="提问-2"><a href="#提问-2" class="headerlink" title="提问"></a>提问</h5><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">给你举个例子 这是.php文件的某个文件 你看一下 如果想要学习的话 需要怎么处理 </span><br><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">declare</span>(strict_types=<span class="number">1</span>);</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This file is part of Hyperf.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@link</span>     https://www.hyperf.io</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@document</span> https://hyperf.wiki</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@contact</span>  group<span class="doctag">@hyperf</span>.io</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@license</span>  https://github.com/hyperf/hyperf/blob/master/LICENSE</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">App</span>\<span class="title">Exception</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">use</span> <span class="title">App</span>\<span class="title">Constants</span>\<span class="title">ErrorCode</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="title">Hyperf</span>\<span class="title">Server</span>\<span class="title">Exception</span>\<span class="title">ServerException</span>;</span><br><span class="line"><span class="keyword">use</span> <span class="title">Throwable</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BusinessException</span> <span class="keyword">extends</span> <span class="title">ServerException</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">__construct</span>(<span class="params"><span class="keyword">int</span> <span class="variable">$code</span> = <span class="number">0</span>, <span class="keyword">string</span> <span class="variable">$message</span> = <span class="literal">null</span>, <span class="built_in">Throwable</span> <span class="variable">$previous</span> = <span class="literal">null</span></span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (is_null(<span class="variable">$message</span>)) &#123;</span><br><span class="line">            <span class="variable">$message</span> = ErrorCode::getMessage(<span class="variable">$code</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">parent</span>::__construct(<span class="variable">$message</span>, <span class="variable">$code</span>, <span class="variable">$previous</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="回答-2"><a href="#回答-2" class="headerlink" title="回答"></a>回答</h5><p>下面是对这个 PHP 文件进行预处理的一般步骤：</p>
<ul>
<li>去除注释和文档注释： 通常代码中包含了大量的注释，但是这些注释对于模型的训练来说可能并不重要，因此可以选择去除注释部分，只保留代码。</li>
<li>分词或分割代码： 将代码分割成单词或标记，这样可以更容易地处理和理解代码结构。在 PHP 中，可以根据空格、分号、括号等符号进行分割。</li>
<li>处理命名空间和引用： 在这个例子中，可以将命名空间 namespace App\Exception; 和 use 声明语句 use App\Constants\ErrorCode; 进行处理，可能需要将它们转换成相应的标记或特殊表示形式。</li>
<li>特殊字符处理： 有些特殊字符可能需要进行特殊处理，例如 :, -&gt;, :: 等符号在代码中具有特殊含义，需要注意处理。</li>
<li>将代码转换成数字表示： 最终，将预处理后的代码转换成模型可以理解的数字表示，例如使用词嵌入或字符嵌入进行编码。</li>
<li>数据序列化和保存： 将预处理后的数据序列化并保存到文件中，以便后续模型的训练和使用。</li>
</ul>
<h3 id="数据集收集和处理训练数据"><a href="#数据集收集和处理训练数据" class="headerlink" title="数据集收集和处理训练数据"></a>数据集收集和处理训练数据</h3><blockquote>
<p>收集大量源代码作为训练数据，可以是从开源项目中爬取的代码片段或完整的项目。<br>对这些源代码进行标注或构建对应的自然语言描述（如果适用），形成输入-输出对（NL-code pairs）。</p>
</blockquote>
<p>Q:对于数据代码，我只有例如Html5、css3、php8、Mysql8等语言而定项目代码 怎么办</p>
<ul>
<li>PHP（hyperf3.1基于swoole）<ul>
<li>提取注释<ul>
<li>使用正则表达式或解析器来提取PHP文件中的注释作为自然语言描述。</li>
<li>将注释与其对应的代码片段（函数、类或方法）组合成训练数据。</li>
</ul>
</li>
<li>自动生成描述<ul>
<li>使用自然语言生成（NLG）技术为PHP文件自动生成自然语言描述。</li>
</ul>
</li>
</ul>
</li>
<li>Mysql<ul>
<li>提取MySQL SQL文件中的注释作为自然语言描述。</li>
<li>将注释与其对应的SQL语句或数据模型组合成训练数据。</li>
</ul>
</li>
<li>前端代码（Vue3 + JavaScript + Sass等）<ul>
<li>提取注释<ul>
<li>提取Vue文件、JavaScript文件和Sass文件中的注释作为自然语言描述。</li>
<li>将注释与其对应的代码片段（组件、函数、样式等）组合成训练数据。</li>
</ul>
</li>
<li>自动生成描述<ul>
<li>使用自然语言生成（NLG）技术为Vue文件、JavaScript文件和Sass文件自动生成自然语言描述。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Q:模型能够运行对应的语言环境达到理解和测试代码吗？</p>
<ul>
<li>可以将训练好的模型集成到代码生成器或辅助工具中，以帮助理解和生成代码</li>
</ul>
<p>我现在准备采用 Transformer 架构，T5模型作为基础预训练模型<br>如何对我现有的数据进行预处理，如何将代码片段和对应的自然语言描述配对，并进行标记化、分词等处理？</p>
<p>我找到了 一个 php的数据集Card 里面似乎是 php的使用文档 包括所有的内置方法 参数 变量使用说明等等 这个对我的需求有帮助吗</p>
<p>帮我寻找一些 和我这个需求符合的 已有数据集Card，能够直接用</p>
<p>找到的数据集：php</p>
<ul>
<li>框架核心架构<ul>
<li>运行在 Swoole 5 的协程和 Swow 协程之上</li>
<li>协程<ul>
<li>配置<ul>
<li>配置文件结构   <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">config</span><br><span class="line">├── autoload <span class="regexp">//</span> 此文件夹内的配置文件会被配置组件自己加载，并以文件夹内的文件名作为第一个键值</span><br><span class="line">│   ├── amqp.php  <span class="regexp">//</span> 用于管理 AMQP 组件</span><br><span class="line">│   ├── annotations.php <span class="regexp">//</span> 用于管理注解</span><br><span class="line">│   ├── apollo.php <span class="regexp">//</span> 用于管理基于 Apollo 实现的配置中心</span><br><span class="line">│   ├── aspects.php <span class="regexp">//</span> 用于管理 AOP 切面</span><br><span class="line">│   ├── async_queue.php <span class="regexp">//</span> 用于管理基于 Redis 实现的简易队列服务</span><br><span class="line">│   ├── cache.php <span class="regexp">//</span> 用于管理缓存组件</span><br><span class="line">│   ├── commands.php <span class="regexp">//</span> 用于管理自定义命令</span><br><span class="line">│   ├── consul.php <span class="regexp">//</span> 用于管理 Consul 客户端</span><br><span class="line">│   ├── databases.php <span class="regexp">//</span> 用于管理数据库客户端</span><br><span class="line">│   ├── dependencies.php <span class="regexp">//</span> 用于管理 DI 的依赖关系和类对应关系</span><br><span class="line">│   ├── devtool.php <span class="regexp">//</span> 用于管理开发者工具</span><br><span class="line">│   ├── exceptions.php <span class="regexp">//</span> 用于管理异常处理器</span><br><span class="line">│   ├── listeners.php <span class="regexp">//</span> 用于管理事件监听者</span><br><span class="line">│   ├── logger.php <span class="regexp">//</span> 用于管理日志</span><br><span class="line">│   ├── middlewares.php <span class="regexp">//</span> 用于管理中间件</span><br><span class="line">│   ├── opentracing.php <span class="regexp">//</span> 用于管理调用链追踪</span><br><span class="line">│   ├── processes.php <span class="regexp">//</span> 用于管理自定义进程</span><br><span class="line">│   ├── redis.php <span class="regexp">//</span> 用于管理 Redis 客户端</span><br><span class="line">│   └── server.php <span class="regexp">//</span> 用于管理 Server 服务</span><br><span class="line">├── config.php <span class="regexp">//</span> 用于管理用户或框架的配置，如配置相对独立亦可放于 autoload 文件夹内</span><br><span class="line">├── container.php <span class="regexp">//</span> 负责容器的初始化，作为一个配置文件运行并最终返回一个 Psr\Container\ContainerInterface 对象</span><br><span class="line">└── routes.php <span class="regexp">//</span> 用于管理路由</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>注解</li>
<li>依赖注入</li>
<li>事件机制</li>
</ul>
</li>
<li>基础功能<ul>
<li>路由</li>
<li>中间件</li>
<li>控制器</li>
<li>请求</li>
<li>响应</li>
<li>异常处理</li>
<li>缓存</li>
<li>日志</li>
<li>分页器</li>
<li>命令行</li>
<li>自动化测试</li>
<li>视图</li>
<li>视图引擎</li>
<li>国际化</li>
<li>验证器</li>
<li>Session会话管理</li>
<li>文件系统</li>
</ul>
</li>
<li>数据库模型</li>
<li>客户端</li>
<li>消息队列</li>
<li>其他组件<ul>
<li>连接池</li>
<li>自定义进程</li>
<li>辅助类</li>
<li>定时任务</li>
<li>Task机制</li>
<li>枚举类</li>
<li>信号处理器</li>
<li>ReactiveX</li>
<li>Watcher</li>
<li>Phar打包器</li>
</ul>
</li>
<li>应用部署<ul>
<li>DockerSwarm集群搭建</li>
<li>DaoCloudDevops搭建</li>
<li>Supervisor部署</li>
<li>Nginx反向代理</li>
<li>阿里云日志服务</li>
</ul>
</li>
</ul>
<p>站在神经网络深度学习的角度上，帮我将hyperf3.1框架（文档网站<a href="https://hyperf.wiki/3.1%EF%BC%89%E6%95%B4%E7%90%86%E6%88%90%E5%8F%AF%E4%BB%A5%E5%81%9A%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%A0%BC%E5%BC%8F%EF%BC%8C%E5%86%85%E5%AE%B9%E6%98%AF%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84%E3%80%81%E5%9F%BA%E7%A1%80%E5%8A%9F%E8%83%BD%E3%80%81%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A8%A1%E5%9E%8B%E3%80%81%E5%AE%A2%E6%88%B7%E7%AB%AF%E3%80%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E3%80%81%E5%85%B6%E4%BB%96%E7%BB%84%E4%BB%B6%E3%80%81%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E7%AD%89%E7%AD%89" target="_blank" rel="noopener">https://hyperf.wiki/3.1）整理成可以做成数据集的格式，内容是框架的核心架构、基础功能、数据库模型、客户端、消息队列、其他组件、应用部署等等</a></p>
<p>这些就可以让神经网络深度学习进行学习了是吗</p>
<p>ok，你先帮我整理hyperf3.1框架（文档网站<a href="https://hyperf.wiki/3.1%EF%BC%89" target="_blank" rel="noopener">https://hyperf.wiki/3.1）</a> 核心架构一章所有重要的数据集，不需向我解释，直接写JSON</p>
<h2 id="Download模型"><a href="#Download模型" class="headerlink" title="Download模型"></a>Download模型</h2><blockquote>
<p><a href="https://hf-mirror.com/" target="_blank" rel="noopener">https://hf-mirror.com/</a> 使用镜像源 + 迅雷下载 token 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</p>
</blockquote>
<p>huggingface-cli download –token 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 –resume-download google&#x2F;gemma-7b –local-dir Z:\web\code_assistant\models\other\google-gemma-7b</p>
<h2 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h2><p>下载模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># export HF_HUB_ENABLE_HF_TRANSFER=1  # For Linux/macOS</span></span><br><span class="line"><span class="comment"># set HF_HUB_ENABLE_HF_TRANSFER=1     # For Windows (Command Prompt)</span></span><br><span class="line"><span class="comment"># huggingface-cli download --resume-download deepseek-ai/deepseek-coder-33b-instruct --local-dir models/other/deepseek-ai/deepseek-coder-33b-instruct</span></span><br></pre></td></tr></table></figure>

<h2 id="课程"><a href="#课程" class="headerlink" title="课程"></a>课程</h2><h3 id="Approaching-Almost-Any-NLP-Problem"><a href="#Approaching-Almost-Any-NLP-Problem" class="headerlink" title="Approaching (Almost) Any NLP Problem"></a>Approaching (Almost) Any NLP Problem</h3><blockquote>
<p>下载 Datasets 数据集 <a href="https://www.kaggle.com/datasets/abhishek/aaamlp/code" target="_blank" rel="noopener">https://www.kaggle.com/datasets/abhishek/aaamlp/code</a></p>
</blockquote>
<h4 id="有监督和无监督学习"><a href="#有监督和无监督学习" class="headerlink" title="有监督和无监督学习"></a>有监督和无监督学习</h4><p>在处理机器学习问题时，通常有两类数据：</p>
<ul>
<li>监督数据：通过有标签的数据训练模型，然后进行推理<ul>
<li>分类：预测类别，如猫或狗</li>
<li>回归：预测数值，如房价</li>
<li>…</li>
</ul>
</li>
<li>无监督数据：在没有标签的情况下，试图从数据中发现隐藏的结构或模式，然后进行推理<ul>
<li>聚类：将数据样本分组成具有相似特征的集合，以便更好地理解数据的内在结构和性质。聚类常被用于数据探索、模式发现以及在预处理阶段为其他机器学习任务提供有用的特征。</li>
<li>…</li>
</ul>
</li>
</ul>
<p>处理无监督问题时，首先要将数据分为n个聚类。</p>
<p>进而使用 <code>聚类算法</code> 解决无监督问题.</p>
<p>为了理解无监督问题，我们还需要了解 <code>降维和特征提取(分解)技术</code>：</p>
<ul>
<li>主成分分析（PCA）<ul>
<li>主要用于数据的降维。它试图找到数据中最重要的方向，以尽可能保留原始数据中的方差，同时减少数据的维度。PCA通常用于探索性数据分析和特征提取，也可用于数据压缩和去噪。</li>
</ul>
</li>
<li>独立成分分析（Independent Component Analysis，ICA）：<ul>
<li>用于从混合信号中分离出统计独立的成分，通常用于信号处理和脑电图（EEG）数据分析。</li>
</ul>
</li>
<li>t-分布随机邻域嵌入（t-SNE）<ul>
<li>用于数据的可视化。它可以将高维数据映射到二维或三维空间，以便直观地展示数据的结构和关系。t-SNE通常用于探索性数据分析、聚类验证和分类问题的可视化。</li>
</ul>
</li>
<li>因子分析（Factor Analysis）<ul>
<li>用于发现数据中的潜在变量或因素，通过将观察到的变量表示为潜在因素的线性组合。</li>
</ul>
</li>
</ul>
<p>实验对象：MNIST数据集（图像0123456789）</p>
<p>进行 t 分布随机邻域嵌入（t-SNE）分解，将数据降维到2个维度，就可以在一定程度上分离图像</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 matplotlib 和 seaborn 进行绘图</span></span><br><span class="line"><span class="comment"># 使用 numpy 处理数值数组</span></span><br><span class="line"><span class="comment"># 使用 pandas 从数值数组创建数据帧</span></span><br><span class="line"><span class="comment"># 使用 scikit-learn (sklearn) 获取数据并执行 t-SNE。</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> manifold</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载数据并单独读取，或者使用 sklearn 的内置函数来提供 MNIST 数据集。</span></span><br><span class="line">data = datasets.fetch_openml(<span class="string">&#x27;mnist_784&#x27;</span>, version=<span class="number">1</span>, return_X_y=<span class="literal">True</span>, parser=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pixel_values 是一个形状为 70000x784 的二维数组。 共有 70000 张不同的图像，每张图像大小为 28x28 像素。平铺 28x28 后得到 784 个数据点。</span></span><br><span class="line">pixel_values, targets = data</span><br><span class="line">pixel_values = np.array(pixel_values)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上面获得了一个像素值数组和另一个目标数组。由于目标是字符串类型，我们将其转换为整数。</span></span><br><span class="line">targets = targets.astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将该数据集中的样本重塑为原来的形状，然后使用 matplotlib 绘制成图表，从而将其可视化。</span></span><br><span class="line">single_image = pixel_values[<span class="number">1</span>, :].reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">plt.imshow(single_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建了数据的 t-SNE 变换。只使用 2 个维度，因为在二维环境中可以很好地将它们可视化。在本例中，转换后的数据是一个 3000x2 形状的数组（3000 行 2 列）。在数组上调用 pd.DataFrame 可以将这样的数据转换为 pandas 数据帧。</span></span><br><span class="line">tsne = manifold.TSNE(n_components=<span class="number">2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">transformed_data = tsne.fit_transform(pixel_values[:<span class="number">3000</span>, :])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从一个 numpy 数组创建一个 pandas 数据帧。x 和 y 是 t-SNE 分解的两个维度，target 是实际数字。</span></span><br><span class="line">tsne_df = pd.DataFrame(np.column_stack((transformed_data, targets[:<span class="number">3000</span>])),</span><br><span class="line">                       columns=[<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;targets&quot;</span>])</span><br><span class="line">tsne_df.loc[:, <span class="string">&quot;targets&quot;</span>] = tsne_df.targets.astype(<span class="built_in">int</span>)</span><br><span class="line"><span class="built_in">print</span>(tsne_df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后，可以使用 seaborn 和 matplotlib 绘制它。</span></span><br><span class="line">grid = sns.FacetGrid(tsne_df, hue=<span class="string">&quot;targets&quot;</span>, height=<span class="number">8</span>)</span><br><span class="line">grid.<span class="built_in">map</span>(plt.scatter, <span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>).add_legend()</span><br></pre></td></tr></table></figure>

<div>
                <img src="p/614a8113/tsne_df.png" alt="tsne_df数据帧" height="300px" width="400px"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[tsne_df数据帧]</p>
            </div>

<div>
                <img src="p/614a8113/进行t分布随机邻域嵌入（t-SNE）分解，将数据降维到2个维度，就可以在一定程度上分离图像.png" alt="进行t分布随机邻域嵌入（t-SNE）分解，将数据降维到2个维度，就可以在一定程度上分离图像"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[进行t分布随机邻域嵌入（t-SNE）分解，将数据降维到2个维度，就可以在一定程度上分离图像]</p>
            </div>

<p>这是无监督数据集可视化的一种方法。我们还可以在同一数据集上进行 k-means 聚类，看看它在无监督环境下的表现如何。</p>
<p>一个经常出现的问题是，如何在 k-means 聚类中找到最佳的簇数。这个问题没有正确答案。你必须通过交叉验证来找到最佳簇数。</p>
<h4 id="交叉检验"><a href="#交叉检验" class="headerlink" title="交叉检验"></a>交叉检验</h4><blockquote>
<p>建立模型的步骤之一，确保模型准确拟合数据,同时确保我们不会过拟合。</p>
</blockquote>
<p>测试数据集：红酒质量数据集（red wine quality dataset）</p>
<p>数据集中有11个特征，共同决定了红酒的质量</p>
<ul>
<li>固定酸度（fixed acidity）</li>
<li>挥发性酸度（volatile acidity）</li>
<li>柠檬酸（citric acid）</li>
<li>残留糖（residual sugar）</li>
<li>氯化物（chlorides）</li>
<li>游离二氧化硫（free sulfur dioxide）</li>
<li>二氧化硫总量（total sulfur dioxide）</li>
<li>密度（density）</li>
<li>PH 值（pH）</li>
<li>硫酸盐（sulphates）</li>
<li>酒精（alcohol）</li>
</ul>
<p>根据这些特征，现在需要预测红葡萄酒的质量，质量值介于 0 到 10 之间。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;winequality-red.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>可以将这个问题视为 分类问题，也可以视为 回归问题</p>
<p>简单起见，选择分类</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个映射字典，用于将质量值从 0 到 5 进行映射</span></span><br><span class="line">quality_mapping = &#123;</span><br><span class="line"> <span class="number">3</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="number">4</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="number">5</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="number">6</span>: <span class="number">3</span>,</span><br><span class="line"> <span class="number">7</span>: <span class="number">4</span>,</span><br><span class="line"> <span class="number">8</span>: <span class="number">5</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 你可以使用 pandas 的 map 函数以及任何字典，</span></span><br><span class="line"><span class="comment"># 来转换给定列中的值为字典中的值</span></span><br><span class="line">df.loc[:, <span class="string">&quot;quality&quot;</span>] = df.quality.<span class="built_in">map</span>(quality_mapping)</span><br></pre></td></tr></table></figure>

<h4 id="分类变量"><a href="#分类变量" class="headerlink" title="分类变量"></a>分类变量</h4><p>两种类型</p>
<ul>
<li>无序变量(名义变量)<ul>
<li>它们的不同取值之间没有没有顺序或等级，例如 <code>性别（男性、女性）</code></li>
</ul>
</li>
<li>有序变量<ul>
<li>它们的不同取值之间存在一定的顺序关系，例如 <code>教育水平（小学、初中、高中、大学）</code> <code>周数（周一、周二、周三、周四、周五、周六、周日）</code></li>
</ul>
</li>
</ul>
<p>数据集由各种分类变量组成</p>
<ul>
<li>无序</li>
<li>有序</li>
<li>循环</li>
<li>二元</li>
</ul>
<blockquote>
<p>下载 数据集 <a href="https://www.kaggle.com/competitions/cat-in-the-dat-ii/data" target="_blank" rel="noopener">https://www.kaggle.com/competitions/cat-in-the-dat-ii/data</a> </p>
</blockquote>
<p>该数据集中总体而言，有：</p>
<ul>
<li>5个二元变量</li>
<li>10个无序变量</li>
<li>6个有序变量</li>
<li>2个循环变量</li>
<li>1个目标变量</li>
</ul>
<h5 id="标签编码"><a href="#标签编码" class="headerlink" title="标签编码"></a>标签编码</h5><blockquote>
<p>将类别型数据转换为整数型数据</p>
</blockquote>
<p>计算机无法理解文本数据，所以需要将这些类别转换为数字，简单的办法是转换为字典</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 映射字典</span></span><br><span class="line">mapping = &#123;</span><br><span class="line"><span class="string">&quot;Freezing&quot;</span>: <span class="number">0</span>, </span><br><span class="line"><span class="string">&quot;Warm&quot;</span>: <span class="number">1</span>, </span><br><span class="line"><span class="string">&quot;Cold&quot;</span>: <span class="number">2</span>,</span><br><span class="line"><span class="string">&quot;Boiling Hot&quot;</span>: <span class="number">3</span>, </span><br><span class="line"><span class="string">&quot;Hot&quot;</span>: <span class="number">4</span>,</span><br><span class="line"><span class="string">&quot;Lava Hot&quot;</span>: <span class="number">5</span> </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>) </span><br><span class="line"><span class="comment"># 取ord_2列，并使用映射将类别转换为数字</span></span><br><span class="line">df.loc[:, <span class="string">&quot;ord_2&quot;</span>] = df.ord_2.<span class="built_in">map</span>(mapping)</span><br></pre></td></tr></table></figure>

<p>使用 scikit-learn 中的 LabelEncoder 进行编码</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing </span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>) </span><br><span class="line"><span class="comment"># 将缺失值填充为&quot;NONE&quot;</span></span><br><span class="line">df.loc[:, <span class="string">&quot;ord_2&quot;</span>] = df.ord_2.fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line"><span class="comment"># LabelEncoder编码</span></span><br><span class="line">lbl_enc = preprocessing.LabelEncoder()</span><br><span class="line"><span class="comment"># 转换数据</span></span><br><span class="line">df.loc[:, <span class="string">&quot;ord_2&quot;</span>] = lbl_enc.fit_transform(df.ord_2.values)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>对于这些类型的模型，可以对数据进行二值化处理</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Freezing    --&gt; <span class="number">0</span> --&gt; <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">Warm        --&gt; <span class="number">1</span> --&gt; <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> </span><br><span class="line">Cold        --&gt; <span class="number">2</span> --&gt; <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> </span><br><span class="line">Boiling Hot --&gt; <span class="number">3</span> --&gt; <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> </span><br><span class="line">Hot         --&gt; <span class="number">4</span> --&gt; <span class="number">1</span> <span class="number">0</span> <span class="number">0</span> </span><br><span class="line">Lava Hot    --&gt; <span class="number">5</span> --&gt; <span class="number">1</span> <span class="number">0</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>这只是将类别转换为数字，然后再转换为二值化表示。</p>
<p>但是如果用稀疏格式存储大量二值化变量，就可以轻松存储</p>
<h5 id="稀疏矩阵"><a href="#稀疏矩阵" class="headerlink" title="稀疏矩阵"></a>稀疏矩阵</h5><blockquote>
<p>只是一种存储方式，它并不会对数据的类型进行转换或处理，用于表示大多数元素为零的矩阵，能够有效地节省内存空间。它只包含非零元素，而其他元素为零。</p>
</blockquote>
<p>我们将数据进行数值化步骤：</p>
<ul>
<li>定义特征</li>
<li>对数据二值化处理 01存储</li>
<li>稀疏矩阵转矩阵 只存储<code>非零元素的位置</code>和<code>值</code></li>
</ul>
<p>numpy数组简单实现</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line"></span><br><span class="line">example = np.array(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    ] </span><br><span class="line">)</span><br><span class="line">sparse_example = sparse.csr_matrix(example)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sparse_example.data.nbytes)</span><br><span class="line"><span class="comment"># Out: 32字节</span></span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 稀疏 csr 矩阵的总大小是三个值的总和</span></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    sparse_example.data.nbytes +</span><br><span class="line">    sparse_example.indptr.nbytes +</span><br><span class="line">    sparse_example.indices.nbytes </span><br><span class="line">)</span><br><span class="line"><span class="comment"># Out:64</span></span><br></pre></td></tr></table></figure>


<p>当我们有更大的数组，差异会很大，例子：基于计数特征的文本数据集</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line">n_rows = <span class="number">10000</span></span><br><span class="line">n_cols = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成符合伯努利分布的随机数组，维度为[10000, 100000]</span></span><br><span class="line">example = np.random.binomial(<span class="number">1</span>, p=<span class="number">0.05</span>, size=(n_rows, n_cols))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of dense array: <span class="subst">&#123;example.nbytes&#125;</span>&quot;</span>) </span><br><span class="line"><span class="comment"># 将随机矩阵转换为稀疏矩阵</span></span><br><span class="line">sparse_example = sparse.csr_matrix(example)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of sparse array: <span class="subst">&#123;sparse_example.data.nbytes&#125;</span>&quot;</span>) </span><br><span class="line">full_size = (</span><br><span class="line">    sparse_example.data.nbytes +</span><br><span class="line">    sparse_example.indptr.nbytes +</span><br><span class="line">    sparse_example.indices.nbytes </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Full size of sparse array: <span class="subst">&#123;full_size&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Out:</span></span><br><span class="line">Size of dense array: <span class="number">8000000000</span></span><br><span class="line">Size of sparse array: <span class="number">400050632</span></span><br><span class="line">Full size of sparse array: <span class="number">600115952</span></span><br><span class="line">密集阵列需要 ~8000MB 或大约 8GB 内存。而稀疏阵列只占用 399MB 内存。</span><br></pre></td></tr></table></figure>

<p>还有一种分类变量 可以进行转换，就是独热编码</p>
<h5 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h5><blockquote>
<p>将类别型数据转换为向量形式，包含0和1（只有对应类别的位置为1，其他位置都为0）<br>独热向量的数量&#x3D;样本特征的数量</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse </span><br><span class="line">example = np.array( </span><br><span class="line">    [</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    ] </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of dense array: <span class="subst">&#123;example.nbytes&#125;</span>&quot;</span>) </span><br><span class="line">sparse_example = sparse.csr_matrix(example)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of sparse array: <span class="subst">&#123;sparse_example.data.nbytes&#125;</span>&quot;</span>) </span><br><span class="line">full_size = (</span><br><span class="line">    sparse_example.data.nbytes +</span><br><span class="line">    sparse_example.indptr.nbytes +</span><br><span class="line">    sparse_example.indices.nbytes </span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Full size of sparse array: <span class="subst">&#123;full_size&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Out:</span></span><br><span class="line">Size of dense array: <span class="number">144</span> <span class="comment"># 密集矩阵内存大小</span></span><br><span class="line">Size of sparse array: <span class="number">24</span> <span class="comment"># 稀疏矩阵data数组的大小</span></span><br><span class="line">Full size of sparse array: <span class="number">52</span> <span class="comment"># 稀疏数组完整内存大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 总结：密集矩阵内存大小 &gt; 稀疏数组完整内存大小</span></span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 大数据集例子</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成符合均匀分布的随机整数，维度为[1000000, 10000000]</span></span><br><span class="line">example = np.random.randint(<span class="number">1000</span>, size=<span class="number">1000000</span>)</span><br><span class="line"><span class="comment"># 独热编码，非稀疏矩阵</span></span><br><span class="line">ohe = preprocessing.OneHotEncoder(sparse_output=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 将随机数组展平</span></span><br><span class="line">ohe_example = ohe.fit_transform(example.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of dense array: <span class="subst">&#123;ohe_example.nbytes&#125;</span>&quot;</span>) </span><br><span class="line"><span class="comment"># 独热编码，稀疏矩阵</span></span><br><span class="line">ohe = preprocessing.OneHotEncoder(sparse_output=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 将随机数组展平</span></span><br><span class="line">ohe_example = ohe.fit_transform(example.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of sparse array: <span class="subst">&#123;ohe_example.data.nbytes&#125;</span>&quot;</span>) </span><br><span class="line">full_size = (</span><br><span class="line">    ohe_example.data.nbytes +</span><br><span class="line">    ohe_example.indptr.nbytes + </span><br><span class="line">    ohe_example.indices.nbytes </span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Full size of sparse array: <span class="subst">&#123;full_size&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Out:</span></span><br><span class="line">Size of dense array: <span class="number">8000000000</span> <span class="comment"># 密集矩阵内存大小</span></span><br><span class="line">Size of sparse array: <span class="number">8000000</span> <span class="comment"># 稀疏矩阵data数组的大小</span></span><br><span class="line">Full size of sparse array: <span class="number">16000004</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 密集矩阵内存大小 &gt;  稀疏数组完整内存大小</span></span><br></pre></td></tr></table></figure>

<p>要处理NaN值</p>
<ul>
<li>丢弃</li>
<li>作为全新的类别</li>
</ul>
<p>作为全新的类别代码填充 df.ord_2.fillna(“NONE”)</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing </span><br><span class="line"><span class="comment"># 读取训练集</span></span><br><span class="line">train = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>) </span><br><span class="line"><span class="comment"># 读取测试集</span></span><br><span class="line">test = pd.read_csv(<span class="string">&quot;../input/cat_test.csv&quot;</span>) </span><br><span class="line"><span class="comment"># 将测试集&quot;target&quot;列全部置为-1</span></span><br><span class="line">test.loc[:, <span class="string">&quot;target&quot;</span>] = -<span class="number">1</span></span><br><span class="line"><span class="comment"># 将训练集、测试集沿行拼接</span></span><br><span class="line">data = pd.concat([train, test]).reset_index(drop=<span class="literal">True</span>) </span><br><span class="line"><span class="comment"># 将除&quot;id&quot;和&quot;target&quot;列的其他特征列名取出</span></span><br><span class="line">features = [x <span class="keyword">for</span> x <span class="keyword">in</span> train.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>]] </span><br><span class="line"><span class="comment"># 遍历特征</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> features:</span><br><span class="line">    <span class="comment"># 标签编码</span></span><br><span class="line">    lbl_enc = preprocessing.LabelEncoder()</span><br><span class="line">    <span class="comment"># 将空值替换为&quot;NONE&quot;,并将该列格式变为str</span></span><br><span class="line">    temp_col = data[feat].fillna(<span class="string">&quot;NONE&quot;</span>).astype(<span class="built_in">str</span>).values </span><br><span class="line">    <span class="comment"># 转换数值</span></span><br><span class="line">    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据&quot;target&quot;列将训练集与测试集分开</span></span><br><span class="line">train = data[data.target != -<span class="number">1</span>].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">test = data[data.target == -<span class="number">1</span>].reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>如果在生产环境中，会出现偶发性的 没有任何值的 NaN，模型管道会抛出错误。</p>
<p>解决方案：创建 罕见类别<br>定义一个稀有值的要求：计数&lt;2000</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df.ord_4 = df.ord_4.fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">df.loc[</span><br><span class="line">  df[<span class="string">&quot;ord_4&quot;</span>].value_counts()[df[<span class="string">&quot;ord_4&quot;</span>]].values &lt; <span class="number">2000</span>,</span><br><span class="line">  <span class="string">&quot;ord_4&quot;</span></span><br><span class="line">] = <span class="string">&quot;RARE&quot;</span></span><br><span class="line"><span class="built_in">print</span>(df.ord_4.value_counts())</span><br></pre></td></tr></table></figure>

<p>构建任何类型的模型之前，交叉检验至关重要，已经观察到 <code>标签/目标分布</code>,，这是一个目标偏斜的二元分类问题，so，使用 StratifiedKFold 分割数据</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 读取数据文件</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 添加&quot;kfold&quot;列，并置为-1</span></span><br><span class="line">    df[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 打乱数据顺序，重置索引</span></span><br><span class="line">    df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 将目标列取出</span></span><br><span class="line">    y = df.target.values</span><br><span class="line">    <span class="comment"># 分层k折交叉检验</span></span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">for</span> f, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=df, y=y)): </span><br><span class="line">        <span class="comment"># 区分折叠</span></span><br><span class="line">        df.loc[v_, <span class="string">&#x27;kfold&#x27;</span>] = f</span><br><span class="line">    <span class="comment"># 保存文件</span></span><br><span class="line">    df.to_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>检查新的折叠 csv，查看每个折叠的样本数</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(df.kfold.value_counts())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Out[X]:  所有折叠都有 120000 个样本。因为训练数据有 600000 个样本，而我们做了5次折叠。</span></span><br><span class="line"><span class="number">4</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">3</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">2</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">1</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">0</span>   <span class="number">120000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还可以检查每个折叠的目标分布</span></span><br><span class="line"><span class="built_in">print</span>(df[df.kfold==<span class="number">0</span>].target.value_counts())</span><br><span class="line"><span class="comment"># Out[X]:</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df[df.kfold==<span class="number">1</span>].target.value_counts())</span><br><span class="line"><span class="comment"># Out[X]:</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df[df.kfold==<span class="number">2</span>].target.value_counts())</span><br><span class="line"><span class="comment"># Out[X]:</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df[df.kfold==<span class="number">3</span>].target.value_counts())</span><br><span class="line"><span class="comment"># Out[X]:</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df[df.kfold==<span class="number">4</span>].target.value_counts())</span><br><span class="line"><span class="comment"># Out[X]:</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以看到，在每个折叠后，目标的分布都是一样的，可以是相似，并不一定要相同。<br>现在建立模型时，每个折叠中的标签分布都会相同</p>
<p>建立最简单的模型之一 对所有数据进行 独热编码 并使用 <code>逻辑回归</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    <span class="comment"># 读取分层k折交叉检验数据</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 取除&quot;id&quot;, &quot;target&quot;, &quot;kfold&quot;外的其他特征列</span></span><br><span class="line">    features = [</span><br><span class="line">        f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>) </span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 遍历特征列表</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 将空值置为&quot;NONE&quot;</span></span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">    <span class="comment"># 取训练集（kfold列中不为fold的样本，重置索引）</span></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    <span class="comment"># 取验证集（kfold列中为fold的样本，重置索引）</span></span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    <span class="comment"># 独热编码</span></span><br><span class="line">    ohe = preprocessing.OneHotEncoder()</span><br><span class="line">    <span class="comment"># 将训练集、验证集沿行合并</span></span><br><span class="line">    full_data = pd.concat([df_train[features], df_valid[features]], axis=<span class="number">0</span>)</span><br><span class="line">    ohe.fit(full_data[features])</span><br><span class="line">    <span class="comment"># 转换训练集</span></span><br><span class="line">    x_train = ohe.transform(df_train[features])</span><br><span class="line">    <span class="comment"># 转换测试集</span></span><br><span class="line">    x_valid = ohe.transform(df_valid[features])</span><br><span class="line">    <span class="comment"># 逻辑回归</span></span><br><span class="line">    model = linear_model.LogisticRegression()</span><br><span class="line">    <span class="comment"># 使用训练集训练模型</span></span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    <span class="comment"># 使用验证集得到预测标签</span></span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    <span class="comment"># 计算auc指标</span></span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(auc)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行折叠0</span></span><br><span class="line">    run(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>上面创建了函数，将数据分为 <code>训练</code> 和 <code>验证</code> 两部分，给定折叠数，处理 NaN 值，对所有数据进行单次编码，并训练一个简单的逻辑回归模型。</p>
<p>运行代码</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">❯ python ohe_logres.py</span><br><span class="line">/home/abhishek/miniconda3/envs/ml/lib/python3<span class="number">.7</span>/site-</span><br><span class="line">packages/sklearn/linear_model/_logistic.py:<span class="number">939</span>: ConvergenceWarning: lbfgs </span><br><span class="line">failed to converge (status=<span class="number">1</span>):</span><br><span class="line">STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.</span><br><span class="line">Increase the number of iterations (max_iter) <span class="keyword">or</span> scale the data <span class="keyword">as</span> shown </span><br><span class="line"><span class="keyword">in</span>:</span><br><span class="line">    https://scikit-learn.org/stable/modules/preprocessing.html.</span><br><span class="line">Please also refer to the documentation <span class="keyword">for</span> alternative solver options: </span><br><span class="line">    https://scikit-learn.org/stable/modules/linear_model.html<span class="comment">#logistic-</span></span><br><span class="line">regression</span><br><span class="line">extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)</span><br><span class="line"><span class="number">0.7847865042255127</span></span><br></pre></td></tr></table></figure>

<p>有一些警告，<code>逻辑回归</code> 似乎没有 <code>收敛到最大迭代次数</code>，因为还没有调整参数，可以看到 AUC 是0.785</p>
<p>fix 代码</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">#...</span></span><br><span class="line">    model = linear_model.LogisticRegression()</span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 循环运行0~4折</span></span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">        run(fold_)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行代码 -W 忽略警告</span></span><br><span class="line">python -W ignore ohe_logres.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Result</span></span><br><span class="line">Fold = 0, AUC = 0.7847865042255127</span><br><span class="line">Fold = 1, AUC = 0.7853553605899214</span><br><span class="line">Fold = 2, AUC = 0.7879321942914885</span><br><span class="line">Fold = 3, AUC = 0.7870315929550808 </span><br><span class="line">Fold = 4, AUC = 0.7864668243125608</span><br></pre></td></tr></table></figure>

<p>开始使用 基于 树的模型，比如随机森林。</p>
<p>应用随机森林时，可以使用标签编码，将每一列中的每个特征都转换为整数，而不是独热编码，因为没太大区别</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 标签编码</span></span><br><span class="line">        lbl = preprocessing.LabelEncoder()</span><br><span class="line">        lbl.fit(df[col])</span><br><span class="line">        df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    x_train = df_train[features].values</span><br><span class="line">    x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># 随机森林模型</span></span><br><span class="line">    model = ensemble.RandomForestClassifier(n_jobs=-<span class="number">1</span>) </span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure>

<p>使用 scikit-learn 中的随机森林，并取消了独热编码。使用标签编码代替独热编码。得分如下</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_rf.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.7167390828113697</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.7165459672958506</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.7159709909587376</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.7161589664189556</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.7156020216155978</span></span><br></pre></td></tr></table></figure>
<p>在不需要任何超参数调整的情况下，表现比简单的逻辑回归差很多</p>
<p>现在尝试在稀疏的独热编码数据上运行随机森林，此时还可以尝试使用 <code>奇异值分解</code> 来 <code>减少稀疏的独热编码矩阵</code>。这是自然语言处理中提取主题的常用方法。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> decomposition</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>)]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    <span class="comment"># 独热编码</span></span><br><span class="line">    ohe = preprocessing.OneHotEncoder()</span><br><span class="line">    full_data = pd.concat([df_train[features], df_valid[features]], axis=<span class="number">0</span>)</span><br><span class="line">    ohe.fit(full_data[features])</span><br><span class="line"></span><br><span class="line">    x_train = ohe.transform(df_train[features])</span><br><span class="line">    x_valid = ohe.transform(df_valid[features])</span><br><span class="line">    <span class="comment"># 奇异值分解</span></span><br><span class="line">    svd = decomposition.TruncatedSVD(n_components=<span class="number">120</span>) </span><br><span class="line">    full_sparse = sparse.vstack((x_train, x_valid)) </span><br><span class="line">    svd.fit(full_sparse)</span><br><span class="line">    x_train = svd.transform(x_train)</span><br><span class="line">    x_valid = svd.transform(x_valid)</span><br><span class="line">    model = ensemble.RandomForestClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure>

<p>对全部数据进行独热编码，然后用训练数据和验证数据在稀疏矩阵上拟合scikit-learn 的 TruncatedSVD。 这样就可以将高维稀疏矩阵减少到120个特征</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">❯ python ohe_svd_rf.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.7064863038754249</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.706050102937374</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.7086069243167242</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.7066819080085971</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.7058154015055585</span></span><br></pre></td></tr></table></figure>

<p>情况更糟，看来解决这个问题的最佳方法是使用 逻辑回归和独热编码。随机深林似乎耗时太多</p>
<p>现在试试 XGBoost(最流行的梯度提升算法之一，基于树算法)，使用标签编码数据</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 标签编码</span></span><br><span class="line">        lbl = preprocessing.LabelEncoder()</span><br><span class="line">        lbl.fit(df[col])</span><br><span class="line">        df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    x_train = df_train[features].values</span><br><span class="line">    x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># XGBoost模型，最大深度从3改成了7，将估计器数量从100改成了200</span></span><br><span class="line">    model = xgb.XGBClassifier(</span><br><span class="line">        n_jobs=-<span class="number">1</span>, </span><br><span class="line">        max_depth=<span class="number">7</span>, </span><br><span class="line">        n_estimators=<span class="number">200</span>)</span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">        <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">            run(fold_)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该模型的 5 折交叉检验得分如下：</span></span><br><span class="line">❯ python lbl_xgb.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.7656768851999011</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.7633006564148015</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.7654277821434345</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.7663609758878182</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.764914671468069</span></span><br></pre></td></tr></table></figure>

<p>还可以观察到，再不做任何调整的情况下，得分会比普通随机森林高得多。</p>
<p>现在将数据集换成另外一个有大量分类变量的数据集， 美国成人人口普查数据（US adult census data）。<br>这个数据集中包含一些特征，我们的任务是预测工资等级。</p>
<p>数据集目前没找到</p>
<p>该数据集有以下几列： </p>
<ul>
<li>年龄（age）</li>
<li>工作类别（workclass）</li>
<li>学历（fnlwgt）</li>
<li>教育程度（education）</li>
<li>教育程度（education.num）</li>
<li>婚姻状况（marital.status）</li>
<li>职业（occupation）</li>
<li>关系（relationship）</li>
<li>种族（race）</li>
<li>性别（sex）</li>
<li>资本收益（capital.gain）</li>
<li>资本损失（capital.loss）</li>
<li>每周小时数（hours.per.week）</li>
<li>原籍国（native.country）</li>
<li>收入（income）</li>
</ul>
<p>尝试建立一个模型</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 收入列是一个字符串。让我们对这一列进行数值统计。</span></span><br><span class="line">In [X]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">In [X]: df = pd.read_csv(<span class="string">&quot;../input/adult.csv&quot;</span>) </span><br><span class="line">In [X]: df.income.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line">&lt;=50K   <span class="number">24720</span></span><br><span class="line">&gt;50K     <span class="number">7841</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有 7841 个实例的收入超过 5 万美元。这占样本总数的 24%</span></span><br></pre></td></tr></table></figure>

<p>再开始建模之前，去掉几列特征</p>
<ul>
<li>学历（fnlwgt）</li>
<li>年龄（age）</li>
<li>资本收益（capital.gain）</li>
<li>资本损失（capital.loss）</li>
<li>每周小时数（hours.per.week）</li>
</ul>
<p>尝试用逻辑回归和独热编码器，第一步总是要进行交叉验证</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 需要删除的列</span></span><br><span class="line">    num_cols = [ </span><br><span class="line">        <span class="string">&quot;fnlwgt&quot;</span>, </span><br><span class="line">        <span class="string">&quot;age&quot;</span>,</span><br><span class="line">        <span class="string">&quot;capital.gain&quot;</span>, </span><br><span class="line">        <span class="string">&quot;capital.loss&quot;</span>, </span><br><span class="line">        <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    df = df.drop(num_cols, axis=<span class="number">1</span>) </span><br><span class="line">    <span class="comment"># 映射</span></span><br><span class="line">    target_mapping = &#123; </span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>, </span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 使用映射替换</span></span><br><span class="line">    df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">    <span class="comment"># 取除&quot;kfold&quot;, &quot;income&quot;列的其他列名</span></span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 将空值替换为&quot;NONE&quot;</span></span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line">    <span class="comment"># 取训练集（kfold列中不为fold的样本，重置索引）</span></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    <span class="comment"># 取验证集（kfold列中为fold的样本，重置索引）</span></span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    <span class="comment"># 独热编码</span></span><br><span class="line">    ohe = preprocessing.OneHotEncoder()</span><br><span class="line">    <span class="comment"># 将训练集、测试集沿行合并</span></span><br><span class="line">    full_data = pd.concat([df_train[features], df_valid[features]], axis=<span class="number">0</span>)</span><br><span class="line">    ohe.fit(full_data[features])</span><br><span class="line">    <span class="comment"># 转换训练集</span></span><br><span class="line">    x_train = ohe.transform(df_train[features])</span><br><span class="line">    <span class="comment"># 转换验证集</span></span><br><span class="line">    x_valid = ohe.transform(df_valid[features])</span><br><span class="line">    <span class="comment"># 构建逻辑回归模型</span></span><br><span class="line">    model = linear_model.LogisticRegression()</span><br><span class="line">    <span class="comment"># 使用训练集训练模型</span></span><br><span class="line">    model.fit(x_train, df_train.income.values)</span><br><span class="line">    <span class="comment"># 使用验证集得到预测标签</span></span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    <span class="comment"># 计算auc指标</span></span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行0~4折</span></span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python -W ignore ohe_logres.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.8794809708119079</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.8875785068274882</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.8852609687685753</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.8681236223251438</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.8728581541840037</span></span><br></pre></td></tr></table></figure>

<p>对于一个简单的模型来讲，AUC的值很不错，现在，在不调整任何超参数的情况下尝试一下标签编码的XGBoost</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    num_cols = [ <span class="string">&quot;fnlwgt&quot;</span>, </span><br><span class="line">                <span class="string">&quot;age&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.gain&quot;</span>, </span><br><span class="line">                <span class="string">&quot;capital.loss&quot;</span>, </span><br><span class="line">                <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">               ]</span><br><span class="line">    df = df.drop(num_cols, axis=<span class="number">1</span>) </span><br><span class="line">    target_mapping = &#123; </span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>, </span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 标签编码</span></span><br><span class="line">        lbl = preprocessing.LabelEncoder()</span><br><span class="line">        lbl.fit(df[col])</span><br><span class="line">        df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    x_train = df_train[features].values</span><br><span class="line">    x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># XGBoost模型</span></span><br><span class="line">    model = xgb.XGBClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">    model.fit(x_train, df_train.income.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行0~4折</span></span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.8800810634234078</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.886811884948154</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.8854421433318472</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.8676319549361007</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.8714450054900602</span></span><br></pre></td></tr></table></figure>

<p>效果很不错，观察将max_depth 增加到 7 和 n_estimators 增加到 200 时的得分</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.8764108944332032</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.8840708537662638</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.8816601162613102</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.8662335762581732</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.8698983461709926</span></span><br></pre></td></tr></table></figure>

<p>并没有改善，一个数据集的参数不能移植到另一个数据集，我们必须再次尝试调整参数</p>
<p>现在，在不调整参数的情况下将数值特征纳入XGBoost模型</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 加入数值特征</span></span><br><span class="line">    num_cols = [ </span><br><span class="line">        <span class="string">&quot;fnlwgt&quot;</span>, </span><br><span class="line">        <span class="string">&quot;age&quot;</span>,</span><br><span class="line">        <span class="string">&quot;capital.gain&quot;</span>, </span><br><span class="line">        <span class="string">&quot;capital.loss&quot;</span>, </span><br><span class="line">        <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    target_mapping = &#123; </span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>, </span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features: </span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            <span class="comment"># 将空值置为&quot;NONE&quot;</span></span><br><span class="line">            df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            <span class="comment"># 标签编码</span></span><br><span class="line">            lbl = preprocessing.LabelEncoder()</span><br><span class="line">            lbl.fit(df[col])</span><br><span class="line">            df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    x_train = df_train[features].values</span><br><span class="line">    x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># XGBoost模型</span></span><br><span class="line">    model = xgb.XGBClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    model.fit(x_train, df_train.income.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure>

<p>保留数字列，只是不对其进行标签编码，这样 最终特征矩阵就由 <code>数字列（原样）</code> 和 <code>编码分类列</code> 组成了.任何基于树的算法都能轻松处理这种混合。</p>
<blockquote>
<p>tips: 在使用基于树的模型时，不需要对数据进行归一化处理。</p>
</blockquote>
<p>运行结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb_num.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.9209790185449889</span> </span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.9247157449144706</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.9269329887598243</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.9119349082169275</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.9166408030141667</span></span><br></pre></td></tr></table></figure>

<p>分数提高了，现在尝试添加一些功能，将提取所有分类列，并创建所有二度组合。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">feature_engineering</span>(<span class="params">df, cat_cols</span>):</span><br><span class="line">    <span class="comment"># 生成两个特征的组合</span></span><br><span class="line">    combi = <span class="built_in">list</span>(itertools.combinations(cat_cols, <span class="number">2</span>)) </span><br><span class="line">    <span class="keyword">for</span> c1, c2 <span class="keyword">in</span> combi:</span><br><span class="line">        df.loc[:, c1 + <span class="string">&quot;_&quot;</span> + c2] = df[c1].astype(<span class="built_in">str</span>) + <span class="string">&quot;_&quot;</span> + df[c2].astype(<span class="built_in">str</span>) </span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>) </span><br><span class="line">    num_cols = [ <span class="string">&quot;fnlwgt&quot;</span>, </span><br><span class="line">                <span class="string">&quot;age&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.gain&quot;</span>, </span><br><span class="line">                <span class="string">&quot;capital.loss&quot;</span>, </span><br><span class="line">                <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">               ]</span><br><span class="line">    target_mapping = &#123; </span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>, </span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping) </span><br><span class="line">    cat_cols = [c <span class="keyword">for</span> c <span class="keyword">in</span> df.columns <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> num_cols <span class="keyword">and</span> c <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>)]</span><br><span class="line">    <span class="comment"># 特征工程</span></span><br><span class="line">    df = feature_engineering(df, cat_cols)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>)]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            lbl = preprocessing.LabelEncoder()</span><br><span class="line">            lbl.fit(df[col])</span><br><span class="line">            df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>) </span><br><span class="line">    x_train = df_train[features].values</span><br><span class="line">    x_valid = df_valid[features].values</span><br><span class="line">    model = xgb.XGBClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">    model.fit(x_train, df_train.income.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>] </span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>): </span><br><span class="line">        run(fold_)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这样的话，最终可能会创建大量特征，此时，就需要使用某种特征选择来选出最佳特征，现在看看分数</p>
<p>运行结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb_num_feat.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.9211483465031423</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.9251499446866125</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.9262344766486692</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.9114264068794995</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.9177914453099201</span></span><br></pre></td></tr></table></figure>

<p>及时不改变任何超参数，只增加一些特征，也能提高折叠得分，将 max_depth 调整为 7 试试是否有帮助。<br>运行结果：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb_num_feat.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.9286668430204137</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.9329340656165378</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.9319817543218744</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.919046187194538</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.9245692057162671</span></span><br></pre></td></tr></table></figure>

<p>再次改进了模型</p>
<blockquote>
<p>tips：请注意，此时还没有使用稀有值、二值化、独热编码和标签编码特征的组合以及其他几种方法。</p>
</blockquote>
<h4 id="设置环境"><a href="#设置环境" class="headerlink" title="设置环境"></a>设置环境</h4><ul>
<li>安装 MiniConda3<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda create -n ai python=<span class="number">3</span>.<span class="number">8</span></span><br><span class="line">conda activate ai</span><br><span class="line"></span><br><span class="line">conda env create -f env.yml</span><br><span class="line">conda install x</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="动手学深度学习v2"><a href="#动手学深度学习v2" class="headerlink" title="动手学深度学习v2"></a>动手学深度学习v2</h3><h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>查询aws最优惠的配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">https://instances.vantage.sh/?selected=g4dn.xlarge</span><br><span class="line"></span><br><span class="line">ssh ubunto@ip</span><br><span class="line"></span><br><span class="line">sudo apt update</span><br><span class="line"></span><br><span class="line">sudo apt install build-essential</span><br><span class="line"></span><br><span class="line">sudo apt install python3<span class="number">.8</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">安装 miniconda docs.conda.io 找到python3<span class="number">.8</span>的包</span><br><span class="line"></span><br><span class="line">wget x86_64.sh</span><br><span class="line"></span><br><span class="line">bash x  壮哉根目录下 初始化 conda</span><br><span class="line"></span><br><span class="line">bash 进入 conda 环境</span><br><span class="line"></span><br><span class="line">pip install jupyter d2l torch torchvision</span><br><span class="line"></span><br><span class="line">记事本 zh-v2.d2l.ai</span><br><span class="line"></span><br><span class="line">wget d2l-zh.<span class="built_in">zip</span></span><br><span class="line"></span><br><span class="line">sudo apt install <span class="built_in">zip</span></span><br><span class="line"></span><br><span class="line">unzip d2l-zh</span><br><span class="line"></span><br><span class="line">cd pytorch</span><br><span class="line"></span><br><span class="line">git clone d2l-ai/d2l-zh-pytorch-sli-des 克隆课件</span><br><span class="line"></span><br><span class="line">jupyter notebook 出现一个link 绑定本地端口 可以进行访问link</span><br><span class="line"></span><br><span class="line">ssh -L8888:localhost:<span class="number">8888</span> ubuntu@ip</span><br><span class="line"></span><br><span class="line">安装插件 幻灯片 rise</span><br><span class="line"></span><br><span class="line">pip install rise</span><br><span class="line"></span><br><span class="line">OPEN notebooks/pytorch/chapter_linear-networks/linear-regression-scratch.ipynb  有个按钮</span><br></pre></td></tr></table></figure>
<h4 id="下載安裝服務器"><a href="#下載安裝服務器" class="headerlink" title="下載安裝服務器"></a>下載安裝服務器</h4><blockquote>
<p><a href="https://www.bilibili.com/video/BV18p4y1h7Dr/?spm_id_from=333.999.0.0&amp;vd_source=508e069b09636e2f68f3ef05a2868539" target="_blank" rel="noopener">https://www.bilibili.com/video/BV18p4y1h7Dr/?spm_id_from=333.999.0.0&amp;vd_source=508e069b09636e2f68f3ef05a2868539</a></p>
</blockquote>
<h4 id="04-数据操作-数据预处理"><a href="#04-数据操作-数据预处理" class="headerlink" title="04 数据操作 + 数据预处理"></a>04 数据操作 + 数据预处理</h4><p>常见的操作</p>
<ul>
<li>N维数组<ul>
<li>0维：0-d 标量 一个类别</li>
<li>1维：1-d 向量 一个特征向量</li>
<li>2维：2-d 矩阵 一个样本-特征矩阵</li>
<li>3维：3-d 一个RGB图片（宽x高x通道）</li>
<li>4维：4-d 一个RGB图片批量（批量大下x宽x高x通道）</li>
<li>5维：4-d 一个视频批量（批量大小x时间x宽x高x通道）</li>
</ul>
</li>
<li>创建数组<ul>
<li>形状：3x4矩阵</li>
<li>数据类型：32位浮点数</li>
<li>每个元素的值 例如都是0，或者随机数<ul>
<li>正态分布</li>
<li>均匀分布</li>
</ul>
</li>
</ul>
</li>
<li>访问元素<ul>
<li>一个元素 [1,2]</li>
<li>一行[1,:] 第一行所有</li>
<li>一列[:,1] 第一列所有</li>
<li>子区域[1:3,1:] 1-2行，不包括3（因为python中切片不包含终止索引），第一列-最后一列</li>
<li>子区域[::3,::2] 从第0行开始，每隔3行选取一个元素，同时从第0列开始，每隔2列选取一个元素。</li>
</ul>
</li>
</ul>
<p>使用方式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.arange(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过shape属性来访问张量的形状</span></span><br><span class="line">In: x.shape</span><br><span class="line">Out: torch.Size([<span class="number">12</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过size()函数来访问张量的形状</span></span><br><span class="line">In: x.size()</span><br><span class="line">Out: torch.Size([<span class="number">12</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过numel()函数来访问张量的元素总数</span></span><br><span class="line">In: x.numel()</span><br><span class="line">Out: <span class="number">12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过reshape()函数来改变张量的形状,不改变张量的元素数量和元素值</span></span><br><span class="line">In: X = x.reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">Out: tensor([[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">             [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">             [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]])</span><br><span class="line">             </span><br><span class="line"><span class="comment"># 通过全0张量和全1张量来创建张量</span></span><br><span class="line">In: torch.zeros((<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">Out: tensor([[[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">             [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">             [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]],</span><br><span class="line">            [[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">             [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">             [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]]])</span><br><span class="line">             </span><br><span class="line"><span class="comment"># 通过提供包含元素值的Python列表（或嵌套列表）来为所需张量的每个元素赋予确定值</span></span><br><span class="line">In: torch.tensor([[<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line">Out: tensor([[<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>],</span><br><span class="line">             [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">             [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 常见的标准算术运算符（+、-、*、/ 和 **）都可以被升级为按元素运算</span></span><br><span class="line">In: x = torch.tensor([<span class="number">1.0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>])</span><br><span class="line">In: y = torch.tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">In: x + y, x - y, x * y, x / y, x**y</span><br><span class="line">Out: (tensor([ <span class="number">3.</span>,  <span class="number">4.</span>,  <span class="number">6.</span>, <span class="number">10.</span>]), </span><br><span class="line">      tensor([-<span class="number">1.</span>,  <span class="number">0.</span>,  <span class="number">2.</span>,  <span class="number">6.</span>]), </span><br><span class="line">      tensor([ <span class="number">2.</span>,  <span class="number">4.</span>,  <span class="number">8.</span>, <span class="number">16.</span>]), </span><br><span class="line">      tensor([<span class="number">0.5000</span>, <span class="number">1.0000</span>, <span class="number">2.0000</span>, <span class="number">4.0000</span>]),</span><br><span class="line">      tensor([ <span class="number">1.</span>,  <span class="number">4.</span>, <span class="number">16.</span>, <span class="number">64.</span>]))</span><br><span class="line">      </span><br><span class="line"><span class="comment"># 按照元素级别应用更多的计算</span></span><br><span class="line">In: torch.exp(x)</span><br><span class="line">Out: tensor([<span class="number">2.7183</span>, <span class="number">7.3891</span>, <span class="number">54.5982</span>, <span class="number">2980.9580</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连接多个张量</span></span><br><span class="line">In: X = torch.arange(<span class="number">12</span>, dtype=torch.float32).reshape((<span class="number">3</span>,<span class="number">4</span>))</span><br><span class="line">In: Y = torch.tensor([[<span class="number">2.0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line">In: torch.cat((X, Y), dim=<span class="number">0</span>), torch.cat((X, Y), dim=<span class="number">1</span>)</span><br><span class="line">Out: (tensor([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>],</span><br><span class="line">              [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>],</span><br><span class="line">              [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>],</span><br><span class="line">              [ <span class="number">2.</span>,  <span class="number">1.</span>,  <span class="number">4.</span>,  <span class="number">3.</span>],</span><br><span class="line">              [ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>],</span><br><span class="line">              [ <span class="number">4.</span>,  <span class="number">3.</span>,  <span class="number">2.</span>,  <span class="number">1.</span>]]),</span><br><span class="line">      tensor([[ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">2.</span>,  <span class="number">1.</span>,  <span class="number">4.</span>,  <span class="number">3.</span>],</span><br><span class="line">              [ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>],</span><br><span class="line">              [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>,  <span class="number">4.</span>,  <span class="number">3.</span>,  <span class="number">2.</span>,  <span class="number">1.</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑运算符</span></span><br><span class="line">In: X == Y</span><br><span class="line">Out: tensor([[<span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>],</span><br><span class="line">             [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">             [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]])</span><br><span class="line">             </span><br><span class="line"><span class="comment"># 对张量中的所有元素进行求和得到只有一个元素的张量</span></span><br><span class="line">In: X.<span class="built_in">sum</span>()</span><br><span class="line">Out: tensor(<span class="number">66.</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 即使形状不同，我们仍然可以通过调用广播机制来执行按元素操作</span></span><br><span class="line">In: a = torch.arange(<span class="number">3</span>).reshape((<span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">In: b = torch.arange(<span class="number">2</span>).reshape((<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">In: a, b</span><br><span class="line">Out: (tensor([[<span class="number">0</span>],</span><br><span class="line">              [<span class="number">1</span>],</span><br><span class="line">              [<span class="number">2</span>]]),</span><br><span class="line">      tensor([[<span class="number">0</span>, <span class="number">1</span>]]))</span><br><span class="line">      </span><br><span class="line">In: a + b</span><br><span class="line">Out: tensor([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">             [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">             [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">             </span><br><span class="line"><span class="comment"># 可以用[-1]选择最后一个元素，可以用[1:3]选择第二个和第三个元素</span></span><br><span class="line">In: X[-<span class="number">1</span>], X[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line">Out: (tensor([ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>]), </span><br><span class="line">        tensor([[ <span class="number">4.</span>,  <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>],</span><br><span class="line">                [ <span class="number">8.</span>,  <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>]]))</span><br><span class="line">                                         </span><br><span class="line"><span class="comment"># 执行原地操作</span></span><br><span class="line">In: Z = torch.zeros_like(Y)</span><br><span class="line">In: Z[:] = X + Y</span><br><span class="line">Out: tensor([[ <span class="number">2.</span>,  <span class="number">2.</span>,  <span class="number">6.</span>,  <span class="number">6.</span>],</span><br><span class="line">             [ <span class="number">5.</span>,  <span class="number">7.</span>,  <span class="number">9.</span>, <span class="number">11.</span>],</span><br><span class="line">             [<span class="number">12.</span>, <span class="number">12.</span>, <span class="number">12.</span>, <span class="number">12.</span>]])</span><br><span class="line">             </span><br><span class="line"><span class="comment"># 如果在后续计算中没有重复使用X，我们也可以使用X[:] = X + Y或X += Y来减少操作的内存开销</span></span><br><span class="line">In: before = <span class="built_in">id</span>(Y)</span><br><span class="line">In: Y = Y + X</span><br><span class="line">In: <span class="built_in">id</span>(Y) == before</span><br><span class="line">Out: <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换为NumPy张量</span></span><br><span class="line">In: A = X.numpy()</span><br><span class="line">In: B = torch.tensor(A)</span><br><span class="line">Out: (A, B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将大小为1的张量转换为Python标量</span></span><br><span class="line">In: a = torch.tensor([<span class="number">3.5</span>])</span><br><span class="line">In: a, a.item(), <span class="built_in">float</span>(a), <span class="built_in">int</span>(a)</span><br><span class="line">Out: (tensor([<span class="number">3.5000</span>]), <span class="number">3.5</span>, <span class="number">3.5</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>数据预处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.makedirs(os.path.join(<span class="string">&#x27;..&#x27;</span>, <span class="string">&#x27;data&#x27;</span>), exist_ok=<span class="literal">True</span>)</span><br><span class="line">data_file = os.path.join(<span class="string">&#x27;..&#x27;</span>, <span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;house_tiny.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(data_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;NumRooms,Alley,Price\n&#x27;</span>)  <span class="comment"># 列名</span></span><br><span class="line">    f.write(<span class="string">&#x27;NA,Pave,127500\n&#x27;</span>)  <span class="comment"># 每行表示一个数据样本</span></span><br><span class="line">    f.write(<span class="string">&#x27;2,NA,106000\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;4,NA,178100\n&#x27;</span>)</span><br><span class="line">    f.write(<span class="string">&#x27;NA,NA,140000\n&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">Out: <span class="string">&#x27;..\\data\\house_tiny.csv&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从csv文件中加载数据集 </span></span><br><span class="line"><span class="comment">## !pip install pandas</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(data_file)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理缺失值，使用插值、删除、填充等方法，下面使用插值</span></span><br><span class="line">inputs, outputs = data.iloc[:, <span class="number">0</span>:<span class="number">2</span>], data.iloc[:, <span class="number">2</span>]</span><br><span class="line">inputs = inputs.fillna(inputs.mean())</span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于Inputs中的类别值或离散值，我们将“NaN”视为一个类别</span></span><br><span class="line">inputs = pd.get_dummies(inputs, dummy_na=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 现在所有的输入和输出都是数值类型，它们可以转换为张量格式</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)</span><br><span class="line">X, y</span><br><span class="line">Out: (tensor([[<span class="number">2.0000</span>, <span class="number">1.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>],</span><br><span class="line">              [<span class="number">4.0000</span>, <span class="number">1.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>],</span><br><span class="line">              [<span class="number">3.0000</span>, <span class="number">1.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>],</span><br><span class="line">              [<span class="number">3.0000</span>, <span class="number">1.0000</span>, <span class="number">0.0000</span>, <span class="number">0.0000</span>]], dtype=torch.float64),</span><br><span class="line">      tensor([<span class="number">127500</span>, <span class="number">106000</span>, <span class="number">178100</span>, <span class="number">140000</span>], dtype=torch.int64))</span><br><span class="line">      </span><br></pre></td></tr></table></figure>

<h4 id="05-线性代数"><a href="#05-线性代数" class="headerlink" title="05 线性代数"></a>05 线性代数</h4><blockquote>
<p>数学的一个分支，研究向量空间和线性映射的理论和运算方法</p>
</blockquote>
<p>标量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单操作</span></span><br><span class="line">c = a + b</span><br><span class="line">c = a * b</span><br><span class="line">c = sina</span><br><span class="line"></span><br><span class="line"><span class="comment"># 长度 绝对值</span></span><br><span class="line">~~~python</span><br><span class="line"><span class="comment">#### 向量</span></span><br><span class="line">~~~python</span><br><span class="line"><span class="comment"># 简单操作</span></span><br><span class="line">c = a + b</span><br><span class="line">c = a * b</span><br><span class="line">c = sina</span><br><span class="line"></span><br><span class="line"><span class="comment"># 长度 每个元素的平方和 再开根号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 点积</span></span><br><span class="line">c = a * b</span><br><span class="line">c = a.dot(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正交 垂直</span></span><br><span class="line">c = a.dot(b) == <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简单操作</span></span><br><span class="line">c = a + b</span><br><span class="line">c = a * b</span><br><span class="line">c = sina</span><br><span class="line"></span><br><span class="line"><span class="comment"># 乘法 矩阵x向量</span></span><br><span class="line">中文含义：矩阵A的第i行与向量x的点积</span><br><span class="line"></span><br><span class="line"><span class="comment"># 乘法 矩阵x矩阵</span></span><br><span class="line">中文含义：矩阵A的第i行与矩阵B的第j列的点积</span><br><span class="line"></span><br><span class="line"><span class="comment"># 范数</span></span><br><span class="line">中文含义：矩阵A的第i行与矩阵B的第j列的点积</span><br><span class="line">取决于如何衡量b和c的长度</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常见范数</span></span><br><span class="line"><span class="comment">## 矩阵范数</span></span><br><span class="line"><span class="comment">## Frobenius范数</span></span><br></pre></td></tr></table></figure>
<p>特殊矩阵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对称和反对称矩阵</span></span><br><span class="line">Aij = Aji 和 Aij = -Aji</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正定矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 正交矩阵 所有行向量和列向量都是单位向量 互相正交</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 置换矩阵 每行每列只有一个1，其他都是0  = 正交矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征向量和特征值</span></span><br><span class="line"><span class="comment">## 不被矩阵变换方向改变的向量</span></span><br><span class="line"><span class="comment">## 对称矩阵总是可以找到特征向量</span></span><br></pre></td></tr></table></figure>


<p>…</p>
<h4 id="10-感知机SNP-和-多层感知机-MLP"><a href="#10-感知机SNP-和-多层感知机-MLP" class="headerlink" title="10 感知机SNP 和 多层感知机 MLP"></a>10 感知机SNP 和 多层感知机 MLP</h4><h5 id="感知机（模型）"><a href="#感知机（模型）" class="headerlink" title="感知机（模型）"></a>感知机（模型）</h5><blockquote>
<p>一个简单的人工神经元模型，是一种线性分类模型</p>
</blockquote>
<p>感知机(二分类)</p>
<ul>
<li>模型：输入 向量x 向量权重w 标量偏移b 输出是个二分类问题：1或-1 这个值是可以随便改的<div>
              <img src="p/614a8113/感知机(二分类" alt="感知机(二分类)模型"></img>
              <p style="
              display: flex;
              color: #999;
              justify-content: center;
              font-size: 0.8rem;
              position: relative;
              top: -1rem;
              right: 50%;
              left: 50%;
              transform: translateX(-50%);
              ">[感知机(二分类)模型]</p>
          </div>模型.png)</li>
</ul>
<p>线性回归 输出 一个实数<br>感知机 输出 一个1或-1<br>Softmax回归 输出概率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练感知机</span></span><br><span class="line">init w=<span class="number">0</span>,b=<span class="number">0</span> <span class="comment">#w是权重，b是偏差</span></span><br><span class="line">repeat</span><br><span class="line">  <span class="keyword">if</span> &lt;=<span class="number">0</span>(有误分类点)  <span class="comment"># 如果是 &gt;0 则是正确分类点</span></span><br><span class="line">    w=w+学习率*误分类点x <span class="comment"># 当前权重和样品分类错误，权重进行梯度下降算法进行，不一定是增加，只是更接近正确的方向</span></span><br><span class="line">    b=b+学习率*误分类点 <span class="comment"># 标号b也增加</span></span><br><span class="line">  end <span class="keyword">if</span></span><br><span class="line">until 没有误分类点</span><br><span class="line"></span><br><span class="line">等价于使用批量大小为<span class="number">1</span>的梯度下降，并使用如下的损失函数：</span><br><span class="line"></span><br><span class="line"><span class="comment"># 总结：感知机是一个简单的线性分类模型，它可以用于二分类和回归问题。感知机的训练算法是简单的梯度下降算法，它可以用于训练线性模型。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 收敛定理</span></span><br><span class="line">如果数据集是线性可分的，那么感知机算法在有限次迭代后收敛，此时感知机算法找到一个能够完美分类训练数据集的模型参数。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 感知机的问题</span></span><br><span class="line">不能解决 XOR 问题，因为 XOR 问题的训练数据集是线性不可分的。</span><br><span class="line">所以要解决这个问题，需要引入新的概念，非线性分类问题。也就是使用多层感知机来处理非线性函数。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多层感知机（解决多线性分类问题）</span></span><br><span class="line">- 模型：</span><br><span class="line">  -  单隐藏层做单分类：输入x1-n(n维向量) 隐藏层h1-n(隐藏层数量n x 输入n的 矩阵，偏移=隐藏层的数量的向量) 输出O1-n(如果是分类问题，一般是指类别的数量) </span><br><span class="line">  - </span><br><span class="line"></span><br><span class="line">隐藏层大小是超参数，需要根据数据集的大小来选择。一般来讲，隐藏层大小应该在 <span class="number">1</span> 到 <span class="number">10</span> 之间。</span><br><span class="line">每个隐藏层的大小是超参数，</span><br><span class="line"></span><br><span class="line">激活函数非必要使用，但是必须是非线性函数</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>激活函数</th>
<th>使用场景</th>
</tr>
</thead>
<tbody><tr>
<td>Sigmoid</td>
<td>二分类问题，输出范围需要在0和1之间</td>
</tr>
<tr>
<td>Softmax</td>
<td>多类别分类问题的输出层激活函数，将输出转化为概率分布</td>
</tr>
<tr>
<td>Tanh</td>
<td>隐藏层激活函数，能够将数据归一化到[-1, 1]范围</td>
</tr>
<tr>
<td>ReLU</td>
<td>隐藏层激活函数，用于减少梯度消失问题，通常表现良好</td>
</tr>
<tr>
<td>Leaky ReLU</td>
<td>隐藏层激活函数，用于解决ReLU中的”死亡神经元”问题</td>
</tr>
<tr>
<td>Linear&#x2F;Identity</td>
<td>回归问题的输出层激活函数，直接输出网络的原始值</td>
</tr>
</tbody></table>
<p>多隐藏层，每一个隐藏层都有自己的权重和偏移量，每个隐藏层都可以独立地学习到不同的特征。</p>
<p>总结：</p>
<ul>
<li>感知机SNP，多层感知机MLP。</li>
<li>感知机主要用于二元分类任务，即将数据划分为两个类别。</li>
<li>感知机的训练过程达到了一个稳定状态，模型参数不再发生显著变化，则停止训练。</li>
<li>感知机无法解决 XOR 非线性分类问题，所以引入多层感知机。</li>
<li>多层感知机的 隐藏层数量 和 大小 都是超参数，需要根据数据集的大小来选择。<ul>
<li>数据复杂，维度高的数据集，需要更多的隐藏层和神经元，但是隐藏层的数量和神经元的数量要逐步增加或减少。</li>
</ul>
</li>
</ul>
<p>实际代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">batct_size=<span class="number">256</span></span><br><span class="line"><span class="comment"># 训练集 测试集</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入，输出，隐藏层</span></span><br><span class="line">num_inputs, num_outputs,num_hiddens=<span class="number">784</span>，<span class="number">10</span>，<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度</span></span><br><span class="line">W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 偏差</span></span><br><span class="line">b1 = nn,Parameter(torch.zeros(num_hiddens, requires_grad=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">W2 = nn.Parameter(torch,randn(num_hiddens, num_outputs,reguires_grad=<span class="literal">True</span>))</span><br><span class="line">b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">params =[W1，b1，w2，b2]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现 ReLU激活函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">relu</span>(<span class="params">X</span>):</span><br><span class="line">  a = torch.zeros_like(X)</span><br><span class="line">  <span class="keyword">return</span> torch.<span class="built_in">max</span>(X, a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现 模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">net</span>(<span class="params">X</span>):</span><br><span class="line">  X = X.reshape((-<span class="number">1</span>, num_inputs))</span><br><span class="line">  H = relu(X@W1 + b1)</span><br><span class="line">  <span class="keyword">return</span> (H@W2 + b2)</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">num_epochs, lr = <span class="number">10</span>, <span class="number">0.1</span></span><br><span class="line">updater = torch.optim.SGD(params, lr=lr)</span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)</span><br></pre></td></tr></table></figure>

<p>简洁实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">num_inputs, num_outputs,num_hiddens=<span class="number">784</span>，<span class="number">10</span>，<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">  nn.Flatten(),</span><br><span class="line">  nn.Linear(num_inputs, num_hiddens), <span class="comment"># 线性层</span></span><br><span class="line">  nn.ReLU(),</span><br><span class="line">  nn.Linear(num_hiddens, num_outputs)) <span class="comment"># 输出</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear:</span><br><span class="line">    nn.init.normal_(m.weight, std=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">net.apply(init_weights)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">batch_size, lr, num_epochs = <span class="number">256</span>, <span class="number">0.1</span>, <span class="number">10</span></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">trainer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line"></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line"></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)</span><br></pre></td></tr></table></figure>


<h5 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h5><p>隐藏层 超参数<br>输出层数量 根据数据决定</p>
<p>激活函数：</p>
<ul>
<li>按元素的激活函数</li>
<li>Sigmoid激活函数</li>
<li>Tanh激活函数</li>
</ul>
<h4 id="15-实战-Kaggle-房价预测"><a href="#15-实战-Kaggle-房价预测" class="headerlink" title="15 实战 Kaggle 房价预测"></a>15 实战 Kaggle 房价预测</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@matplotlib inline</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">DATA_HUB[<span class="string">&#x27;kaggle_house_train&#x27;</span>] = (DATA_URL + <span class="string">&#x27;kaggle_house_pred_train.csv&#x27;</span>,</span><br><span class="line">                                  <span class="string">&#x27;585e9cc93e70b39160e7921475f9bcd7d31219ce&#x27;</span>)</span><br><span class="line">DATA_HUB[<span class="string">&#x27;kaggle_house_test&#x27;</span>] = (DATA_URL + <span class="string">&#x27;kaggle_house_pred_test.csv&#x27;</span>,</span><br><span class="line">                                 <span class="string">&#x27;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#x27;</span>)</span><br><span class="line">train_data = pd.read_csv(d2l.download(<span class="string">&#x27;kaggle_house_train&#x27;</span>))</span><br><span class="line">test_data = pd.read_csv(d2l.download(<span class="string">&#x27;kaggle_house_test&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_data.shape)</span><br><span class="line"><span class="built_in">print</span>(test_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前四个和最后两个特征，以及相应的标签（房价）</span></span><br><span class="line"><span class="built_in">print</span>(train_data.iloc[<span class="number">0</span>:<span class="number">4</span>, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, -<span class="number">3</span>, -<span class="number">2</span>, -<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在每个样本中，第一个特征是ID，将其从数据集中删除</span></span><br><span class="line">all_features = pd.concat((train_data.iloc[:, <span class="number">1</span>:-<span class="number">1</span>], test_data.iloc[:, <span class="number">1</span>:]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将所有缺失的值替换为相应特征的平均值。通过将特征重新缩放到零均值和单位方差来标准化数据</span></span><br><span class="line"><span class="comment">## 每一列，均值为0，方差为1</span></span><br><span class="line">numeric_features = all_features.dtypes[all_features.dtypes != <span class="string">&#x27;object&#x27;</span>].index</span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].apply(</span><br><span class="line">    <span class="keyword">lambda</span> x: (x - x.mean()) / (x.std()))</span><br><span class="line">all_features[numeric_features] = all_features[numeric_features].fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理离散值（字符串），用一次独热编码替换</span></span><br><span class="line">all_features = pd.get_dummies(all_features, dummy_na=<span class="literal">True</span>)</span><br><span class="line">all_features.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 pandas 格式中提取 numpy 格式，将其转换为张量格式</span></span><br><span class="line">n_train = train_data.shape[<span class="number">0</span>]</span><br><span class="line">train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)</span><br><span class="line">test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)</span><br><span class="line">train_labels = torch.tensor(train_data.SalePrice.values, dtype=torch.float32).view(-<span class="number">1</span>, <span class="number">1</span>), dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">in_features = train_features.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_net</span>():</span><br><span class="line">    net = nn.Sequential(nn.Linear(in_features, <span class="number">1</span>)) <span class="comment"># 单层线性回归模型</span></span><br><span class="line">    <span class="keyword">return</span> net </span><br><span class="line">    </span><br><span class="line"><span class="comment"># 更关心相对误差，解决这个问题的一种方式 用价格预测的对数来衡量差异 (计算回归模型的对数均方根误差)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log_rmse</span>(<span class="params">net, features, labels</span>):</span><br><span class="line">    clipped_preds = torch.clamp(net(features), <span class="number">1</span>, <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>))</span><br><span class="line">    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))</span><br><span class="line">    <span class="keyword">return</span> rmse.item()</span><br><span class="line"></span><br><span class="line">torch.clamp: 这个方法用于将输入张量中的元素限制在指定范围内。在这里，它被用来将神经网络的预测值限制在<span class="number">1</span>到正无穷之间，因为对数函数的定义域是大于<span class="number">0</span>的实数。</span><br><span class="line">net(features): 这一步是将输入特征通过神经网络模型进行前向传播，得到模型的预测值。</span><br><span class="line">torch.log: 这个方法是求取张量的自然对数。在这里，它被用来对神经网络的预测值和真实标签值取对数，以便将回归问题转化为对数空间中的线性问题。</span><br><span class="line">loss: 这个变量代表了损失函数，它用来计算模型预测值与真实标签值之间的差异。</span><br><span class="line">torch.sqrt: 这个方法是求取张量的平方根。在这里，它被用来将均方误差（MSE）转化为均方根误差（RMSE）。</span><br><span class="line">rmse.item(): 这一步是将计算得到的 RMSE 值转化为 Python 标量值，并返回给调用者。</span><br><span class="line">综合起来，这段代码的作用是计算神经网络模型在给定输入特征和真实标签下的对数均方根误差。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练函数将借助 Adam 优化器</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class="line">    train_ls, test_ls = [], []</span><br><span class="line">    train_iter = d2l.load_array((train_features, train_labels), batch_size)</span><br><span class="line">    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l = loss(net(X), y)</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">        train_ls.append(log_rmse(net, train_features, train_labels))</span><br><span class="line">        <span class="keyword">if</span> test_labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            test_ls.append(log_rmse(net, test_features, test_labels))</span><br><span class="line">    <span class="keyword">return</span> train_ls, test_ls</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># K折交叉验证</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_k_fold_data</span>(<span class="params">k, i, X, y</span>):</span><br><span class="line">    <span class="keyword">assert</span> k &gt; <span class="number">1</span></span><br><span class="line">    fold_size = X.shape[<span class="number">0</span>] // k</span><br><span class="line">    X_train, y_train = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        idx = <span class="built_in">slice</span>(j * fold_size, (j + <span class="number">1</span>) * fold_size)</span><br><span class="line">        X_part, y_part = X[idx, :], y[idx]</span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            X_valid, y_valid = X_part, y_part</span><br><span class="line">        <span class="keyword">elif</span> X_train <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            X_train, y_train = X_part, y_part</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X_train = torch.cat([X_train, X_part], <span class="number">0</span>)</span><br><span class="line">            y_train = torch.cat([y_train, y_part], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train, y_train, X_valid, y_valid <span class="comment"># 返回训练集和验证集</span></span><br></pre></td></tr></table></figure>
<div>
                <img src="p/614a8113/K折交叉验证.png" alt="K折交叉验证.png"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[K折交叉验证.png]</p>
            </div>

<p>返回训练和验证误差的平均值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">k_fold</span>(<span class="params">k, X_train, num_epochs, learning_rate, weight_decay, batch_size</span>):</span><br><span class="line">    train_l_sum, valid_l_sum = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class="line">        net = get_net()</span><br><span class="line">        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)</span><br><span class="line">        train_l_sum += train_ls[-<span class="number">1</span>]</span><br><span class="line">        valid_l_sum += valid_ls[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            d2l.plot(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, num_epochs + <span class="number">1</span>)), [train_ls, valid_ls], xlabel=<span class="string">&#x27;epoch&#x27;</span>, ylabel=<span class="string">&#x27;rmse&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs], legend=[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;valid&#x27;</span>], yscale=<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;fold <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, train log rmse <span class="subst">&#123;<span class="built_in">float</span>(train_ls[-<span class="number">1</span>]):f&#125;</span>, valid log rmse <span class="subst">&#123;<span class="built_in">float</span>(valid_ls[-<span class="number">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> train_l_sum / k, valid_l_sum / k</span><br></pre></td></tr></table></figure>

<p>模型选择</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k, num_epochs, lr, weight_decay, batch_size = <span class="number">5</span>, <span class="number">100</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">64</span></span><br><span class="line">train_l, valid_l = k_fold(k, train_features, num_epochs, lr, weight_decay, batch_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;k&#125;</span>-折验证: 平均训练log rmse: <span class="subst">&#123;<span class="built_in">float</span>(train_l):f&#125;</span>, 平均验证log rmse: <span class="subst">&#123;<span class="built_in">float</span>(valid_l):f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>提交Kaggle预测结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_and_pred</span>(<span class="params">train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size</span>):</span><br><span class="line">    net = get_net()</span><br><span class="line">    train_ls, _ = train(net, train_features, train_labels, <span class="literal">None</span>, <span class="literal">None</span>, num_epochs, lr, weight_decay, batch_size)</span><br><span class="line">    d2l.plot(np.arange(<span class="number">1</span>, num_epochs + <span class="number">1</span>), [train_ls], xlabel=<span class="string">&#x27;epoch&#x27;</span>, ylabel=<span class="string">&#x27;log rmse&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs], yscale=<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;train log rmse <span class="subst">&#123;<span class="built_in">float</span>(train_ls[-<span class="number">1</span>]):f&#125;</span>&#x27;</span>)</span><br><span class="line">    preds = net(test_features).detach().numpy()</span><br><span class="line">    test_data[<span class="string">&#x27;SalePrice&#x27;</span>] = pd.Series(preds.reshape(<span class="number">1</span>, -<span class="number">1</span>)[<span class="number">0</span>])</span><br><span class="line">    submission = pd.concat([test_data[<span class="string">&#x27;Id&#x27;</span>], test_data[<span class="string">&#x27;SalePrice&#x27;</span>]], axis=<span class="number">1</span>)</span><br><span class="line">    submission.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">train_and_pred(train_features, test_features, train_labels, test_data, num_epochs, lr, weight_decay, batch_size)</span><br></pre></td></tr></table></figure>

<h4 id="19-卷积层"><a href="#19-卷积层" class="headerlink" title="19 卷积层"></a>19 卷积层</h4><blockquote>
<p>深度学习中常用的一种层类型，用于处理具有空间结构的数据，如图像、音频和视频</p>
</blockquote>
<p>卷积神经网络（CNN）的两个原则</p>
<ul>
<li>平移不变性：无论物品在图像中哪个位置，都能够识别到它</li>
<li>局部性：在局部内提取特征，也就是相邻位置的像素或样本之间存在相关性</li>
</ul>
<table>
<thead>
<tr>
<th>特点</th>
<th>全连接层</th>
<th>卷积层</th>
<th>池化层</th>
</tr>
</thead>
<tbody><tr>
<td><strong>相同点</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>连接方式</td>
<td>全连接</td>
<td>局部连接</td>
<td>无连接</td>
</tr>
<tr>
<td>激活方式</td>
<td>有</td>
<td>有</td>
<td>无</td>
</tr>
<tr>
<td><strong>不同点</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>连接方式</td>
<td>全连接</td>
<td>局部连接和权值共享</td>
<td>无连接</td>
</tr>
<tr>
<td>参数数量</td>
<td>大</td>
<td>较小</td>
<td>无</td>
</tr>
<tr>
<td>处理方式</td>
<td>全局处理</td>
<td>局部特征提取</td>
<td>特征降维</td>
</tr>
</tbody></table>
<p>全连接层流程</p>
<ul>
<li>输入 and 输出 变形为 矩阵 宽度,高度 类似excel表</li>
<li>将权重 变形为 4-D 张量(h,w) 到 (h’,w’)<ul>
<li>权重 存储的是 矩阵，可能会占内存很多(根据神经元数量和特征数量)，但是实际上表示的是一个数值</li>
</ul>
</li>
</ul>
<p>原则#1-平移不变性</p>
<ul>
<li>x的平移导致h的平移</li>
<li>v不应该依赖于(i,j)</li>
<li>解决方案 v(i,j,a,b) &#x3D; v(a,b)</li>
<li>这就是2维 交叉相关</li>
</ul>
<p>解释：</p>
<ul>
<li>x的平移导致h的平移：平移不变性意味着输入数据（通常表示为x）的平移不应该影响神经网络的输出。换句话说，如果输入数据x在空间中平移了一段距离，那么网络的输出应该保持不变，或者说输出也会相应地平移。</li>
<li>v不应该依赖于(i,j)：这意味着网络的输出v不应该依赖于输入数据的位置(i, j)。无论输入数据在空间中的具体位置如何，网络的输出都应该保持不变。</li>
<li>解决方案 v(i,j,a,b) &#x3D; v(a,b)：为了满足平移不变性的要求，作者提出了一种解决方案，即通过二维的交叉相关（cross-correlation）操作来实现。这种操作使得网络的输出v在输入数据的不同位置（i, j）之间保持不变。</li>
</ul>
<p>具体地说，v(i,j,a,b) &#x3D; v(a,b) 意味着输出v在空间中的某个位置(i, j)上的值等于在另一个位置(a, b)上的值，这种情况下，网络的输出在空间平移上是不变的。交叉相关操作是一种滤波操作，可以提取图像中的特征，并且保持输入数据在空间平移上的不变性，因此非常适合应用在具有平移不变性要求的任务中，比如图像识别任务。</p>
<p>原则#2-局部性(只看局部，排除其他部分)</p>
<ul>
<li>当评估h(i,j)时，不应该用远离x(i,j)的参数</li>
<li>解决方案：当 |a| or |b| &gt; U 时，使得v(a,b) &#x3D; 0</li>
</ul>
<p>深度学习中的卷积层 &#x3D; 二维交叉相关</p>
<p>二维交叉相关</p>
<ul>
<li>输入X</li>
<li>核W：可以学习的参数，不同的核可以达到不同的效果：图片高斯模糊、图片边缘检测、图片锐化</li>
<li>偏差b</li>
<li>输出Y： Y&#x3D;X*W + b</li>
</ul>
<p>二维卷积 和 二维交叉相关 是对称的，实际上没区别</p>
<p>一维和三维交叉相关</p>
<ul>
<li>一维<ul>
<li>文本</li>
<li>语言</li>
<li>时间序列</li>
</ul>
</li>
<li>三维<ul>
<li>视频</li>
<li>医学图像</li>
<li>气象地图</li>
</ul>
</li>
</ul>
<p>总结：</p>
<ol>
<li>对全连接层 使用 平移不变性 和 局部性 得到卷积层</li>
<li>卷积层 将输入和核矩阵进行交叉相关，加上偏移后得到输出</li>
<li>核矩阵和偏移是可学习的参数</li>
<li>核矩阵的大小是超参数</li>
</ol>
<p>代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图像卷积  使用 互相关运算</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入X，核矩阵K</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d</span>(<span class="params">X, K</span>):</span><br><span class="line">  <span class="comment"># 计算二维互相关运算</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 行数 和 列数</span></span><br><span class="line">  h, w = K.shape</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 输出Y(高宽) = 输入的高-核高+1  输如的宽-核宽+1</span></span><br><span class="line">  Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">      Y[i, j] = (X[i: i + h, j: j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">  <span class="keyword">return</span> Y</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>检验上述二维互相关运算的输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X = = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],[<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>]，[<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]])</span><br><span class="line"></span><br><span class="line">K = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>]，[<span class="number">2.0</span>, <span class="number">3.0</span>]])</span><br><span class="line"></span><br><span class="line">corr2d(X, K)</span><br><span class="line"></span><br><span class="line">Out[<span class="number">2</span>]: tensor(</span><br><span class="line">  [<span class="number">19.</span>, <span class="number">25.</span>],</span><br><span class="line">  [<span class="number">37.</span>, <span class="number">43.</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>实现二维卷积层</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Conv2D</span>(nn.Module):</span><br><span class="line">  <span class="comment"># kernel_size 超参数</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel_size</span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    <span class="comment"># 随机值</span></span><br><span class="line">    self.weight = nn.Parameter(torch.rand(kernel_size))</span><br><span class="line">    <span class="comment"># 偏移 标量</span></span><br><span class="line">    self.bias = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># 互相关运算 + 偏移</span></span><br><span class="line">    <span class="keyword">return</span> corr2d(x, self.weight) + self.bias</span><br></pre></td></tr></table></figure>
<p>卷积层简单应用：检测图像中不同颜色的边缘</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">X = trouch.ones((<span class="number">6</span>,<span class="number">8</span>))</span><br><span class="line">X[: <span class="number">2</span>:<span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">X</span><br><span class="line"></span><br><span class="line">K = torch.tensor([[<span class="number">1.0</span>, -<span class="number">1.0</span>]])</span><br><span class="line"></span><br><span class="line">Y = corr2d(X, K)</span><br><span class="line">Y</span><br><span class="line">Out[<span class="number">6</span>]: tensor([<span class="number">0.</span>,  ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积核K只能检测垂直边缘</span></span><br><span class="line">corr2d(X.t(), K)</span><br><span class="line">Out[<span class="number">7</span>]: tensor(...</span><br></pre></td></tr></table></figure>

<p>学习由X生成Y的卷积核</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入的通道1 输出的通道也是1 卷积核尺寸1*2</span></span><br><span class="line">conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">X = X.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">Y = Y.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">  Y_hat = conv2d(X)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 损失函数</span></span><br><span class="line">  l = (Y_hat - Y) ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">  conv2d.zero_grad()</span><br><span class="line">  l.<span class="built_in">sum</span>().backward()</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 梯度下降 -= 学习率3e-2  * 梯度</span></span><br><span class="line">  conv2d.weight.data[:] -= <span class="number">3e-2</span> * conv2d.weight.grad</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 每两次 打印一次损失函数</span></span><br><span class="line">  <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;l.<span class="built_in">sum</span>():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习的卷积核的权重张量</span></span><br><span class="line">conv2d.weight.data.reshape((<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">Out[<span class="number">9</span>]: tensor([[ <span class="number">0.9186</span>, -<span class="number">1.0584</span>]])</span><br></pre></td></tr></table></figure>


<h4 id="22-池化层"><a href="#22-池化层" class="headerlink" title="22 池化层"></a>22 池化层</h4><blockquote>
<p>池化层是卷积神经网络CNN的常见层次，作用是通过减小特征图的空间尺寸来降低网络的计算复杂度，并且提取特征的不变性。 降维、特征不变性、提取主要特征</p>
</blockquote>
<ul>
<li>积对位置敏感<ul>
<li>检测垂直边缘</li>
</ul>
</li>
<li>需要一定程度的平移不变性<ul>
<li>照明，物体位置，比例，外观等因图像而已</li>
</ul>
</li>
</ul>
<p>二维最大池化</p>
<ul>
<li>返回滑动窗口中的最大值，而不是返回和<ul>
<li>核尺寸内选中的所有数值 返回最大的</li>
</ul>
</li>
</ul>
<p>填充，步幅和多个通道</p>
<ul>
<li>池化层和卷积层一样，都是使用滑动窗口，但是池化层没有偏移，没有可学习的参数，没有激活函数</li>
<li>在每个输入通道应用池化层 以获得相应的输出通道</li>
<li>输出通道数&#x3D;输入通道数 每个输入通道都做一次池化层</li>
</ul>
<p>最大池化层：每个窗口中最强的模式信号<br>平均池化层：将最大池化层中 最大操作 替换成 平均</p>
<p>总结：</p>
<ul>
<li>池化层返回窗口中最大或平均值</li>
<li>作用：缓解卷积层对位置的敏感性（通常池化层在卷积层后）</li>
<li>同样有 窗口大小、填充、步幅 作为超参数</li>
</ul>
<p>代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># 池化层窗口 高宽</span></span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出Y(高宽)这里假设单通道 = 输入的高-池化层窗口高+1  输如的宽-池化层窗口宽+1</span></span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">          Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">          Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证二维最大池化层的输出</span></span><br><span class="line">X = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]])</span><br><span class="line">pool2d(X, (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">Out[<span class="number">3</span>]: tensor([[<span class="number">4.</span>, <span class="number">5.</span>], [<span class="number">7.</span>, <span class="number">8.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证二维平均池化层的输出</span></span><br><span class="line">pool2d(X, (<span class="number">2</span>, <span class="number">2</span>), mode=<span class="string">&#x27;avg&#x27;</span>)</span><br><span class="line">Out[<span class="number">4</span>]: tensor([[<span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">5.</span>, <span class="number">6.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充和步幅</span></span><br><span class="line">X = torch.arange(<span class="number">16</span>, dtype=torch.float32).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">Out[<span class="number">5</span>]: tensor([[[ <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>] [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>, <span class="number">7.</span>][<span class="number">8.</span>, <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>][[<span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>]]]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 深度学习框架中的步幅和池化窗口的大小相同</span></span><br><span class="line">pool2d = nn.MaxPool2d(<span class="number">3</span>)</span><br><span class="line">pool2d(X)</span><br><span class="line">Out[<span class="number">6</span>]: tensor([[[[ <span class="number">10.</span>]]]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充和步幅可以手动设定</span></span><br><span class="line">pool2d = nn.MaxPool2d(<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">pool2d(X)</span><br><span class="line">Out[<span class="number">7</span>]: tensor([[[[ <span class="number">5.</span>, <span class="number">7.</span>], [<span class="number">13.</span>, <span class="number">15.</span>]]]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定一个任意大小的矩阵池化窗口，并分别设定填充和步幅的高度和宽度</span></span><br><span class="line">pool2d = nn.MaxPool2d((<span class="number">2</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">pool2d(X)</span><br><span class="line">Out[<span class="number">8</span>]: tensor([[[[ <span class="number">1.</span>, <span class="number">3.</span>], [ <span class="number">9.</span>, <span class="number">11.</span>], [<span class="number">13.</span>, <span class="number">15.</span>]]]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 池化层在每个通道上单独运算</span></span><br><span class="line">X = torch.cat([X, X+<span class="number">1</span>], <span class="number">1</span>)</span><br><span class="line">X</span><br><span class="line">Out[<span class="number">9</span>]: tensor([[[[ <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [ <span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>, <span class="number">7.</span>], [ <span class="number">8.</span>, <span class="number">9.</span>, <span class="number">10.</span>, <span class="number">11.</span>], [<span class="number">12.</span>, <span class="number">13.</span>, <span class="number">14.</span>, <span class="number">15.</span>]]]])</span><br><span class="line"></span><br><span class="line">pool2d = nn.MaxPool2d(<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">pool2d(X)</span><br><span class="line">Out[<span class="number">10</span>]: tensor([[[[ <span class="number">5.</span>, <span class="number">7.</span>], [<span class="number">13.</span>, <span class="number">15.</span>], [<span class="number">6.</span>, <span class="number">8.</span>], [<span class="number">14.</span>, <span class="number">16.</span>]]]])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="33-单机多卡并行"><a href="#33-单机多卡并行" class="headerlink" title="33 单机多卡并行"></a>33 单机多卡并行</h4><blockquote>
<p>在<code>训练和预测</code>过程中，将一个<code>小批量计算</code>切分到多个GPU加速计算</p>
</blockquote>
<p>数据并行：将数据分成n块，每个GPU拿到完整的参数计算一块数据的梯度，然后将梯度合并</p>
<ul>
<li>性能好，用于小模型<div>
              <img src="p/614a8113/数据并行.png" alt="数据并行.png"></img>
              <p style="
              display: flex;
              color: #999;
              justify-content: center;
              font-size: 0.8rem;
              position: relative;
              top: -1rem;
              right: 50%;
              left: 50%;
              transform: translateX(-50%);
              ">[数据并行.png]</p>
          </div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> 读一个数据块</span><br><span class="line"><span class="number">2.</span> 拿到参数</span><br><span class="line"><span class="number">3.</span> 计算梯度</span><br><span class="line"><span class="number">4.</span> 发出梯度</span><br><span class="line"><span class="number">5.</span> 合并梯度</span><br></pre></td></tr></table></figure></li>
</ul>
<p>模型并行：将模型分成n块，每个GPU计算模型的前向和方向结果</p>
<ul>
<li>用于模型大到单GPU无法容纳，用在超大模型上</li>
</ul>
<h4 id="35-分布式训练"><a href="#35-分布式训练" class="headerlink" title="35 分布式训练"></a>35 分布式训练</h4><h4 id="37-微调"><a href="#37-微调" class="headerlink" title="37 微调"></a>37 微调</h4><h4 id="64-注意力机制"><a href="#64-注意力机制" class="headerlink" title="64 注意力机制"></a>64 注意力机制</h4><blockquote>
<p>注意力机制是<code>一种模拟人类视觉或听觉系统的方法</code>，它允许神经网络在处理输入数据时集中关注重要的部分，并且动态地调整对不同部分的注意力。在深度学习中，其目的是使模型能够更加集中地关注输入数据的特定部分，从而提高模型的性能和泛化能力。</p>
</blockquote>
<blockquote>
<p>注意力机制的核心思想是在模型中引入<code>可学习的权重</code>，用来动态地调整不同输入的重要性，并且根据这些<code>权重</code>来<code>加权输入数据</code>，以产生输出。</p>
</blockquote>
<p>注意力机制通常包含一下几个组成部分</p>
<ol>
<li>注意力得分计算：根据某种方法(<code>根据输入数据和当前的任务的特性</code>)计算每个输入的注意力得分.</li>
<li>注意力权重计算：根据注意力得分计算每个输入的注意力权重，通常使用softmax函数来将<code>得分</code>归一化为<code>概率分布</code>.</li>
<li>加权求和：将<code>注意力权重</code>对<code>输入数据</code>进行加权求和，产生输出</li>
</ol>
<ul>
<li>卷积、全连接、池化层 都只考虑不随意线索<ul>
<li>卷积成 提取局部特征</li>
<li>全连接 提取特征映射到输出层</li>
<li>池化层 减少特征图的维度和计算量</li>
</ul>
</li>
<li>注意力机制 则显示的考虑随意线索<ul>
<li>随意线索被称为 查询 query</li>
<li>每个输入是一个值 value 和 不随意线索 key 的对</li>
<li>通过注意力池化层来由偏向性的选择某些输入</li>
</ul>
</li>
</ul>
<p>实现：<br>非参注意力池化层</p>
<ul>
<li>给定数据(xi,yi),i &#x3D; 1,…n</li>
<li>平均池化是最简单的方案</li>
<li>更好的方案是 60年代提出的 Nadaraya-Watson 核回归</li>
</ul>
<p>Nadaraya-Watson 核回归</p>
<blockquote>
<p>一种非参数的回归方法，用于估计输入变量（自变量）和输出变量（因变量）之间的关系，特别是在处理非线性数据时很有用。该方法通常用于回归问题，尤其是在样本量较小或数据结构复杂的情况下。</p>
</blockquote>
<ul>
<li>使用高斯核 K(u)&#x3D;1&#x2F;sqrt(2π)exp(-u²&#x2F;2)</li>
</ul>
<p>参数化的注意力机制</p>
<ul>
<li>在之前基础上引入可以学习的w</li>
</ul>
<p>总结：</p>
<ul>
<li>心理学认为 人通过随意线索和不随意线索 选择注意点</li>
<li>注意力机制中，通过query(随意线索)和key(不随意线索)来有偏向性的选择输入</li>
</ul>
<p>下面是多个不同的权重设计</p>
<p>代码实现<br>注意力汇聚：Nadaraya-Watson 核回归</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line">n_train = <span class="number">50</span></span><br><span class="line">x_train, _ = torch.sort(torch.rand(n_train) * <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">  <span class="keyword">return</span> <span class="number">2</span> * torch.sin(x) + x**<span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">y_train = f(x_train) + torch.normal(<span class="number">0.0</span>, <span class="number">0.5</span>, (n_train,))</span><br><span class="line">x_test = torch.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.1</span>)</span><br><span class="line">y_truth = f(x_test)</span><br><span class="line">n_test = <span class="built_in">len</span>(x_test)</span><br><span class="line">n_test</span><br><span class="line"></span><br><span class="line">Out[<span class="number">2</span>]: <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_kernel_reg</span>(<span class="params">y_hat</span>):</span><br><span class="line">  d2l.plot(x_test, [y_truth, y_hat], <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, legend=[<span class="string">&#x27;Truth&#x27;</span>, xlim=[<span class="number">0</span>, <span class="number">5</span>], ylim=[-<span class="number">1</span>, <span class="number">5</span>])</span><br><span class="line">  d2l.plt.plot(x_train, y_train, <span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">y_hat = torch.repeat_interleave(y_train.mean(), n_test)</span><br><span class="line">plot_kernel_reg(y_hat)</span><br></pre></td></tr></table></figure>

<p>非参数注意力汇聚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_repeat = x_test.repeat_interleave(n_train).reshape((-<span class="number">1</span>, n_train))</span><br><span class="line"></span><br><span class="line">attention_weights = nn.functional.softmax(-(X_repeat - x_train) ** <span class="number">2</span>)</span><br><span class="line">y_hat = torch.matmul(attention_weights, y_train)</span><br><span class="line">plot_kernel_reg(y_hat)</span><br></pre></td></tr></table></figure>

<h4 id="68-Transformer"><a href="#68-Transformer" class="headerlink" title="68 Transformer"></a>68 Transformer</h4><blockquote>
<p>一个基于注意力机制的序列到序列模型，用于处理序列数据</p>
</blockquote>
<ul>
<li>基于<code>编码器-解码器 架构</code>处理序列对</li>
<li>跟使用注意力的 seq2seq 不同， Tf 纯基于注意力</li>
</ul>
<div>
                <img src="p/614a8113/Transformer.png" alt="Transformer.png"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[Transformer.png]</p>
            </div>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Sources</span><br><span class="line">Embedding</span><br><span class="line">Positional encoding</span><br><span class="line">执行n次 Transformer块</span><br><span class="line">Encoder</span><br><span class="line">信息传递 给 每一个 Transformer块</span><br></pre></td></tr></table></figure>
<p>多头注意力 Multi-Head Attention</p>
<ul>
<li>对统一key,value,query 希望抽取不同的信息<ul>
<li>例如短距离关系和长距离关系</li>
</ul>
</li>
<li>多头注意力使用h个独立的注意力池化<ul>
<li>合并各个头 输出得到最终输出</li>
</ul>
</li>
</ul>
<p>结果是多头 n×x的 多头</p>
<p>有掩码的多头注意力 Masked Multi-Head Attention</p>
<ul>
<li>解码器对序列中的一个元素输出时，不应该考虑该元素之后的元素</li>
<li>可以通过掩码来实现 Valid lens<ul>
<li>也就是计算 xi 输出时，假装当前序列长度为xi， 把合法长度设置成i(Valid lens),在算Softmax的时候，不算它的权重，不会对后面的key v 进行权重</li>
</ul>
</li>
</ul>
<p>基于位置的前馈网络 Position-wise Feed-Forward Networks(FFN)</p>
<ul>
<li>输入形状由三维(b,n,d) 变换成二维(bn,d)，因为n是序列的长度，会变，不能当成特征</li>
<li>作用两个全连接层</li>
<li>输出形状由二维(bn,d) 变换成三维(b,n,d)</li>
<li>等价于两层核窗口为1的一维卷积层</li>
</ul>
<p>层归一化 Add &amp; norm</p>
<ul>
<li>批量归一化对每个特征&#x2F;通道里元素进行归一化<ul>
<li>不适合序列长度会变的NLP应用</li>
</ul>
</li>
<li>层归一化对每个样本里的免俗进行归一化</li>
</ul>
<div>
                <img src="p/614a8113/层归一化.png" alt="层归一化.png"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[层归一化.png]</p>
            </div>



<h3 id="斯坦福21秋季：实用机器学习"><a href="#斯坦福21秋季：实用机器学习" class="headerlink" title="斯坦福21秋季：实用机器学习"></a>斯坦福21秋季：实用机器学习</h3><h4 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h4><div>
                <img src="p/614a8113/斯坦福21秋季：实用机器学习-例如：预测房屋销售价格.png" alt="斯坦福21秋季：实用机器学习-例如：预测房屋销售价格.png"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[斯坦福21秋季：实用机器学习-例如：预测房屋销售价格.png]</p>
            </div>


<h4 id="1-2-数据获取"><a href="#1-2-数据获取" class="headerlink" title="1.2 数据获取"></a>1.2 数据获取</h4><ul>
<li>现有数据集<ul>
<li>Paerswithcodes Datasets <a href="https://paperswithcode.com/datasets" target="_blank" rel="noopener">https://paperswithcode.com/datasets</a></li>
<li>Kaggle Datasets <a href="https://www.kaggle.com/datasets" target="_blank" rel="noopener">https://www.kaggle.com/datasets</a></li>
<li>Google Dataset search <a href="https://datasetsearch.research.google.com/" target="_blank" rel="noopener">https://datasetsearch.research.google.com/</a></li>
<li>Various toolkits datasets: tensorflow,huggingface</li>
<li>OpenData on Aws(100+ large-scale raw data批级别) 例如：整个气象数据集，需要自己处理数据</li>
</ul>
</li>
<li>python爬取</li>
</ul>
<p>找不到数据集</p>
<ul>
<li>生成数据集 GANs</li>
<li>数据增强 图片</li>
<li>文本 通过翻译成多国语言并且翻译回来 可以获取多个 不同语义相同意思的数据集</li>
</ul>
<h4 id="1-3-网页的数据抓取"><a href="#1-3-网页的数据抓取" class="headerlink" title="1.3 网页的数据抓取"></a>1.3 网页的数据抓取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># selenium 抓取数据</span></span><br><span class="line"><span class="keyword">import</span> selenium <span class="keyword">from</span> webdriver</span><br><span class="line">chrome_options = webdriver.ChromeOPtions()</span><br><span class="line">chrome_options.headless = <span class="literal">True</span></span><br><span class="line">chrome = webdriver.Chrome(Chrome_options=chrome_options)</span><br><span class="line">page = chrome.get(url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理数据</span></span><br><span class="line">page = BeautifulSoup(<span class="built_in">open</span>(html_path, <span class="string">&#x27;r&#x27;</span>))</span><br><span class="line">links = [a[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">for</span> a <span class="keyword">in</span> page.find_all(<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;list-card-link&#x27;</span>)]</span><br><span class="line">ids = [l.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">2</span>]].split(<span class="string">&#x27;_&#x27;</span>)(<span class="number">0</span>) <span class="keyword">for</span> l <span class="keyword">in</span> links]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 整理并导出数据</span></span><br><span class="line">sold_items = [a.text <span class="keyword">for</span> a <span class="keyword">in</span> page.find(<span class="string">&#x27;div&#x27;</span>, <span class="string">&#x27;ds-home-details-chip&#x27;</span>).find(<span class="string">&#x27;p&#x27;</span>).find_all(<span class="string">&#x27;span&#x27;</span>)]</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> sold_items:</span><br><span class="line">  <span class="keyword">if</span> <span class="string">&#x27;Sold&#x27;</span>:<span class="string">&#x27; in item:</span></span><br><span class="line"><span class="string">    result[&#x27;</span>Sold Price<span class="string">&#x27;] = item.split(&#x27;</span> <span class="string">&#x27;)[1]</span></span><br><span class="line"><span class="string">  if &#x27;</span>Sold on<span class="string">&#x27;:&#x27;</span> <span class="keyword">in</span> item:</span><br><span class="line">    result[<span class="string">&#x27;Sold On&#x27;</span>] = item.split(<span class="string">&#x27; &#x27;</span>)[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 获取所有图片url</span></span><br><span class="line">p = <span class="string">r&#x27;https:\\/\\/photos.zillowstatic.com\\/fp\\/([\d\w\-\_]+).jpg&#x27;</span></span><br><span class="line">ids = [a.split(<span class="string">&#x27;-&#x27;</span>)[<span class="number">0</span>] <span class="keyword">for</span> a <span class="keyword">in</span> re.findall(p,html)]</span><br><span class="line">urls = [<span class="string">f&#x27;https://photos.zillowstatic.com/fp/<span class="subst">&#123;<span class="built_in">id</span>&#125;</span>-uncropped_scaled_within_1536_1152.jpg&#x27;</span> <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> ids]</span><br></pre></td></tr></table></figure>


<h4 id="1-4-数据标注"><a href="#1-4-数据标注" class="headerlink" title="1.4 数据标注"></a>1.4 数据标注</h4><p>手动标注 费时<br>众包标注 费钱<br>半监督学习</p>
<p>策略1：将数据标注方式简单化<br>策略2：半监督学习，利用少量标记数据和大量未标记数据进行训练<br>策略3：主动学习，人干预，手动标记重要或明确的数据</p>
<ul>
<li>在已有的数据集中，找到最不确定的数据，让人标注</li>
<li>从模型的不同版本中找到最不确定的数据</li>
</ul>
<div>
                <img src="p/614a8113/半监督学习.png" alt="半监督学习"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[半监督学习]</p>
            </div>

<p>主动学习+自学习</p>
<h4 id="3-1-8分钟机器学习介绍"><a href="#3-1-8分钟机器学习介绍" class="headerlink" title="3.1 8分钟机器学习介绍"></a>3.1 8分钟机器学习介绍</h4><p>机器学习算法</p>
<ul>
<li>监督学习 Supervised Learning 在有标号的数据上训练模型，任务就是预测标号<ul>
<li>重要<ul>
<li>训练<ul>
<li>损失函数 Loss Function</li>
</ul>
</li>
<li>模型<ul>
<li>输入</li>
<li>输出</li>
</ul>
</li>
</ul>
</li>
<li>预测房子的价格</li>
<li>预测图片的类别</li>
<li>自监督学习 Self-Supervised Learning 标号来自于数据本身</li>
</ul>
</li>
<li>无监督学习 Unsupervised Learning 在没有标号的数据上训练模型，任务也不是预测标号<ul>
<li>GAN 生成对抗模型</li>
</ul>
</li>
<li>强化学习 Reinforcement Learning 通过与环境的交互学习，任务是找到最优策略<ul>
<li>机器人学习走路</li>
<li>游戏AI</li>
</ul>
</li>
</ul>
<h4 id="3-2-最简单也最常用的决策树-Decision-Tree"><a href="#3-2-最简单也最常用的决策树-Decision-Tree" class="headerlink" title="3.2 最简单也最常用的决策树 Decision Tree"></a>3.2 最简单也最常用的决策树 Decision Tree</h4><p>分类树 Classification Tree</p>
<ul>
<li>节点判断 是or不是<ul>
<li>不是 break</li>
<li>是 是否要对标号进行提升<ul>
<li>是 标注数据 break</li>
<li>不是 执行类别判断<ul>
<li>…</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>回归树 Regression Tree</p>
<ul>
<li>1级分类判断<ul>
<li>不是 break</li>
<li>是 2级分类判断<ul>
<li>…</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="从0入门人工智能"><a href="#从0入门人工智能" class="headerlink" title="从0入门人工智能"></a>从0入门人工智能</h3><h4 id="介绍以及环境配置"><a href="#介绍以及环境配置" class="headerlink" title="介绍以及环境配置"></a>介绍以及环境配置</h4><h5 id="基础工具包"><a href="#基础工具包" class="headerlink" title="基础工具包"></a>基础工具包</h5><p>matplotlib</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">x = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">y = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(x,y)</span><br><span class="line">fig1 = plt.figure(figsize=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment"># plt.plot(x,y) # 折线图</span></span><br><span class="line">plt.scatter(x,y) <span class="comment"># 散点图</span></span><br><span class="line">plt.title(<span class="string">&#x27;y vs x&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>numpy</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 生成矩阵：对角线是1 其他位置都是0</span></span><br><span class="line">a = np.eye(<span class="number">5</span>)</span><br><span class="line">b = np.ones([<span class="number">5</span>,<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a),a)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(b),b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看维度</span></span><br><span class="line"><span class="built_in">print</span>(a.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数组加法</span></span><br><span class="line">c = a + b</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(c),c)</span><br></pre></td></tr></table></figure>
<p>pandas</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对本地的csv进行加载</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;data.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(data), data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定位，获取第x行所有列</span></span><br><span class="line">x = data.loc[:,<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定位，获取第x行所有列,并且y&gt;50</span></span><br><span class="line">c = data.loc[:,<span class="string">&#x27;x&#x27;</span>][y&gt;<span class="number">50</span>]</span><br><span class="line"></span><br><span class="line">data_array = np.array(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(data_array), data_array)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line">data_new = data + <span class="number">10</span></span><br><span class="line">data_new.head()</span><br><span class="line">data_new.to_csv(<span class="string">&#x27;data_new.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="机器学习介绍"><a href="#机器学习介绍" class="headerlink" title="机器学习介绍"></a>机器学习介绍</h5><p>什么是机器学习？</p>
<p>小明1月工资1000，每月增长10%，第10月是多少？<br>y &#x3D; 1000 x 1.1^x</p>
<p>符号：输入第x月 得出结果<br>机器学习：训练数据喂给计算机，计算机自动求解数据关系，在新的数据上做出预测和给出建议。</p>
<h5 id="机器学习-线性回归"><a href="#机器学习-线性回归" class="headerlink" title="机器学习-线性回归"></a>机器学习-线性回归</h5><p>回归分析：根据数据，确定两种或两种以上变量 之间 互相依赖的定量关系</p>
<p>线性回归：回归分析中，变量和因变量存在线性关系<br>函数表达式：</p>
<ul>
<li>线性回归<ul>
<li>距离S &#x3D; 速度 x t + S0</li>
</ul>
</li>
<li>非线性回归<ul>
<li>距离S &#x3D; 加速度 x T^2 + S0</li>
</ul>
</li>
</ul>
<p>问题：面积110平米售价150万是否值得投资？</p>
<ol>
<li>确定 面积 和 售价 的定量关系<ul>
<li>售价P &#x3D; f(面积 a)</li>
</ul>
</li>
<li>根据关系预测合理价格<ul>
<li>P(a&#x3D;110) &#x3D; f(110)</li>
</ul>
</li>
<li>做出判断</li>
</ol>
<p>线性模型： y &#x3D; ax+b</p>
<p>如何寻找最合适的a、b？<br>问题转换：假设x为变量，y是对应的结果  y’是模型输出结果，目标变为 y’ 尽可能接近y</p>
<div>
                <img src="p/614a8113/如何寻找最合适的a、b.png" alt="如何寻找最合适的a、b.png"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[如何寻找最合适的a、b.png]</p>
            </div>
公式：m为样本数；y'i预测值和yi实际值之间的距离

<p>求导之后 变成了</p>
<div>
                <img src="p/614a8113/如何寻找最合适的a、b_转化.png" alt="如何寻找最合适的a、b_转化.png"></img>
                <p style="
                display: flex;
                color: #999;
                justify-content: center;
                font-size: 0.8rem;
                position: relative;
                top: -1rem;
                right: 50%;
                left: 50%;
                transform: translateX(-50%);
                ">[如何寻找最合适的a、b_转化.png]</p>
            </div>
尽可能找到a和b，让损失函数J最小（最小值）

<p>如何求解找a</p>
<p>Scikit-learn <a href="https://scikit-learn.org/" target="_blank" rel="noopener">https://scikit-learn.org/</a></p>
<ul>
<li>继承了机器学习中各类成熟的算法</li>
<li>不支持Python之外的语言，不支持深度学习和强化学习</li>
</ul>
<p>使用 Scikit-learn 解决线性回归问题</p>
<blockquote>
<p><a href="https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> slearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model = LLinearRegression()</span><br><span class="line">lr_model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示a和b</span></span><br><span class="line">a = lr_model.coef_</span><br><span class="line">b = lr_model.intercept_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对新数据做预测</span></span><br><span class="line">prodictions = lr_model.predict(x_new)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据 y = 2x + 5</span></span><br><span class="line">x y</span><br><span class="line"><span class="number">1</span> <span class="number">7</span></span><br><span class="line"><span class="number">2</span> <span class="number">9</span></span><br><span class="line"><span class="number">3</span> <span class="number">11</span></span><br><span class="line"><span class="number">4</span> <span class="number">13</span></span><br><span class="line"><span class="number">5</span> <span class="number">15</span></span><br><span class="line"><span class="number">6</span> <span class="number">17</span></span><br><span class="line"><span class="number">7</span> <span class="number">19</span></span><br><span class="line"><span class="number">8</span> <span class="number">21</span></span><br><span class="line"><span class="number">9</span> <span class="number">23</span></span><br><span class="line"><span class="number">10</span> <span class="number">25</span></span><br><span class="line"></span><br><span class="line">均方误差(MSE)</span><br><span class="line">- 越小越好</span><br><span class="line"><span class="keyword">from</span> s</span><br><span class="line"></span><br><span class="line">R方值(R^<span class="number">2</span>) = <span class="number">1</span> - MSE/方差</span><br><span class="line">- 越接近<span class="number">1</span>越好</span><br><span class="line"></span><br><span class="line">y和y<span class="string">&#x27;的集中度越高越好（越接近直线分布）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">实现方法1</span></span><br><span class="line"><span class="string">from sklearn.metrics import mean_squared_error, r2_score</span></span><br><span class="line"><span class="string">MSE = mean_squared_error(y, y_predict)</span></span><br><span class="line"><span class="string">R2 = r2_score(y, y_predict)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">实现方法2 画图对比</span></span><br><span class="line"><span class="string">from matplotlib import pyplot as plt</span></span><br><span class="line"><span class="string">plt.scatter(y, y&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多张图 同时展示</span></span><br><span class="line">fig1 = plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.scatter(x1, y1)</span><br><span class="line"></span><br><span class="line">fig2 = plt.subplot(<span class="number">212</span>)</span><br><span class="line">plt.scatter(x2, y2)</span><br></pre></td></tr></table></figure>

<p>LR实现线性预测</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the data</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;week2/generated_data.csv&#x27;</span>)</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印 类型 维度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(data), data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data 赋值</span></span><br><span class="line">x = data.loc[:, <span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">y = data.loc[:, <span class="string">&#x27;y&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示 数据</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line">plt.figure()</span><br><span class="line"><span class="comment"># 创建散点图</span></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立 linear regression 模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.array(x)</span><br><span class="line">x = x.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y = np.array(y)</span><br><span class="line">y = y.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">lr_model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测 y</span></span><br><span class="line">y_predict = lr_model.predict(x)</span><br><span class="line"><span class="built_in">print</span>(y_predict)</span><br><span class="line"></span><br><span class="line">y3 = lr_model.predict([[<span class="number">3.5</span>]])</span><br><span class="line"><span class="built_in">print</span>(y3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示a和b y=ax+b的值</span></span><br><span class="line">a = lr_model.coef_</span><br><span class="line">b = lr_model.intercept_</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a,b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2 获取ab的值</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line">MSE = mean_squared_error(y, y_predict)</span><br><span class="line">R2 = r2_score(y, y_predict)</span><br><span class="line"><span class="built_in">print</span>(MSE, R2)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(y, y_predict)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上面的结果差距太大，不适用</p>
<p>增加多因子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_mu</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-5-多因子线性回归实战"><a href="#2-5-多因子线性回归实战" class="headerlink" title="2-5 多因子线性回归实战"></a>2-5 多因子线性回归实战</h4><p>多因子房价预测</p>
<ol>
<li>以面积作为输入变量，建立单因子模型，评估模型表现，可视化线性回归预测结果</li>
<li>以income&#x2F;house_age&#x2F;numbers of rooms&#x2F;population&#x2F;area为输入变量，建立多因子模型，评估模型表现</li>
<li>预测 Income&#x3D;65000, House Age&#x3D;5, Number of Rooms&#x3D;5,population&#x3D;30000,size&#x3D;200的合理房价</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the data</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;week2/usa_housing_price.csv&#x27;</span>)</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">30</span>, <span class="number">12</span>))</span><br><span class="line"></span><br><span class="line">fig1 = plt.subplot(<span class="number">231</span>)</span><br><span class="line">plt.scatter(data.loc[:, <span class="string">&#x27;Avg. Area Income&#x27;</span>], data.loc[:, <span class="string">&#x27;Price&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Price VS Income&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig2 = plt.subplot(<span class="number">232</span>)</span><br><span class="line">plt.scatter(data.loc[:, <span class="string">&#x27;Avg. Area House Age&#x27;</span>], data.loc[:, <span class="string">&#x27;Price&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Price VS House Age&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig3 = plt.subplot(<span class="number">233</span>)</span><br><span class="line">plt.scatter(data.loc[:, <span class="string">&#x27;Avg. Area Number of Rooms&#x27;</span>], data.loc[:, <span class="string">&#x27;Price&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Price VS Number of Rooms&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig4 = plt.subplot(<span class="number">234</span>)</span><br><span class="line">plt.scatter(data.loc[:, <span class="string">&#x27;Area Population&#x27;</span>], data.loc[:, <span class="string">&#x27;Price&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Price VS Population&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig5 = plt.subplot(<span class="number">235</span>)</span><br><span class="line">plt.scatter(data.loc[:, <span class="string">&#x27;size&#x27;</span>], data.loc[:, <span class="string">&#x27;Price&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Price VS size&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 单因子</span></span><br><span class="line">x = data.loc[:, <span class="string">&#x27;size&#x27;</span>]</span><br><span class="line">y = data.loc[:, <span class="string">&#x27;Price&#x27;</span>]</span><br><span class="line">y.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立 单因子 模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line"></span><br><span class="line">x = np.array(x)</span><br><span class="line">x = x.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y = np.array(y)</span><br><span class="line">y = y.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">lr_model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 price vs size</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对新数据做预测</span></span><br><span class="line">y_prodict_1 = lr_model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># mean_squared_error(实际结果, 预测结果)</span></span><br><span class="line">MSE = mean_squared_error(y, y_prodict_1)</span><br><span class="line">R2 = r2_score(y, y_prodict_1)</span><br><span class="line"><span class="built_in">print</span>(MSE, R2)</span><br><span class="line"></span><br><span class="line">fig6 = plt.figure()</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(X, y_prodict_1, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">x_multi = data.drop([<span class="string">&#x27;Price&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">x_multi</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立 多因子 模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model_multi = LinearRegression()</span><br><span class="line"></span><br><span class="line">lr_model_multi.fit(x_multi,y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对新数据做预测</span></span><br><span class="line">y_prodict_multi = lr_model_multi.predict(x_multi)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># mean_squared_error(实际结果, 预测结果)</span></span><br><span class="line">MSE = mean_squared_error(y, y_prodict_multi)</span><br><span class="line">R2 = r2_score(y, y_prodict_multi)</span><br><span class="line"><span class="built_in">print</span>(MSE, R2)</span><br><span class="line"></span><br><span class="line">fig8 = plt.figure()</span><br><span class="line">plt.scatter(y, y_prodict_multi)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对具体的需求 进行预测</span></span><br><span class="line">x_test = [<span class="number">65000</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">30000</span>, <span class="number">200</span>]</span><br><span class="line">x_test = np.array(x_test).reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(x_test)</span><br><span class="line">y_test_predict = lr_model_multi.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y_test_predict)</span><br></pre></td></tr></table></figure>



<h4 id="3-1-机器学习-逻辑回归"><a href="#3-1-机器学习-逻辑回归" class="headerlink" title="3-1 机器学习-逻辑回归"></a>3-1 机器学习-逻辑回归</h4><p>解决分类问题</p>
<p>什么是分类问题？</p>
<p>垃圾邮件检测</p>
<ul>
<li>输入：电子邮件</li>
<li>输出：是否是垃圾邮件</li>
</ul>
<p>流程：</p>
<ul>
<li>打标签</li>
<li>根据批量的样本和标签，学习特征<ul>
<li>发件人包含 字符 ！￥！@</li>
<li>正文包含：现金、领取等等</li>
</ul>
</li>
<li>针对新的样本，进行预测</li>
</ul>
<p>特点：</p>
<ol>
<li>样本越多，准确率会下降</li>
</ol>
<p>基本框架：</p>
<ul>
<li>y&#x3D;f(x1,x2,…,xn) 众多个特征</li>
<li>判断为类别N，如果y&#x3D;n<ul>
<li>y&#x3D;0 就是垃圾邮件</li>
</ul>
</li>
</ul>
<p>用什么方法？</p>
<ul>
<li>逻辑回归</li>
<li>KNN近邻算法<ul>
<li>通过计算不同特征之间的距离，来判断新的样本属于哪个类别</li>
</ul>
</li>
<li>决策树<ul>
<li>不停地问n个问题，最后得到结果</li>
</ul>
</li>
<li>神经网络<ul>
<li>通过多层神经网络，来学习特征之间的关系</li>
</ul>
</li>
</ul>
<p>分类任务和回归任务的区别</p>
<ul>
<li>分类目标：判断类别<ul>
<li>模型输出：非连续性标签 （passed&#x2F;failed;0&#x2F;1&#x2F;2…）</li>
</ul>
</li>
<li>回归目标：建立函数关系<ul>
<li>模型输出：连续性数值</li>
</ul>
</li>
</ul>
<p>问题：根据余额，判断小明是否会去看电影<br>训练数据</p>
<ul>
<li>余额为 1,2,3,4,5,<ul>
<li>看电影 正样本</li>
</ul>
</li>
<li>余额为 -1 -2 -3 -4 -5<ul>
<li>不看电影 负样本</li>
</ul>
</li>
</ul>
<p>寻找f(x)</p>
<p>样本量变大之后，准确率会下降</p>
<p>解决办法<br>逻辑回归</p>
<ul>
<li>用于解决分类问题的一种模型，根据数据特征，计算其归属于某一类别的概率P(x)，根据概率数值判断其所属类别</li>
<li>主要应用场景：二分类问题</li>
</ul>
<p>方程变成了<br>Y &#x3D; 1&#x2F;(1+e^(-x))</p>
<p>y是识别效果,P是概率分布</p>
<ul>
<li>1 P(x) &gt;&#x3D; 0.5</li>
<li>0 P(x) &lt; 0.5</li>
</ul>
<h4 id="3-3"><a href="#3-3" class="headerlink" title="3-3"></a>3-3</h4><p>无论是多少维度的分类任务，找出决策边界最重要</p>
<ul>
<li>g(x) &#x3D; xxx 也就是 xxx &#x3D; 0<ul>
<li>得出 &gt; 0 和 &lt; 0 的两个区域</li>
</ul>
</li>
</ul>
<h4 id="3-4"><a href="#3-4" class="headerlink" title="3-4"></a>3-4</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分类散点图可视化</span></span><br><span class="line"><span class="comment">## 未区分类别散点图</span></span><br><span class="line">plt.scatter(x1,x2)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 区分类别散点图</span></span><br><span class="line">mask = y == <span class="number">1</span></span><br><span class="line">passed = plt.scatter(x1[mask], x2[mask])</span><br><span class="line">failed = plt.scatter(x1[~mask], x2[~mask], marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逻辑回归模型使用</span></span><br><span class="line"><span class="comment">## 模型训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">LR = LogisticRegression()</span><br><span class="line">LR.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 边界函数系数</span></span><br><span class="line">theta1 = LR.coef_[<span class="number">0</span>][<span class="number">0</span>],LR.coef_[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">theta0 = LR.intercept_[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## 对新数据做预测</span></span><br><span class="line">predictions = LR.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立新数据集</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="comment">## 准确率（类别正确预测的臂力）,越接近1越好</span></span><br><span class="line"><span class="comment">### Accuracy = 正确预测样本数量/总样本数量</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">y_predict = LR.predict(x)</span><br><span class="line">accuracy = accuracy_score(y, y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 画图看决策边界效果，可视化模型表现.蓝色线是边界函数，观察分类效果，分割效果越明显越好</span></span><br><span class="line">plt.plot(x, x_boundary)</span><br><span class="line">passed = plt.scatter(x1[mask], x2[mask])</span><br><span class="line">failed = plt.scatter(x1[~mask], x2[~mask], marker=<span class="string">&#x27;^&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="3-5-实战1-考试通过预测"><a href="#3-5-实战1-考试通过预测" class="headerlink" title="3-5 实战1 考试通过预测"></a>3-5 实战1 考试通过预测</h4><ol>
<li>给予 examdata.csv 数据，建立逻辑回归模型，评估模型表现</li>
<li>预测 Exam1&#x3D;70,Exam2&#x3D;65 该同学是否能通过Exam3</li>
<li>建立二阶边界函数，重复步骤1和2<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the data</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;week3/examdata.csv&#x27;</span>)</span><br><span class="line">data.head()</span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"></span><br><span class="line">fig1 = plt.figure()</span><br><span class="line">plt.scatter(data.loc[:, <span class="string">&#x27;Exam1&#x27;</span>], data.loc[:, <span class="string">&#x27;Exam2&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Exam1 - Exam2&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Exam1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Exam2&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分 Exam1 和 Exam2</span></span><br><span class="line">mask = data.loc[:, <span class="string">&#x27;Pass&#x27;</span>] == <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(~mask)</span><br><span class="line"></span><br><span class="line">fig2 = plt.figure()</span><br><span class="line"><span class="comment"># 能通过的同学</span></span><br><span class="line">passed = plt.scatter(data.loc[:, <span class="string">&#x27;Exam1&#x27;</span>][mask], data.loc[:, <span class="string">&#x27;Exam2&#x27;</span>][mask])</span><br><span class="line"><span class="comment"># 不能通过的同学</span></span><br><span class="line">failed = plt.scatter(data.loc[:, <span class="string">&#x27;Exam1&#x27;</span>][~mask], data.loc[:, <span class="string">&#x27;Exam2&#x27;</span>][~mask])</span><br><span class="line">plt.title(<span class="string">&#x27;Exam1 - Exam2&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Exam1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Exam2&#x27;</span>)</span><br><span class="line">plt.legend((passed, failed), (<span class="string">&#x27;passed&#x27;</span>, <span class="string">&#x27;failed&#x27;</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除 Pass 列</span></span><br><span class="line">X = data.drop([<span class="string">&#x27;Pass&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = data.loc[:, <span class="string">&#x27;Pass&#x27;</span>]</span><br><span class="line">X1 = data.loc[:, <span class="string">&#x27;Exam1&#x27;</span>]</span><br><span class="line">X2 = data.loc[:, <span class="string">&#x27;Exam2&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立 逻辑回归 模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">LR = LogisticRegression()</span><br><span class="line">LR.fit(X, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">y_predict = LR.predict(X)</span><br><span class="line"><span class="built_in">print</span>(y_predict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">accuracy = accuracy_score(y, y_predict)</span><br><span class="line"><span class="built_in">print</span>(accuracy)</span><br><span class="line"></span><br><span class="line">y_test = LR.predict([[<span class="number">70</span>, <span class="number">65</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;passed&#x27;</span> <span class="keyword">if</span> y_test == <span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;failed&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LR.coef_, LR.intercept_</span><br><span class="line"></span><br><span class="line">theta0 = LR.intercept_</span><br><span class="line">theta1, theta2 = LR.coef_[<span class="number">0</span>][<span class="number">0</span>], LR.coef_[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(theta1, theta2)</span><br><span class="line"></span><br><span class="line">X2_new = -(theta0 + theta1 * X1) / theta2</span><br><span class="line"><span class="built_in">print</span>(X2_new)</span><br><span class="line"></span><br><span class="line">fig101 = plt.figure()</span><br><span class="line"><span class="comment"># 能通过的同学</span></span><br><span class="line">passed = plt.scatter(data.loc[:, <span class="string">&#x27;Exam1&#x27;</span>][mask], data.loc[:, <span class="string">&#x27;Exam2&#x27;</span>][mask])</span><br><span class="line"><span class="comment"># 不能通过的同学</span></span><br><span class="line">failed = plt.scatter(data.loc[:, <span class="string">&#x27;Exam1&#x27;</span>][~mask], data.loc[:, <span class="string">&#x27;Exam2&#x27;</span>][~mask])</span><br><span class="line">plt.plot(X1, X2_new)</span><br><span class="line">plt.title(<span class="string">&#x27;Exam1 - Exam2&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Exam1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Exam2&#x27;</span>)</span><br><span class="line">plt.legend((passed, failed), (<span class="string">&#x27;passed&#x27;</span>, <span class="string">&#x27;failed&#x27;</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li>
</ol>
<p>得出的结果不是特别好，需要进行二阶边界函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 new data</span></span><br><span class="line">X1_2 = X1 * X1</span><br><span class="line">X2_2 = X2 * X2</span><br><span class="line">X1_X2 = X1 * X2</span><br><span class="line"></span><br><span class="line">X_new = &#123;<span class="string">&#x27;X1&#x27;</span>: X1, <span class="string">&#x27;X2&#x27;</span>: X2, <span class="string">&#x27;X1_2&#x27;</span>: X1_2, <span class="string">&#x27;X2_2&#x27;</span>: X2_2, <span class="string">&#x27;X1_X2&#x27;</span>: X1_X2&#125;</span><br><span class="line">X_new = pd.DataFrame(X_new)</span><br><span class="line"><span class="built_in">print</span>(X_new)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建型模型以及训练</span></span><br><span class="line">LR2 = LogisticRegression()</span><br><span class="line">LR2.fit(X_new, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">y2_predict = LR2.predict(X_new)</span><br><span class="line">accuracy2 = accuracy_score(y, y2_predict)</span><br><span class="line"><span class="built_in">print</span>(accuracy2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将结果可视化</span></span><br><span class="line">Lr2.coef_, LR2.intercept_</span><br><span class="line"></span><br><span class="line">theta0 = LR.intercept_</span><br><span class="line">theta1, theta2, theta3, theta4, theta5 = LR2.coef_[<span class="number">0</span>][<span class="number">0</span>], LR2.coef_[<span class="number">0</span>][<span class="number">1</span>], LR2.coef_[<span class="number">0</span>][<span class="number">2</span>], LR2.coef_[<span class="number">0</span>][<span class="number">3</span>], LR2.coef_[<span class="number">0</span>][<span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span>(theta1, theta2, theta3, theta4, theta5)</span><br><span class="line"></span><br><span class="line">X2_new = -(theta0 + theta1 * X1) / theta2</span><br><span class="line"><span class="built_in">print</span>(X2_new)</span><br></pre></td></tr></table></figure>


<h4 id="4-机器学习-聚类"><a href="#4-机器学习-聚类" class="headerlink" title="4 机器学习-聚类"></a>4 机器学习-聚类</h4><h4 id="5-机器学习-其他"><a href="#5-机器学习-其他" class="headerlink" title="5 机器学习-其他"></a>5 机器学习-其他</h4><h4 id="6-模型评价和优化"><a href="#6-模型评价和优化" class="headerlink" title="6 模型评价和优化"></a>6 模型评价和优化</h4><h4 id="7-深度学习-多层感知机"><a href="#7-深度学习-多层感知机" class="headerlink" title="7 深度学习-多层感知机"></a>7 深度学习-多层感知机</h4><h4 id="7-1-多层感知机-MLP"><a href="#7-1-多层感知机-MLP" class="headerlink" title="7-1 多层感知机 MLP"></a>7-1 多层感知机 MLP</h4><p>模型二次项数量过多，计算量过大，而NLP在不增加高次项的情况下，可以实现复杂的非线性分类</p>
<p>人体神经结构</p>
<ul>
<li>树突<ul>
<li>接受上一个神经的轴突释放的化学物质</li>
</ul>
</li>
<li>几包和</li>
<li>细胞体</li>
<li>轴突<ul>
<li>释放递质给下一个神经元，实现信息传递</li>
</ul>
</li>
<li>轴突末端</li>
</ul>
<p>神经网络总结：</p>
<ul>
<li>由多个神经元组成</li>
<li>包含<ul>
<li>输入层</li>
<li>隐藏层</li>
<li>输出层</li>
</ul>
</li>
<li>多层感知机模型框架<ul>
<li>输入n个神经元 权值系数：θ1</li>
<li>隐含神经元 权值系数：θ2</li>
<li>隐含神经元 权值系数：θ3</li>
<li>…</li>
<li>输出神经元</li>
</ul>
</li>
</ul>
<p>NLP数学表达式： </p>
<ul>
<li>y &#x3D; g(z) &#x3D; 1&#x2F;(1+e^(-z)) -z其实是θx</li>
</ul>
<p>输入层 常数项 X0</p>
<h4 id="7-2-MLP-实现非线性分类"><a href="#7-2-MLP-实现非线性分类" class="headerlink" title="7-2 MLP 实现非线性分类"></a>7-2 MLP 实现非线性分类</h4><h4 id="7-3-Keras"><a href="#7-3-Keras" class="headerlink" title="7-3 Keras"></a>7-3 Keras</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立一个 sequential 顺序模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过.add()方法叠加各层网络</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line">model.add(Dense(units=<span class="number">3</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, input_dim=<span class="number">3</span>))</span><br><span class="line">model.add(Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看模型结构</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过.compile()方法配置模型求解过程参数</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="string">&#x27;sgd&#x27;</span>,metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h4 id="7-4-实战-1-建立MLP实现非线性二分类"><a href="#7-4-实战-1-建立MLP实现非线性二分类" class="headerlink" title="7-4 实战 1 建立MLP实现非线性二分类"></a>7-4 实战 1 建立MLP实现非线性二分类</h4><p>基于data.csv数据，建立mlp模型，计算其在测试数据上的准确率，可视化模型预测结果</p>
<ol>
<li>进行数据分离： test_size&#x3D;0.33, random_state&#x3D;10</li>
<li>模型结构：一层隐藏层，有20个神经元</li>
</ol>
<p>好坏质检二分类mlp实战summary：</p>
<ol>
<li>通过mlp模型，在不增加特征项的情况下，实现了非线性二分类任务</li>
<li>熟悉了mlp模型的建立、配置和训练方法，并实现基于新数据的预测</li>
<li>熟悉了mlp分类的预测数据格式，并实现格式转换</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the data</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Activation</span><br><span class="line"></span><br><span class="line">physical_devices = tf.config.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(physical_devices) &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;GPU is available!&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;No GPU detected. Training will use CPU.&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;week7/data.csv&#x27;</span>)</span><br><span class="line">data.head()</span><br><span class="line">X = data.drop([<span class="string">&#x27;y&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = data.loc[:, <span class="string">&#x27;y&#x27;</span>]</span><br><span class="line">X.head()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"></span><br><span class="line">fig1 = plt.figure()</span><br><span class="line">plt.scatter(X.loc[:, <span class="string">&#x27;x1&#x27;</span>], X.loc[:, <span class="string">&#x27;x2&#x27;</span>])</span><br><span class="line">passed = plt.scatter(X.loc[:, <span class="string">&#x27;x1&#x27;</span>][y==<span class="number">1</span>], X.loc[:, <span class="string">&#x27;x2&#x27;</span>][y==<span class="number">1</span>])</span><br><span class="line">failed = plt.scatter(X.loc[:, <span class="string">&#x27;x1&#x27;</span>][y==<span class="number">0</span>], X.loc[:, <span class="string">&#x27;x2&#x27;</span>][y==<span class="number">0</span>], marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.legend((passed, failed), (<span class="string">&#x27;passed&#x27;</span>, <span class="string">&#x27;failed&#x27;</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;row data&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据分离</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.33</span>, random_state=<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置模型</span></span><br><span class="line">mlp = Sequential()</span><br><span class="line">mlp.add(Dense(units=<span class="number">20</span>, input_dim=<span class="number">2</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">mlp.add(Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">mlp.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置模型 二分类是binary_crossentropy</span></span><br><span class="line">mlp.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">mlp.fit(X_train, y_train, epochs=<span class="number">3000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测并计算准确性 make prediction and calculate the accuracy</span></span><br><span class="line">y_train_predict = mlp.predict_classes(X_train)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">accuracy_train = accuracy_score(y_train, y_train_predict)</span><br><span class="line"><span class="built_in">print</span>(accuracy_train)</span><br><span class="line"><span class="comment">## Out: 0.88363636</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测测试数据并计算准确性 make prediction and calculate the test data</span></span><br><span class="line">y_train_predict = mlp.predict_classes(X_test)</span><br><span class="line">accuracy_test = accuracy_score(y_test, y_train_predict)</span><br><span class="line"><span class="built_in">print</span>(accuracy_test)</span><br><span class="line"><span class="comment">## Out: 0.88970588</span></span><br><span class="line"></span><br><span class="line">y_train_predict_form = pd.Series(i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> y_train_predict)</span><br><span class="line"><span class="built_in">print</span>(y_train_predict_form )</span><br></pre></td></tr></table></figure>


<h4 id="8-深度学习-卷积神经网络"><a href="#8-深度学习-卷积神经网络" class="headerlink" title="8 深度学习-卷积神经网络"></a>8 深度学习-卷积神经网络</h4><h4 id="9-深度学习-循环神经网络"><a href="#9-深度学习-循环神经网络" class="headerlink" title="9 深度学习-循环神经网络"></a>9 深度学习-循环神经网络</h4><h4 id="10-迁移学习、混合算法"><a href="#10-迁移学习、混合算法" class="headerlink" title="10 迁移学习、混合算法"></a>10 迁移学习、混合算法</h4><p>迁移学习</p>
<ul>
<li>主要思想是将从一个任务中学到的知识迁移到另一个相关的任务中。<ul>
<li>模型迁移</li>
<li>数据迁移</li>
</ul>
</li>
</ul>
<h4 id="10-2-混合模型"><a href="#10-2-混合模型" class="headerlink" title="10-2 混合模型"></a>10-2 混合模型</h4><p>监督+无监督学习<br>实际上我们更偏向于使用监督学习</p>
<p>数据决定模型表现上限</p>
<ul>
<li>理想的训练情况（更多的高质量数据）<ul>
<li>正常数据</li>
<li>穷尽类别</li>
<li>标注正确</li>
</ul>
</li>
<li>现实的训练情况（普通数据）<ul>
<li>夹杂异常数据</li>
<li>包含部分类别</li>
<li>标注标准不一</li>
</ul>
</li>
</ul>
<p>工业检测案例</p>
<ul>
<li>划痕</li>
<li>缺角</li>
<li>普通斑痕</li>
<li>蓝色斑痕</li>
</ul>
<p>苹果检测案例</p>
<ul>
<li>样本总数30个，普通和其他苹果 大约各占一半<ul>
<li>有10个苹果已经标注(普通苹果)，其他样本无标签</li>
</ul>
</li>
<li>建立模型区分普通&#x2F;其他苹果</li>
</ul>
<p>采用半监督学习：利用标签数据提供的正确信息，提高准确性</p>
<ul>
<li>在标记想本优先的情况下，尽可能识别出总样本的共同特性</li>
<li>利用有标记和无标记样本一起学习</li>
<li>具体实现<ul>
<li>伪标签学习：用<code>有标签数据</code>训练一个<code>分类器</code>，对<code>无标签数据</code>进行分类，产生伪标签，按一定规则挑选认为分类正确的无标签样本，将其和有标签样本作为数据对分类器进行训练。</li>
</ul>
</li>
</ul>
<p>半监督学习例子</p>
<ul>
<li>基于确定标签的部分数据，对聚类模型结果进行分类矫正<ul>
<li>根据已经打了标签的数据(原始数据分布)进行 聚类</li>
<li>无监督聚类<ul>
<li>只知道根据少量标签分类后的数据</li>
</ul>
</li>
<li>正确标签矫正结果<ul>
<li>分类完成</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>半监督学习例子2：有标签数据提取特征</p>
<ol>
<li>用有标签数据训练网络</li>
<li>通过隐藏层提取特征，基于<code>特征数据</code>对<code>无标签数据</code>进行建模预测</li>
<li>也可以用别人使用的类似数据甚至模型，例如VGG16提取图像特征</li>
</ol>
<p>机器学习和深度学习结合</p>
<p>数据预处理</p>
<ul>
<li>数据降维PCA</li>
<li>异常检测</li>
</ul>
<p>任务模型</p>
<ul>
<li>聚类 Kmeans&#x2F;Meanshift 等</li>
<li>分类 逻辑回归&#x2F;决策树等</li>
<li>回归 线性&#x2F;非线性</li>
</ul>
<p>深度学习</p>
<ul>
<li>多层感知机 MLP</li>
<li>卷积神经网络 CNN</li>
<li>循环神经网络 RNN</li>
</ul>
<h4 id="10-6-实战准备"><a href="#10-6-实战准备" class="headerlink" title="10-6 实战准备"></a>10-6 实战准备</h4><h5 id="实战1-准备"><a href="#实战1-准备" class="headerlink" title="实战1 准备"></a>实战1 准备</h5><p>任务：基于transfer_data.csv数据，建立迁移mlp模型，并且实现模型迁移学习</p>
<ul>
<li>实现x对y的预测，可视化效果</li>
<li>基于新数据transfer_data2.csv,对前模型进行二次训练，对比模型训练次数少的情况下的表现</li>
</ul>
<p>模型结构：mlp，两个隐藏层，每个隐藏层有50个神经元，激活函数relu，输出层激活函数linear，迭代次数：100次</p>
<p>上面是一道题目，对于模型结构的 隐藏层个数，有多少个神经元 激活函数 确定依据是什么？</p>
<ul>
<li>2个隐藏层 折中选择</li>
<li>每个隐藏层50个神经元 一般选择2的倍数 可以提供足够的模型复杂性，避免过拟合</li>
<li>隐藏层使用 ReLU 激活函数，可以提高模型的训练速度和准确性。</li>
<li>输出层使用 linear 激活函数，可以使模型输出与目标值保持一致。</li>
<li>由于数据集较小，选择100次迭代可以避免过拟合。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立mlp模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两个隐藏层</span></span><br><span class="line">model.add(Dense(units=<span class="number">50</span>, input_dim=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(units=<span class="number">50</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出层</span></span><br><span class="line">model.add(Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;linear&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 优化器和损失函数</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印摘要信息</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练和二次训练</span></span><br><span class="line">model.fit(x,y)</span><br><span class="line">model.fit(x2,y2) <span class="comment"># 模型迁移学习</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型保存到本地</span></span><br><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(model, <span class="string">&#x27;model1.m&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型加载</span></span><br><span class="line">model2 = joblib.load(<span class="string">&#x27;model1.m&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="实战1-基于新数据的迁移学习"><a href="#实战1-基于新数据的迁移学习" class="headerlink" title="实战1 基于新数据的迁移学习"></a>实战1 基于新数据的迁移学习</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;week10/transfer_data.csv&#x27;</span>)</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 x 和 y</span></span><br><span class="line">X = data.loc[:, <span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">y = data.loc[:, <span class="string">&#x27;y&#x27;</span>]</span><br><span class="line">X.head();</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示 数据</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig1 = plt.figure(figsize=(<span class="number">7</span>,<span class="number">5</span>))</span><br><span class="line">plt.scatter(X,y)</span><br><span class="line">plt.title(<span class="string">&#x27;y - x&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show() <span class="comment"># 执行后发现是二次函数</span></span><br><span class="line"></span><br><span class="line">X = np.array(X).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(X.shape, y.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 mlp 模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line">model1 = Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输入层</span></span><br><span class="line">model1.add(Dense(units=<span class="number">50</span>, input_dim=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model1.add(Dense(units=<span class="number">50</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出层</span></span><br><span class="line">model1.add(Dense(units=<span class="number">1</span>, activation=<span class="string">&#x27;linear&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 优化器和损失函数</span></span><br><span class="line">model1.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印摘要信息</span></span><br><span class="line">model1.summary()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练100次</span></span><br><span class="line"><span class="comment"># 模型训练和二次训练</span></span><br><span class="line">model1.fit(X,y,epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果预测</span></span><br><span class="line">y_predict = model1.predict(X)</span><br><span class="line"></span><br><span class="line">fig100 = plt.figure(figsize=(<span class="number">7</span>,<span class="number">5</span>))</span><br><span class="line">plt.scatter(X, y)</span><br><span class="line">plt.plot(X, y_predict, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;y vs x(epochs=100)&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次训练100次</span></span><br><span class="line"><span class="comment"># 模型训练和二次训练</span></span><br><span class="line">model1.fit(X,y,epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果预测</span></span><br><span class="line">y_predict = model1.predict(X)</span><br><span class="line"></span><br><span class="line">fig200 = plt.figure(figsize=(<span class="number">7</span>,<span class="number">5</span>))</span><br><span class="line">plt.scatter(X, y)</span><br><span class="line">plt.plot(X, y_predict, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;y vs x(epochs=200)&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次训练100次</span></span><br><span class="line"><span class="comment"># 模型训练和二次训练</span></span><br><span class="line">model1.fit(X,y,epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果预测</span></span><br><span class="line">y_predict = model1.predict(X)</span><br><span class="line"></span><br><span class="line">fig300 = plt.figure(figsize=(<span class="number">7</span>,<span class="number">5</span>))</span><br><span class="line">plt.scatter(X, y)</span><br><span class="line">plt.plot(X, y_predict, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;y vs x(epochs=300)&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型架构和权重</span></span><br><span class="line">model1.save(<span class="string">&#x27;week10/model1.keras&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型架构和权重</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"></span><br><span class="line">model2 = load_model(<span class="string">&#x27;week10/model1.keras&#x27;</span>)</span><br><span class="line"></span><br><span class="line">data2 = pd.read_csv(<span class="string">&#x27;week10/transfer_data2.csv&#x27;</span>)</span><br><span class="line">data2.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 x 和 y</span></span><br><span class="line">X2 = np.array(data2.loc[:, <span class="string">&#x27;x2&#x27;</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y2 = data2.loc[:, <span class="string">&#x27;y2&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(X2.shape, y2.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果预测</span></span><br><span class="line">y2_predict = model2.predict(X2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示 数据</span></span><br><span class="line">fig5 = plt.figure(figsize=(<span class="number">7</span>,<span class="number">5</span>))</span><br><span class="line">plt.scatter(X, y, label=<span class="string">&#x27;data1&#x27;</span>)</span><br><span class="line">plt.scatter(X2, y2, label=<span class="string">&#x27;data2&#x27;</span>)</span><br><span class="line">plt.plot(X, y2_predict, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;predict2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;y - x&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习</span></span><br><span class="line">model2.fit(X2, y2, epochs=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y2_predict = model2.predict(X2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示 数据</span></span><br><span class="line">fig100 = plt.figure(figsize=(<span class="number">7</span>,<span class="number">5</span>))</span><br><span class="line">plt.scatter(X, y, label=<span class="string">&#x27;data1&#x27;</span>)</span><br><span class="line">plt.scatter(X2, y2, label=<span class="string">&#x27;data2&#x27;</span>)</span><br><span class="line">plt.plot(X, y2_predict, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;predict2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.title(<span class="string">&#x27;y - x(epochs=100)&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">X = np.array(X).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(X.shape, y.shape)</span><br></pre></td></tr></table></figure>

<h5 id="实战2-寻找普通苹果和其他苹果"><a href="#实战2-寻找普通苹果和其他苹果" class="headerlink" title="实战2 寻找普通苹果和其他苹果"></a>实战2 寻找普通苹果和其他苹果</h5><p>资源：30张苹果图片，13张普通苹果，10张带标签(4开头)，文件夹：origin_data</p>
<p>思路：根据 original_data 样本，建立模型,对test_data的图片进行普通&#x2F;其他苹果判断:</p>
<ul>
<li>数据增强，增加 普通苹果的样本数量</li>
<li>特征提取，使用VGG16模型提取图像特征（深度卷积神经网络模型，可以进行图像识别和特征提取）</li>
<li>图片批量处理</li>
<li>使用 Kmeans 模型 并且 基于标签数据矫正结果以及可视化，但是效果不是很好</li>
<li>进而使用 Meanshift 模型提升模型表现</li>
<li>数据降维PCA处理，因为特征太多，没有必要保存太多维度，留下主要信息，删除噪音</li>
</ul>
<p>K-均值聚类（中心）<br>算法：以空间中k个点位中心进行聚类，对最靠近他们的对象归类，是聚类算法中最为基础但也最为重要的算法</p>
<p>公式：</p>
<ul>
<li>数据点和各簇中心点距离：dist</li>
<li>根据距离归类：</li>
<li>中心更新</li>
</ul>
<p>均值漂移聚类（密度）<br>算法：一种基于密度梯度上升的聚类算法（沿着密度上升方向寻找聚类中心点）<br>公式：</p>
<ul>
<li>均值偏移: M(x) &#x3D; 1&#x2F;N * ΣK(u-xi)</li>
<li>中心更新：u^t+1 &#x3D; u^t + m^t<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据增强</span></span><br><span class="line"><span class="keyword">from</span> keras_preprocessing.image <span class="keyword">import</span> ImageDataGenerator, array_to_img, img_to_array, load_img</span><br><span class="line">path = <span class="string">&#x27;week10/original_data&#x27;</span> <span class="comment"># 原始数据文件夹</span></span><br><span class="line">dst_path = <span class="string">&#x27;week10/gen_data&#x27;</span> <span class="comment"># 图片增强后的文件夹</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建实例、配置图片增强参数 # 参考连接：https://keras.io/zh/preprocessing/image/</span></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    rotation_range=<span class="number">10</span>, <span class="comment"># 旋转角度</span></span><br><span class="line">    width_shift_range=<span class="number">0.1</span>, <span class="comment"># 宽度偏移</span></span><br><span class="line">    height_shift_range=<span class="number">0.02</span>, <span class="comment"># 高度偏移</span></span><br><span class="line">    horizontal_flip=<span class="literal">True</span>, <span class="comment"># 水平翻转</span></span><br><span class="line">    vertical_flip=<span class="literal">True</span>, <span class="comment"># 垂直翻转</span></span><br><span class="line">    <span class="comment"># shear_range=0.2, # 剪切强度</span></span><br><span class="line">    <span class="comment"># zoom_range=0.2, # 缩放强度</span></span><br><span class="line">    <span class="comment"># fill_mode=&#x27;nearest&#x27; # 填充模式</span></span><br><span class="line">)</span><br><span class="line">gen = datagen.flow_from_directory(</span><br><span class="line">    path, <span class="comment"># 原始数据文件夹</span></span><br><span class="line">    target_size=(<span class="number">224</span>,<span class="number">224</span>), <span class="comment"># 图片大小</span></span><br><span class="line">    batch_size=<span class="number">2</span>, <span class="comment"># 批量大小</span></span><br><span class="line">    save_to_dir=dst_path, <span class="comment"># 图片增强后的文件夹</span></span><br><span class="line">    save_prefix=<span class="string">&#x27;gen&#x27;</span>, <span class="comment"># 图片增强后的文件名前缀</span></span><br><span class="line">    save_format=<span class="string">&#x27;jpg&#x27;</span> <span class="comment"># 图片增强后的文件格式</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    gen.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 单张图片载入</span></span><br><span class="line">img_path = <span class="string">&#x27;week10/1.jpg&#x27;</span></span><br><span class="line">img = load_img(img_path, target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line"><span class="built_in">type</span>(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单张图片可视化</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure(figsize=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">plt.imshow(img)</span><br><span class="line"></span><br><span class="line">img_array = img_to_array(img)</span><br><span class="line"><span class="built_in">type</span>(img_array)</span><br><span class="line"><span class="built_in">print</span>(img_array.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单张图片特征提取</span></span><br><span class="line"><span class="comment">## 模型加载、图像矩阵预处理</span></span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> preprocess_input</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 国内无法下载，可以先下载，放入C:\Users\li\.keras\models文件夹内执行</span></span><br><span class="line">model_vgg = VGG16(weights=<span class="string">&#x27;imagenet&#x27;</span>, include_top=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加维度</span></span><br><span class="line">x = np.expand_dims(img_array, axis=<span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"><span class="built_in">print</span>(x.shape)  <span class="comment"># 结果是 (1, 224, 224, 3)</span></span><br><span class="line"> </span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征提取</span></span><br><span class="line">features = model_vgg.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征数据格式预处理</span></span><br><span class="line">features = features.reshape(<span class="number">1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">512</span>)</span><br><span class="line"><span class="built_in">print</span>(features.shape)  <span class="comment"># 结果是 (1, 25088)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量图片路径加载</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">folder = <span class="string">&#x27;week10/train_data&#x27;</span> <span class="comment"># 训练数据文件夹名称</span></span><br><span class="line">dirs = os.listdir(folder) <span class="comment"># 获取文件夹下所有文件名称</span></span><br><span class="line"><span class="built_in">print</span>(dirs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图片路径合成</span></span><br><span class="line">img_path = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dirs:</span><br><span class="line">  <span class="keyword">if</span> os.path.splitext(i)[<span class="number">1</span>] == <span class="string">&#x27;.jpg&#x27;</span>:</span><br><span class="line">    img_path.append(i)</span><br><span class="line">img_path = [folder + <span class="string">&#x27;//&#x27;</span> + i <span class="keyword">for</span> i <span class="keyword">in</span> img_path]</span><br><span class="line"><span class="built_in">print</span>(img_path)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个提取图片特征的方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modelProcess</span>(<span class="params">img_path, model</span>):</span><br><span class="line">    img = load_img(img_path, target_size=(<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">    img_array = img_to_array(img)</span><br><span class="line">    x = np.expand_dims(img_array, axis=<span class="number">0</span>)</span><br><span class="line">    x = preprocess_input(x)</span><br><span class="line">    features = model.predict(x)</span><br><span class="line">    features = features.reshape(<span class="number">1</span>,<span class="number">7</span>*<span class="number">7</span>*<span class="number">512</span>)</span><br><span class="line">    <span class="keyword">return</span> features</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量提取图片特征</span></span><br><span class="line">features_train = np.zeros((<span class="built_in">len</span>(img_path), <span class="number">7</span>*<span class="number">7</span>*<span class="number">512</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img_path)):</span><br><span class="line">    features_i = modelProcess(img_path[i], model_vgg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;preprocessed: &#x27;</span>, img_path[i])</span><br><span class="line">    features_train[i] = features_i</span><br><span class="line"><span class="built_in">print</span>(features_train.shape) <span class="comment"># (230, 25088) 230张图片，每张图片有25088个特征</span></span><br></pre></td></tr></table></figure>
无监督学习 KMeans 聚类<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"><span class="comment"># 报错：Anaconda3\lib\site-packages\sklearn\cluster\_kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.</span></span><br><span class="line"></span><br><span class="line">x = features_train</span><br><span class="line"><span class="comment"># 无监督学习 KMeans 聚类</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">cnn_kmeans = KMeans(n_clusters=<span class="number">2</span>, max_iter=<span class="number">2000</span>) <span class="comment"># 两个类别，苹果和生成的200个特征</span></span><br><span class="line">cnn_kmeans.fit(x)</span><br><span class="line">y_pred_kmeans = cnn_kmeans.predict(x)</span><br><span class="line"><span class="built_in">print</span>(y_pred_kmeans)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果统计</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="built_in">print</span>(Counter(y_pred_kmeans)) <span class="comment"># 如果两个类别相近，则有问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量可视化结果</span></span><br><span class="line">normal_apple_id = <span class="number">1</span></span><br><span class="line">fig2 = plt.figure(figsize=(<span class="number">10</span>,<span class="number">40</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">45</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        img = load_img(img_path[i*<span class="number">5</span>+j])</span><br><span class="line">        plt.subplot(<span class="number">45</span>,<span class="number">5</span>,i*<span class="number">5</span>+j+<span class="number">1</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;apple&#x27;</span> <span class="keyword">if</span> y_pred_kmeans[i*<span class="number">5</span>+j] == normal_apple_id <span class="keyword">else</span> <span class="string">&#x27;others&#x27;</span>)</span><br><span class="line">        plt.imshow(img), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line">folder_test = <span class="string">&#x27;week10/test_data&#x27;</span> <span class="comment"># 测试数据文件夹名称</span></span><br><span class="line">dirs_test = os.listdir(folder_test) <span class="comment"># 获取文件夹下所有文件名称</span></span><br><span class="line"><span class="comment"># 图片路径合成</span></span><br><span class="line">img_path_test = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dirs_test:</span><br><span class="line">  <span class="keyword">if</span> os.path.splitext(i)[<span class="number">1</span>] == <span class="string">&#x27;.jpg&#x27;</span>:</span><br><span class="line">    img_path_test.append(i)</span><br><span class="line">img_path_test = [folder_test + <span class="string">&#x27;//&#x27;</span> + i <span class="keyword">for</span> i <span class="keyword">in</span> img_path_test]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(img_path_test), img_path_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量提取图片特征</span></span><br><span class="line">features_test = np.zeros((<span class="built_in">len</span>(img_path_test), <span class="number">7</span>*<span class="number">7</span>*<span class="number">512</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img_path_test)):</span><br><span class="line">    features_i = modelProcess(img_path_test[i], model_vgg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;preprocessed: &#x27;</span>, img_path_test[i])</span><br><span class="line">    features_test[i] = features_i</span><br><span class="line">x_test = features_test</span><br><span class="line"><span class="built_in">print</span>(x_test.shape) <span class="comment"># (12, 25088) 12张图片，每张图片有25088个特征</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">y_pred_kmeans_test = cnn_kmeans.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(y_pred_kmeans_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量可视化结果</span></span><br><span class="line">normal_apple_id = <span class="number">1</span></span><br><span class="line">fig3 = plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        img = load_img(img_path_test[i*<span class="number">4</span>+j])</span><br><span class="line">        plt.subplot(<span class="number">3</span>,<span class="number">4</span>,i*<span class="number">4</span>+j+<span class="number">1</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;apple&#x27;</span> <span class="keyword">if</span> y_pred_kmeans_test[i*<span class="number">4</span>+j] == normal_apple_id <span class="keyword">else</span> <span class="string">&#x27;others&#x27;</span>)</span><br><span class="line">        plt.imshow(img), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果统计</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="built_in">print</span>(Counter(y_pred_kmeans_test)) <span class="comment"># 如果两个类别相近，则有问题</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>Meanshift 聚类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Meanshift 聚类</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MeanShift, estimate_bandwidth</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动获取区域宽度 140个样本进行评估</span></span><br><span class="line">bw = estimate_bandwidth(x, n_samples=<span class="number">140</span>)</span><br><span class="line"><span class="built_in">print</span>(bw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">cnn_ms = MeanShift(bandwidth=bw)</span><br><span class="line">cnn_ms.fit(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">y_predict_ms = ms.predict(x)</span><br><span class="line"><span class="built_in">print</span>(y_predict_ms)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量可视化结果</span></span><br><span class="line">normal_apple_id = <span class="number">0</span></span><br><span class="line">fig4 = plt.figure(figsize=(<span class="number">10</span>,<span class="number">40</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">45</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        img = load_img(img_path[i*<span class="number">5</span>+j])</span><br><span class="line">        plt.subplot(<span class="number">45</span>,<span class="number">5</span>,i*<span class="number">5</span>+j+<span class="number">1</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;apple&#x27;</span> <span class="keyword">if</span> y_predict_ms[i*<span class="number">5</span>+j] == normal_apple_id <span class="keyword">else</span> <span class="string">&#x27;others&#x27;</span>)</span><br><span class="line">        plt.imshow(img), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果统计</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="built_in">print</span>(Counter(y_predict_ms)) <span class="comment"># 如果两个类别相近，则有问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测 cnn_ms test 的 结果</span></span><br><span class="line">y_predict_ms_test = cnn_ms.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(y_predict_ms_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量可视化结果</span></span><br><span class="line">fig5 = plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        img = load_img(img_path_test[i*<span class="number">4</span>+j])</span><br><span class="line">        plt.subplot(<span class="number">3</span>,<span class="number">4</span>,i*<span class="number">4</span>+j+<span class="number">1</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;apple&#x27;</span> <span class="keyword">if</span> y_predict_ms_test[i*<span class="number">4</span>+j] == normal_apple_id <span class="keyword">else</span> <span class="string">&#x27;others&#x27;</span>)</span><br><span class="line">        plt.imshow(img), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果统计</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="built_in">print</span>(Counter(y_predict_ms_test)) <span class="comment"># 如果两个类别相近，则有问题</span></span><br></pre></td></tr></table></figure>

<p>主成分分析PCA降维</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PCA 降维</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">stds = StandardScaler()</span><br><span class="line">X_norm = stds.fit_transform(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># PCA analysis</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">200</span>) <span class="comment"># 200维 效果比较好 原来是224</span></span><br><span class="line">X_pca = pca.fit_transform(X_norm)</span><br><span class="line"><span class="built_in">print</span>(X_pca)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算主成分方法比例</span></span><br><span class="line">var_ratio = pca.explained_variance_ratio_</span><br><span class="line"><span class="built_in">print</span>(var_ratio) <span class="comment"># 方差比例</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看主成分方差比之和</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(var_ratio))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建模之前查看X_pca和原来x的的shape</span></span><br><span class="line"><span class="built_in">print</span>(X_pca.shape, x.shape) <span class="comment"># 样本数一样，但是维度改成了200</span></span><br><span class="line"><span class="comment">#---------------------------------</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>再次进行 Meanshift聚类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Meanshift 聚类</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MeanShift, estimate_bandwidth</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动获取区域宽度 140个样本进行评估</span></span><br><span class="line">bw = estimate_bandwidth(X_pca, n_samples=<span class="number">140</span>)</span><br><span class="line"><span class="built_in">print</span>(bw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">cnn_pca_ms = MeanShift(bandwidth=bw)</span><br><span class="line">cnn_pca_ms.fit(X_pca)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line">y_predict_pca_ms = cnn_pca_ms.predict(X_pca)</span><br><span class="line"><span class="built_in">print</span>(y_predict_pca_ms)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量可视化结果</span></span><br><span class="line">normal_apple_id = <span class="number">0</span></span><br><span class="line">fig6 = plt.figure(figsize=(<span class="number">10</span>,<span class="number">40</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">45</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        img = load_img(img_path[i*<span class="number">5</span>+j])</span><br><span class="line">        plt.subplot(<span class="number">45</span>,<span class="number">5</span>,i*<span class="number">5</span>+j+<span class="number">1</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;apple&#x27;</span> <span class="keyword">if</span> y_predict_pca_ms[i*<span class="number">5</span>+j] == normal_apple_id <span class="keyword">else</span> <span class="string">&#x27;others&#x27;</span>)</span><br><span class="line">        plt.imshow(img), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果统计</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="built_in">print</span>(Counter(y_predict_pca_ms)) <span class="comment"># 如果两个类别相近，则有问题</span></span><br><span class="line"></span><br><span class="line">X_norm_test = stds.transform(x_test) <span class="comment"># 标准化</span></span><br><span class="line">X_pca_test = pca.transform(X_norm_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测 cnn_ms test 的 结果</span></span><br><span class="line">y_predict_pca_ms_test = cnn_pca_ms.predict(X_pca_test)</span><br><span class="line"><span class="built_in">print</span>(y_predict_pca_ms_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量可视化结果</span></span><br><span class="line">fig7 = plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        img = load_img(img_path_test[i*<span class="number">4</span>+j])</span><br><span class="line">        plt.subplot(<span class="number">3</span>,<span class="number">4</span>,i*<span class="number">4</span>+j+<span class="number">1</span>)</span><br><span class="line">        plt.title(<span class="string">&#x27;apple&#x27;</span> <span class="keyword">if</span> y_predict_pca_ms_test[i*<span class="number">4</span>+j] == normal_apple_id <span class="keyword">else</span> <span class="string">&#x27;others&#x27;</span>)</span><br><span class="line">        plt.imshow(img), plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测结果统计</span></span><br><span class="line"><span class="keyword">from</span> coll</span><br></pre></td></tr></table></figure>

<h3 id="微软生成式AI-generative-ai-for-beginners"><a href="#微软生成式AI-generative-ai-for-beginners" class="headerlink" title="微软生成式AI generative-ai-for-beginners"></a>微软生成式AI generative-ai-for-beginners</h3><p>能够生成文本、图像、其他类型内容的AI</p>
<p>新算法的开发——被称为机器学习——能够从数据中学习模式，而无需显式编程。<br>这种方法允许<code>机器</code>模拟<code>人类</code>语言理解：统计模型在<code>文本标签配对</code>上进行训练，使模型能够使用代表消息意图的预定义标签对未知输入文本进行分类。</p>
<p>神经网络（特别是循环神经网络 - RNN）显着增强了自然语言处理，能够以更有意义的方式表示文本含义，并重视句子中单词的上下文。</p>
<ul>
<li>人工智能<ul>
<li>机器学习<ul>
<li>深度学习<ul>
<li>生成性AI</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blog/p/614a8811/" rel="prev" title="UE游戏开发">
                  <i class="fa fa-chevron-left"></i> UE游戏开发
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/blog/p/5618cb0a/" rel="next" title="DevTools">
                  DevTools <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">阿尤</span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/blog/js/comments.js"></script><script src="/blog/js/utils.js"></script><script src="/blog/js/motion.js"></script><script src="/blog/js/schemes/muse.js"></script><script src="/blog/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/blog/js/third-party/search/local-search.js"></script>





  





</body>
</html>
